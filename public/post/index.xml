<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on DNA confesses and Data speak</title>
    <link>/post/</link>
    <description>Recent content in Posts on DNA confesses and Data speak</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Ming Tang</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 -0500</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Merge featureCount table from RNAseq</title>
      <link>/post/merge-featurecount-table-from-rnaseq/</link>
      <pubDate>Tue, 27 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/merge-featurecount-table-from-rnaseq/</guid>
      <description>featureCounts is a program to fast summarize counts from sequencing data. I use it to get gene-level RNAseq counts by
featureCounts -p -t exon -g gene_id -a annotation.gtf -o mysample_featureCount.txt mapping_results_PE.bam
If you have a lot of samples, you will get a lot of *featureCount.txt and you will need to merge them for downstream analysis.
I will show you how to merge the tables using R, python and unix below.</description>
    </item>
    
    <item>
      <title>Three gotchas when using R for Genomic data analysis</title>
      <link>/post/three-gotchas-when-using-r-for-genomic-data-analysis/</link>
      <pubDate>Tue, 27 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/three-gotchas-when-using-r-for-genomic-data-analysis/</guid>
      <description>During my daily work with R for genomic data analysis, I encountered several instances that R gives me some (bad) surprises.
1. The devil 1 and 0 coordinate system read detail here https://github.com/crazyhottommy/DNA-seq-analysis#tips-and-lessons-learned-during-my-dna-seq-data-analysis-journey
some files such as bed file is 0 based. Two genomic regions:
chr1 0 1000 chr1 1001 2000  when you import that bed file into R using rtracklayer::import(), it will become
chr1 1 1000 chr1 1000 2000  The function convert it to 1 based internally (R is 1 based unlike python).</description>
    </item>
    
    <item>
      <title>open files on remote with sublime by ssh</title>
      <link>/post/open-files-on-remote-with-sublime-by-ssh/</link>
      <pubDate>Wed, 10 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/open-files-on-remote-with-sublime-by-ssh/</guid>
      <description>I am still suck at vim or emacs. I use nano to edit files on remote machines. But for more complicated editing, I prefer to use sublime.
use this https://github.com/randy3k/RemoteSubl for editing remote files.
Steps:
on remote machine, install rmate ssh bio1 curl -o ~/bin/rmate https://raw.githubusercontent.com/aurora/rmate/master/rmate chmod u+x bin/rmate  on your local computer, install RemoteSubl on your local computer, open sublime, click tools &amp;ndash;&amp;gt; Command Palette &amp;ndash;&amp;gt; type Package control:Install Package &amp;ndash;&amp;gt; type RemoteSubl to install.</description>
    </item>
    
    <item>
      <title>set up odyssey HPC dot files</title>
      <link>/post/set-up-odyssey-hpc-dot-files/</link>
      <pubDate>Tue, 09 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/set-up-odyssey-hpc-dot-files/</guid>
      <description>dot files Those files are originally got from Samir Amin, my labmate in Roel Verhaak&amp;rsquo;s lab. Thanks for sharing!
.screenrc
.bashrc
.bash_profile
and inside .profile.d folder, there is a file named 01_odyssey_config.sh. It was executed when you login the shell.
You can grab my dot files in my github repo.
Inside the .bash_profile:
if [ -d $HOME/.profile.d ]; then for i in $HOME/.profile.d/*.sh; do if [ -r $i ]; then if [ &amp;quot;${-#*i}&amp;quot; !</description>
    </item>
    
    <item>
      <title>set up ssh odyssey HPC</title>
      <link>/post/set-up-ssh-odyssey-hpc/</link>
      <pubDate>Thu, 04 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/set-up-ssh-odyssey-hpc/</guid>
      <description>request an account following here.
 Harvard odyssey HPC requires a two-factor security login. First set up the VPN following here
 Then read about OpenAuth here. One can download mobile apps such as Duo and google-Authenticator on your phone, but then each time you will need to type the password to the terminal. Or you can download the java program for desktop, if you have a FAS research computing account, you should be able to download it from the link FASRC send you.</description>
    </item>
    
    <item>
      <title>set up my new mac laptop</title>
      <link>/post/set-up-my-new-mac-laptop/</link>
      <pubDate>Wed, 03 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/set-up-my-new-mac-laptop/</guid>
      <description>I am starting my first day at Harvard FAS informatics and I will keep a note here on how I set up my new laptop.
customize terminal following this gist:
download iterm2 for mac here.
install on-my-zsh sh -c &amp;quot;$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&amp;quot;  You will have to install git first for the upper command to work. Now, when you fire up your terminal, it looks much more prettier! (there are many other schemes for oh my zsh, I found the default is good.</description>
    </item>
    
    <item>
      <title>Compute averages/sums on GRanges or equal length bins</title>
      <link>/post/compute-averages-sums-on-granges-or-equal-length-bins/</link>
      <pubDate>Fri, 07 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/compute-averages-sums-on-granges-or-equal-length-bins/</guid>
      <description>Googling is a required technique for programmers. Once I have a programming problem in mind, the first thing I do is to google to see if other people have encountered the same problem and maybe they already have a solution. Do not re-invent the wheels. Actually, reading other peopleâ€™s code and mimicing their code is a great way of learning. Today, I am going to show you how to compute binned averages/sums along a genome or any genomic regions of interest.</description>
    </item>
    
    <item>
      <title>my first try on Rmarkdown using blogdown</title>
      <link>/post/my-first-try-on-rmarkdown-using-blogdown/</link>
      <pubDate>Sat, 30 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/my-first-try-on-rmarkdown-using-blogdown/</guid>
      <description>I have used blogdown writing regular markdown posts, but the real power is from the Rmarkdown! let me try it for this post.
Note that you do not knit the Rmarkdown by yourself, rather you let blogdown do the heavy lift.
library(tidyverse)  ## Loading tidyverse: ggplot2 ## Loading tidyverse: tibble ## Loading tidyverse: tidyr ## Loading tidyverse: readr ## Loading tidyverse: purrr ## Loading tidyverse: dplyr  ## Warning: package &#39;tibble&#39; was built under R version 3.</description>
    </item>
    
    <item>
      <title>hugo academic theme blog down deployment (some details)</title>
      <link>/post/hugo-academic-theme-blog-down-deployment-some-details/</link>
      <pubDate>Fri, 29 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/hugo-academic-theme-blog-down-deployment-some-details/</guid>
      <description>I have been following this tutorial from Alison and tips from Leslie Myint for some customization for deploying my blogdown website
It is quite straightforward to have a working site following Alison&amp;rsquo;s guide. However, you always want some customization of your own site.
I took the tips from Leslie.
changed the menue bar to black. I like it better than the default white. in the config.toml file, change the theme:</description>
    </item>
    
    <item>
      <title>Backup automatically with cron</title>
      <link>/post/crontab-for-backup/</link>
      <pubDate>Wed, 27 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/crontab-for-backup/</guid>
      <description>Data backup is an essential step in the data analysis life cycle. As shown in a pic below taken from DataOne.
There are so many important things you may want to back up: your raw/processed data, your code, and your dot configuration files. While for every project, I have git version control my scripts (not the data) and push it to github or gitlab to have a backup, big files can not be hosted on github or gitlab.</description>
    </item>
    
    <item>
      <title>How to upload files to GEO</title>
      <link>/post/how-to-upload-files-to-geo/</link>
      <pubDate>Fri, 22 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/how-to-upload-files-to-geo/</guid>
      <description>readings links: http://yeolab.github.io/onboarding/geo.html
http://www.hildeschjerven.net/Protocols/Submission_of_HighSeq_data_to_GEO.pdf
https://www.ncbi.nlm.nih.gov/geo/info/submissionftp.html
1. create account Go to NCBI GEO: http://www.ncbi.nlm.nih.gov/geo/ Create User ID and password. my username is research_guru
I used my google account.
2. fill in the xls sheet Downloaded the meta xls sheet from https://www.ncbi.nlm.nih.gov/geo/info/seq.html
## bgzip the fastqs cd 01seq find *fastq | parallel bgzip md5sum *fastq.gz &amp;gt; fastq_md5.txt # copy to excle cat fastq_md5.txt | awk &#39;{print $2}&#39; #copy to excle cat fastq_md5.</description>
    </item>
    
  </channel>
</rss>