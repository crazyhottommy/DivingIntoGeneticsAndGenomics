<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DNA confesses Data speak on DNA confesses Data speak</title>
    <link>/</link>
    <description>Recent content in DNA confesses Data speak on DNA confesses Data speak</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Ming Tang</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0400</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>The end of 2018</title>
      <link>/post/the-end-of-2018/</link>
      <pubDate>Fri, 28 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/the-end-of-2018/</guid>
      <description>

&lt;p&gt;It is almost the end of 2018. It is a good time to review what I have achieved during the year
and look forward to a brand new 2019. I wrote a similar post for 2017 &lt;a href=&#34;http://crazyhottommy.blogspot.com/2017/12/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;some-highlights-of-the-year-2018&#34;&gt;Some highlights of the year 2018:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;My son Noah Tang was born in April. He is so lovely and we love him so much. Can&amp;rsquo;t believe he is
almost 9 months old.
&lt;img src=&#34;/img/noah.jpg&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Our epigenomic project was selected by the &lt;a href=&#34;https://bigdatau.ini.usc.edu/roadtrip&#34; target=&#34;_blank&#34;&gt;Data Science Road-Trip program&lt;/a&gt; by USC. I spent 2 weeks in PNNL and worked closely with &lt;a href=&#34;https://www.pnnl.gov/science/staff/staff_info.asp?staff_num=8785&#34; target=&#34;_blank&#34;&gt;Lisa Bramer&lt;/a&gt; and developed a pipeline to do feature selection using machine learning from a lot of chromHMM data sets. You can find the github repo &lt;a href=&#34;https://github.com/crazyhottommy/pyflow-chromForest/tree/vsurf_merge&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;. I kept a note for everyday what I did as well at &lt;a href=&#34;https://github.com/crazyhottommy/Epigenome_RoadTrip&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;. I will think about writing it up.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;I finally migrated my &lt;a href=&#34;http://crazyhottommy.blogspot.com/&#34; target=&#34;_blank&#34;&gt;previous blog&lt;/a&gt; to blogdown which you are reading now :) Oh my, I love it. It makes blogging so much fun.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;I taught the ChIP-seq lesson for &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/talk/2018-dibsi-course/&#34; target=&#34;_blank&#34;&gt;2018 ANGUS Next-Gen Sequence Analysis Workshop&lt;/a&gt; held in UC Davis from 7/1/2018 to 7/14/2018, and TAed for the rest of the sessions. It was a great teaching experience for me. I got to know many people and built connections. Most importantly, I enjoyed the teaching very much! Thanks &lt;a href=&#34;https://biology.ucdavis.edu/people/c-titus-brown&#34; target=&#34;_blank&#34;&gt;Titus Brown&lt;/a&gt; for the invitation. I highly recommend you to attend this workshop if you want to start learning sequencing data analysis. The environment is so welcoming and Titus is so hilarious:) I was in the workshop to learn in 2014 and now I am back to teach!&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;I went back to University of Florida where I did my PhD to give a &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/talk/2018-uf-talk/&#34; target=&#34;_blank&#34;&gt;talk&lt;/a&gt;. It was very nice to be back home and catch up with my supervisor, other professors and some church friends!&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Several co-author &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/&#34; target=&#34;_blank&#34;&gt;papers/see the publications section&lt;/a&gt; are out in 2018. My first video shot for JOVE can be found at &lt;a href=&#34;https://www.jove.com/video/56972/an-integrated-platform-for-genome-wide-mapping-chromatin-states-using&#34; target=&#34;_blank&#34;&gt;https://www.jove.com/video/56972/an-integrated-platform-for-genome-wide-mapping-chromatin-states-using&lt;/a&gt;. I was nervous but It was fun.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;In addition, two papers are out in Biorxiv at the end of 2018. I am co-first author in one of them. Both papers describe how epigenetic regulator KMT2D mediate tumor progression in melanoma and lung cancer, respectively. We are in the process submitting those papers to journals, but you can read more details at &lt;a href=&#34;https://www.biorxiv.org/content/early/2018/12/28/507202&#34; target=&#34;_blank&#34;&gt;https://www.biorxiv.org/content/early/2018/12/28/507202&lt;/a&gt; and &lt;a href=&#34;https://www.biorxiv.org/content/early/2018/12/27/507327&#34; target=&#34;_blank&#34;&gt;https://www.biorxiv.org/content/early/2018/12/27/507327&lt;/a&gt;.&lt;br /&gt;
The work was done in &lt;a href=&#34;http://railab.org/people.html&#34; target=&#34;_blank&#34;&gt;Kunal Rai&amp;rsquo;s lab&lt;/a&gt; where I had a chance to play with large amount of ChIP-seq data sets. My &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/project/snakemake-pipelines/&#34; target=&#34;_blank&#34;&gt;Snakemake pipeline&lt;/a&gt; is being used in the lab by others and has processed thousands of ChIP-seq data sets.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;My three &lt;a href=&#34;https://github.com/crazyhottommy&#34; target=&#34;_blank&#34;&gt;most stared github repos&lt;/a&gt; were cited in a paper &lt;a href=&#34;https://www.frontiersin.org/articles/10.3389/fbioe.2018.00198/full&#34; target=&#34;_blank&#34;&gt;GitHub Statistics as a Measure of the Impact of Open-Source Bioinformatics Software&lt;/a&gt; by &lt;a href=&#34;https://medschool.vcu.edu/expertise/detail.html?id=mdozmorov&#34; target=&#34;_blank&#34;&gt;Mikhail G. Dozmorov&lt;/a&gt;. The table summarizing the popular github repos can be found at &lt;a href=&#34;https://github.com/mdozmorov/bioinformatics-impact/blob/master/tables/table_1.md&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;I joined Harvard FAS Informatics as a bioinformatics scientist in October and started working on single-cell RNAseq with &lt;a href=&#34;https://www.dulaclab.com/&#34; target=&#34;_blank&#34;&gt;Dulac lab&lt;/a&gt; and will have a chance to play with other single molecule transcriptome data generated from &lt;a href=&#34;http://zhuang.harvard.edu/&#34; target=&#34;_blank&#34;&gt;Xiaowei Zhuang&amp;rsquo;s lab&lt;/a&gt;. I am really excited about learning more!&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;I have my green card approved. This is important so I can work in the US without worrying about my visa status. Thanks to my previous postdoc adviser &lt;a href=&#34;https://www.jax.org/research-and-faculty/faculty/roel-verhaak&#34; target=&#34;_blank&#34;&gt;Roel Verhaak&lt;/a&gt;, &lt;a href=&#34;http://pinellolab.org/&#34; target=&#34;_blank&#34;&gt;Luca Pinello&lt;/a&gt;, &lt;a href=&#34;https://www.ialbert.me/&#34; target=&#34;_blank&#34;&gt;Istvan Albert&lt;/a&gt;,  &lt;a href=&#34;https://blogs.cornell.edu/sethupathylab/&#34; target=&#34;_blank&#34;&gt;Praveen Sethupathy&lt;/a&gt; and &lt;a href=&#34;https://medicine.iu.edu/faculty/14584/cheng-liang/&#34; target=&#34;_blank&#34;&gt;Liang Cheng&lt;/a&gt; for writing recommendation letters. I will need to visit Luca&amp;rsquo;s lab to say thanks personally, I have not had a chance to meet him after I moved to Harvard.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;I finally got a chance to write an R package. It is now in github private repo and works. I implemented some functions for visualizing single cell data and evaluating cluster stability. I will make it public once I clean up a bit. I was so satisfied to have it installed by &lt;code&gt;devtools::install_github()&lt;/code&gt; and all functions and help pages are readily available as a package. I mean I am gradually transiting myself from an R user to R programmer. I know I still have a lot to learn, but this is exciting! By the way, I highly recommend the &lt;a href=&#34;https://github.com/r-lib/usethis&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;usethis&lt;/code&gt;&lt;/a&gt; package for writing R packages and read the &lt;a href=&#34;http://r-pkgs.had.co.nz/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;R pacakges book&lt;/code&gt;&lt;/a&gt; by Hadley Wickham. read &lt;a href=&#34;https://blog.methodsconsultants.com/posts/developing-r-packages-using-gitlab-ci-part-i/&#34; target=&#34;_blank&#34;&gt;this&lt;/a&gt; and &lt;a href=&#34;https://www.hvitfeldt.me/blog/usethis-workflow-for-package-development/&#34; target=&#34;_blank&#34;&gt;this&lt;/a&gt; blog post to get started on how to write a minimal functional R package.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;what-to-expect-in-2019&#34;&gt;What to expect in 2019&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;I will have a lot of opportunities to teach workshops on R, Unix and single-cell RNAseq at my current position.&lt;/li&gt;
&lt;li&gt;A lot to learn on neuroscience. I will audit classes taught by Catherine Dulac.&lt;/li&gt;
&lt;li&gt;I will guest lecture a few lessons for &lt;a href=&#34;https://canvas.harvard.edu/courses/39391&#34; target=&#34;_blank&#34;&gt;STAT 115: Introduction to Computational Biology and Bioinformatics&lt;/a&gt; taught by &lt;a href=&#34;http://liulab.dfci.harvard.edu/&#34; target=&#34;_blank&#34;&gt;Sheirly Liu&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;I would love to learn more on deep learning and apply it to single cell data analysis. Currently, I am taking classes from Coursera.&lt;/li&gt;
&lt;li&gt;Attend several conferences. Would love to catch up with the twitter-verse in person.&lt;/li&gt;
&lt;li&gt;A few more papers to write. I have at least 2 first author papers to finish. It&amp;rsquo;s hanging there forever.&lt;/li&gt;
&lt;li&gt;Of course, spend time with the family.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A tale of two heatmap functions</title>
      <link>/post/a-tale-of-two-heatmap-functions/</link>
      <pubDate>Wed, 19 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/a-tale-of-two-heatmap-functions/</guid>
      <description>&lt;p&gt;You probably do not understand heatmap! Please read &lt;a href=&#34;http://www.opiniomics.org/you-probably-dont-understand-heatmaps/&#34;&gt;You probably don’t understand heatmaps by Mick Watson&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In the blog post, Mick used &lt;code&gt;heatmap&lt;/code&gt; function in the &lt;code&gt;stats&lt;/code&gt; package, I will try to walk you through comparing &lt;code&gt;heatmap&lt;/code&gt;, and &lt;code&gt;heatmap.2&lt;/code&gt; from &lt;code&gt;gplots&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;Before I start, I want to quote this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“The defaults of almost every heat map function in R does the hierarchical clustering first, then scales the rows then displays the image”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;see these two posts in biostar: &lt;a href=&#34;https://www.biostars.org/p/85527/&#34;&gt;post1&lt;/a&gt;&lt;br /&gt;
and &lt;a href=&#34;https://www.biostars.org/p/15285/&#34;&gt;post2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In other words, the &lt;code&gt;scale&lt;/code&gt; parameter inside the &lt;code&gt;heatmap&lt;/code&gt; functions only plays a role in displaying the colors, but does not involve clustering. This is critical to know! We will test to see if this hold true.&lt;/p&gt;
&lt;div id=&#34;heatmap-function-in-stats-package&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;heatmap function in stats package&lt;/h3&gt;
&lt;p&gt;Simulate the data. The example is exactly the same as in the Mick Watson’s blog post.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(stats)
library(gplots)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;gplots&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &amp;#39;package:stats&amp;#39;:
## 
##     lowess&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;h1 &amp;lt;- c(10,20,10,20,10,20,10,20)
h2 &amp;lt;- c(20,10,20,10,20,10,20,10)

l1 &amp;lt;- c(1,3,1,3,1,3,1,3)
l2 &amp;lt;- c(3,1,3,1,3,1,3,1)

mat &amp;lt;- rbind(h1,h2,l1,l2)

par(mfrow =c(1,1), mar=c(4,4,1,1))
plot(1:8,rep(0,8), ylim=c(0,35), pch=&amp;quot;&amp;quot;, xlab=&amp;quot;Time&amp;quot;, ylab=&amp;quot;Gene Expression&amp;quot;)

for (i in 1:nrow(mat)) {
lines(1:8,mat[i,], lwd=3, col=i)
}

legend(1,35,rownames(mat), 1:4, cex=0.7)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-19-a-tale-of-two-heatmap-functions_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In this dummy example, we have four genes (l1, l2, h1, h2) that are measured in 8 time points.&lt;/p&gt;
&lt;p&gt;when we do clustering, we want to cluster l1 h1 together, and l2 h2 together as they have the same trend across the time points. However, you will notice that the scale of the expression levels of these four genes are different: with h1 and h2 are high, and l1 l2 are low.&lt;/p&gt;
&lt;p&gt;If we calculate the distance:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#?dist to see other distance measures
dist(mat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           h1        h2        l1
## h2 28.284271                    
## l1 38.470768 40.496913          
## l2 40.496913 38.470768  5.656854&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## I will use the default for linkage method: complete
plot(hclust(dist(mat)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-19-a-tale-of-two-heatmap-functions_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The default distance measure is &lt;a href=&#34;https://en.wikipedia.org/wiki/Euclidean_distance&#34;&gt;Eucledian distance&lt;/a&gt;, and you will see h1 and h2 are closer (28.284271), l1 and l2 are closer. This simply because how euclidean distance is defined.&lt;/p&gt;
&lt;p&gt;Let’s check the help for &lt;code&gt;?heatmap&lt;/code&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;scale character indicating if the values should be centered and scaled in either the row direction or the column direction, or none. The default is “row” if symm false, and “none” otherwise.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;symm
logical indicating if x should be treated symmetrically; can only be true when x is a square matrix.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;So the default is scale row inside the &lt;code&gt;heatmap&lt;/code&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## default, I will give parameters explicitly
heatmap(mat, Colv=NA, col=greenred(10), scale = &amp;quot;row&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-19-a-tale-of-two-heatmap-functions_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We do see h1,h2 cluster together; l1 l2 cluster together. Inside heatmap function, the default distance measure is the same as default of &lt;code&gt;dist&lt;/code&gt;, the linkage method is the same as &lt;code&gt;hclust&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If you read the heatmap carefully, you will find that h1,h2 are with large values, but they have the same red color as l1,l2. &lt;strong&gt;This confirms that heatmap does clustering first, and then scale the row for representing the color!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;How about if we turn off scale inside &lt;code&gt;heatmap&lt;/code&gt;?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heatmap(mat, Colv = NA, col=greenred(10), scale = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-19-a-tale-of-two-heatmap-functions_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You will see the &lt;strong&gt;clustering does not change, but the color changed!&lt;/strong&gt; l1 and l2 are all green now (small values)&lt;/p&gt;
&lt;p&gt;How about if we scale the genes before we feed into heatmap? scale works on columns, transpose for rows.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mat.scaled&amp;lt;- t(scale(t(mat), center=TRUE, scale = TRUE))
mat.scaled&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          [,1]       [,2]       [,3]       [,4]       [,5]       [,6]
## h1 -0.9354143  0.9354143 -0.9354143  0.9354143 -0.9354143  0.9354143
## h2  0.9354143 -0.9354143  0.9354143 -0.9354143  0.9354143 -0.9354143
## l1 -0.9354143  0.9354143 -0.9354143  0.9354143 -0.9354143  0.9354143
## l2  0.9354143 -0.9354143  0.9354143 -0.9354143  0.9354143 -0.9354143
##          [,7]       [,8]
## h1 -0.9354143  0.9354143
## h2  0.9354143 -0.9354143
## l1 -0.9354143  0.9354143
## l2  0.9354143 -0.9354143
## attr(,&amp;quot;scaled:center&amp;quot;)
## h1 h2 l1 l2 
## 15 15  2  2 
## attr(,&amp;quot;scaled:scale&amp;quot;)
##       h1       h2       l1       l2 
## 5.345225 5.345225 1.069045 1.069045&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s see how the distance change among genes:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dist(mat.scaled)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          h1       h2       l1
## h2 5.291503                  
## l1 0.000000 5.291503         
## l2 5.291503 0.000000 5.291503&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(hclust(dist(mat.scaled)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-19-a-tale-of-two-heatmap-functions_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Wow! h1 and l1 are clustered together; l2 and h2 are clustered together.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heatmap(mat.scaled, Colv = NA, col=greenred(10), scale = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-19-a-tale-of-two-heatmap-functions_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I hope you understand now how scale the data &lt;strong&gt;before or after&lt;/strong&gt; can affect the looking of your heatmaps.&lt;/p&gt;
&lt;p&gt;If we do not scale the data beforehand, but we still want l1 and h1 cluster together; l2 and h2 cluster together, we can use a different distance measure.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## correlation among the genes
cor(t(mat))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    h1 h2 l1 l2
## h1  1 -1  1 -1
## h2 -1  1 -1  1
## l1  1 -1  1 -1
## l2 -1  1 -1  1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## 1- correation to define the distance
1- cor(t(mat))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    h1 h2 l1 l2
## h1  0  2  0  2
## h2  2  0  2  0
## l1  0  2  0  2
## l2  2  0  2  0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hc &amp;lt;- hclust(as.dist(1-cor(t(mat))))
plot(hc)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-19-a-tale-of-two-heatmap-functions_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Indeed, h1 and l1 are together; h2 and l2 are together.&lt;/p&gt;
&lt;p&gt;Now, we plot the heatmap, but set scale = “none” inside heatmap&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heatmap(mat, Colv = NA, Rowv=as.dendrogram(hc), col=greenred(10), scale = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-19-a-tale-of-two-heatmap-functions_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Is this what you expect?! Yes, l1 and h2 are clustered together; l1 and h1 clustered together. but because the value range are different, you see l1 and l2 are green (small values); h1 and h2 are red (big values).&lt;/p&gt;
&lt;p&gt;The magic will happen if we set scale =“row” which is the default:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heatmap(mat, Colv = NA, Rowv=as.dendrogram(hc), col=greenred(10), scale = &amp;quot;row&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-19-a-tale-of-two-heatmap-functions_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I hope I have clarified a bit for the complications of heatmaps.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;heatmap.2-function-in-gplots-package&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;heatmap.2 function in gplots package&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;scale character indicating if the values should be centered and scaled in either the row direction or the column direction, or none. The default is “none”.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;The default is none!!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Please also pay attention to the Color Key of the heatmap.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## defaults of heatmap.2, scale is none
heatmap.2(mat, trace = &amp;quot;none&amp;quot;, Colv= NA, dendrogram = &amp;quot;row&amp;quot;, scale = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-19-a-tale-of-two-heatmap-functions_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## FACT of heatmap functions in R: it does clustering first and then use the scale argument (if set) to represent the data.
heatmap.2(mat, trace = &amp;quot;none&amp;quot;, Colv= NA, dendrogram = &amp;quot;row&amp;quot;, scale = &amp;quot;row&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-19-a-tale-of-two-heatmap-functions_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;how about we scale the data explicitly first and use euclidean distance. works fine!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heatmap.2(t(scale(t(mat), center=TRUE, scale=TRUE)), trace = &amp;quot;none&amp;quot;, Colv= NA, dendrogram = &amp;quot;row&amp;quot;, scale = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-19-a-tale-of-two-heatmap-functions_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;use-1--corx-as-distance-and-do-not-scale-before-hand&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;use 1- cor(x) as distance and do not scale before hand&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heatmap.2(mat, trace = &amp;quot;none&amp;quot;, 
          Colv= NA, dendrogram = &amp;quot;row&amp;quot;,
          scale = &amp;quot;none&amp;quot;,
          hclust=function(x) hclust(x, method=&amp;#39;complete&amp;#39;), distfun=function(x) as.dist(1-cor(t(x))))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-19-a-tale-of-two-heatmap-functions_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;use-1--corx-as-distance-and-do-not-scale-before-hand-but-use-scale-in-the-heatmap.2-function-to-represent-the-colors&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;use 1- cor(x) as distance and do not scale before hand, but use scale in the heatmap.2 function to represent the colors&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heatmap.2(mat, trace = &amp;quot;none&amp;quot;, 
          Colv= NA, dendrogram = &amp;quot;row&amp;quot;,
          scale = &amp;quot;row&amp;quot;,
          hclust=function(x) hclust(x, method=&amp;#39;complete&amp;#39;), distfun=function(x) as.dist(1-cor(t(x))))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-19-a-tale-of-two-heatmap-functions_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;scale-before-hand-and-use-1--corx-as-distance&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;scale before hand and use 1- cor(x) as distance&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heatmap.2(t(scale(t(mat), center=TRUE, scale=TRUE)), trace = &amp;quot;none&amp;quot;, 
          Colv= NA, dendrogram = &amp;quot;row&amp;quot;,
          hclust=function(x) hclust(x, method=&amp;#39;complete&amp;#39;), distfun=function(x) as.dist(1-cor(t(x))))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-19-a-tale-of-two-heatmap-functions_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Note that the dendrogram can be rotated and without changing the clustering. Check &lt;a href=&#34;https://cran.r-project.org/web/packages/dendsort/index.html&#34;&gt;Dendersort&lt;/a&gt; if you want to specify the order of the dendrogram.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://jokergoo.github.io/ComplexHeatmap-reference/book/&#34;&gt;ComplexHeatmap&lt;/a&gt; package which now I am using mainly &lt;strong&gt;does not&lt;/strong&gt; do any scaling inside the Heatmap function.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;take-home-messages&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Take home messages&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Generate heatmap is easy, but make sure to understand the parameters in each heatmap function.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Understand your data and what you are looking for. Do you need to scale your data before clustering?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Distance measure and linkage method can drastically affect your clustering. Choose the right one for your data!. Please also read my &lt;a href=&#34;https://rpubs.com/crazyhottommy/heatmap_demystified&#34;&gt;last post&lt;/a&gt; on this theme.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>PCA in action</title>
      <link>/post/pca-in-action/</link>
      <pubDate>Tue, 18 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/pca-in-action/</guid>
      <description>&lt;div id=&#34;pca-in-practice.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;PCA in practice.&lt;/h3&gt;
&lt;p&gt;Principle Component Analysis(PCA) is a very important skill for dimention reduction to analyze high-dimentional data. High-dimentional data are data with features (p) a lot more than observations (n). This types of data are very commonly generated from high-throuput sequencing experiments. For example, an RNA-seq or microarry experiment measures expression of tens of thousands of genes for only 8 samples (4 controls and 4 treatments).&lt;/p&gt;
&lt;p&gt;Let’s use a microarray data for demonstration. One thing to note is that in linear algebra, a matrix is coded as &lt;code&gt;n (rows are observations) X p (columns are features)&lt;/code&gt;.However, in the microarray/RNA-seq case, the matrix is represented as &lt;code&gt;p (rows are features/genes) X n (columns are observations/samples)&lt;/code&gt;. That’s why we need to transpose the matrix before feeding the matrix to &lt;code&gt;prcomp&lt;/code&gt; or &lt;code&gt;SVD&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ISLR)

# transpose the data
ncidat&amp;lt;- t(NCI60$data)
colnames(ncidat)&amp;lt;- NCI60$labs

dim(ncidat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 6830   64&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## it is a data matrix with 64 columns (different tissues) and 6830 rows (genes)
ncidat[1:6,1:6]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      CNS      CNS    CNS         RENAL BREAST    CNS
## 1  0.300 0.679961  0.940  2.800000e-01  0.485  0.310
## 2  1.180 1.289961 -0.040 -3.100000e-01 -0.465 -0.030
## 3  0.550 0.169961 -0.170  6.800000e-01  0.395 -0.100
## 4  1.140 0.379961 -0.040 -8.100000e-01  0.905 -0.460
## 5 -0.265 0.464961 -0.605  6.250000e-01  0.200 -0.205
## 6 -0.070 0.579961  0.000 -1.387779e-17 -0.005 -0.540&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;use-prcomp&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Use prcomp&lt;/h3&gt;
&lt;p&gt;The default R package stats comes with function &lt;code&gt;prcomp()&lt;/code&gt; to perform principal component analysis. This means that we don’t need to install anything (although there are other options using external packages).&lt;/p&gt;
&lt;p&gt;We take the transpose of ncidat because &lt;strong&gt;&lt;code&gt;prcomp&lt;/code&gt; assumes: units/samples in row and features (genes) in columns&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## please look at the help page to see the meanings of  center and scale. parameters.
## center and scale can affect the result a lot. Usually we center the data.

pca_prcomp&amp;lt;- prcomp(t(ncidat), center = TRUE, scale. = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How much variantion is explained by each component:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(pca_prcomp)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-18-pca-in-action_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(pca_prcomp)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Importance of components:
##                            PC1      PC2      PC3      PC4      PC5
## Standard deviation     25.1638 18.78637 16.73078 13.53082 12.78895
## Proportion of Variance  0.1489  0.08301  0.06584  0.04306  0.03847
## Cumulative Proportion   0.1489  0.23194  0.29777  0.34083  0.37930
##                             PC6      PC7      PC8      PC9    PC10   PC11
## Standard deviation     12.21052 11.05840 10.94492 10.59140 9.57657 9.4493
## Proportion of Variance  0.03507  0.02876  0.02817  0.02638 0.02157 0.0210
## Cumulative Proportion   0.41437  0.44313  0.47130  0.49769 0.51926 0.5403
##                           PC12   PC13    PC14    PC15   PC16    PC17
## Standard deviation     9.22659 8.8220 8.66863 8.43185 8.2746 8.19031
## Proportion of Variance 0.02002 0.0183 0.01767 0.01672 0.0161 0.01578
## Cumulative Proportion  0.56028 0.5786 0.59626 0.61298 0.6291 0.64486
##                           PC18    PC19    PC20    PC21    PC22   PC23
## Standard deviation     7.86272 7.84561 7.74753 7.64167 7.41462 7.3207
## Proportion of Variance 0.01454 0.01448 0.01412 0.01373 0.01293 0.0126
## Cumulative Proportion  0.65940 0.67388 0.68799 0.70173 0.71466 0.7273
##                           PC24   PC25    PC26    PC27   PC28    PC29
## Standard deviation     7.09512 7.0817 6.86791 6.71857 6.6190 6.57295
## Proportion of Variance 0.01184 0.0118 0.01109 0.01062 0.0103 0.01016
## Cumulative Proportion  0.73910 0.7509 0.76199 0.77261 0.7829 0.79307
##                           PC30    PC31    PC32    PC33    PC34    PC35
## Standard deviation     6.50142 6.38411 6.31688 6.10274 6.07004 5.96433
## Proportion of Variance 0.00994 0.00959 0.00938 0.00876 0.00867 0.00837
## Cumulative Proportion  0.80302 0.81260 0.82199 0.83075 0.83941 0.84778
##                           PC36    PC37    PC38    PC39    PC40   PC41
## Standard deviation     5.93322 5.87286 5.82866 5.67923 5.63268 5.5707
## Proportion of Variance 0.00828 0.00811 0.00799 0.00759 0.00746 0.0073
## Cumulative Proportion  0.85606 0.86417 0.87216 0.87975 0.88721 0.8945
##                           PC42   PC43    PC44    PC45   PC46    PC47
## Standard deviation     5.51265 5.4555 5.37942 5.32142 5.1743 5.14470
## Proportion of Variance 0.00715 0.0070 0.00681 0.00666 0.0063 0.00623
## Cumulative Proportion  0.90165 0.9086 0.91546 0.92212 0.9284 0.93464
##                           PC48    PC49    PC50    PC51   PC52    PC53
## Standard deviation     5.01790 4.82436 4.77879 4.69168 4.5637 4.49039
## Proportion of Variance 0.00592 0.00547 0.00537 0.00518 0.0049 0.00474
## Cumulative Proportion  0.94057 0.94604 0.95141 0.95659 0.9615 0.96623
##                           PC54   PC55    PC56    PC57    PC58    PC59
## Standard deviation     4.41142 4.2741 4.21355 4.08613 3.91956 3.78810
## Proportion of Variance 0.00458 0.0043 0.00418 0.00393 0.00361 0.00337
## Cumulative Proportion  0.97081 0.9751 0.97928 0.98320 0.98682 0.99019
##                           PC60    PC61    PC62   PC63      PC64
## Standard deviation     3.52405 3.22882 3.15278 2.9856 1.341e-14
## Proportion of Variance 0.00292 0.00245 0.00234 0.0021 0.000e+00
## Cumulative Proportion  0.99311 0.99557 0.99790 1.0000 1.000e+00&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#sdev refers to the standard deviation of principal components.
pca_prcomp$sdev&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 2.516378e+01 1.878637e+01 1.673078e+01 1.353082e+01 1.278895e+01
##  [6] 1.221052e+01 1.105840e+01 1.094492e+01 1.059140e+01 9.576574e+00
## [11] 9.449313e+00 9.226590e+00 8.821954e+00 8.668634e+00 8.431849e+00
## [16] 8.274578e+00 8.190308e+00 7.862721e+00 7.845612e+00 7.747529e+00
## [21] 7.641665e+00 7.414624e+00 7.320674e+00 7.095120e+00 7.081674e+00
## [26] 6.867907e+00 6.718573e+00 6.618968e+00 6.572955e+00 6.501420e+00
## [31] 6.384107e+00 6.316878e+00 6.102743e+00 6.070035e+00 5.964333e+00
## [36] 5.933221e+00 5.872856e+00 5.828663e+00 5.679232e+00 5.632684e+00
## [41] 5.570718e+00 5.512649e+00 5.455510e+00 5.379416e+00 5.321422e+00
## [46] 5.174272e+00 5.144699e+00 5.017899e+00 4.824356e+00 4.778789e+00
## [51] 4.691679e+00 4.563740e+00 4.490394e+00 4.411423e+00 4.274070e+00
## [56] 4.213548e+00 4.086132e+00 3.919560e+00 3.788098e+00 3.524054e+00
## [61] 3.228818e+00 3.152782e+00 2.985601e+00 1.341106e-14&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## variance explained by each PC cumulatively
cumsum(pca_prcomp$sdev^2)/sum(pca_prcomp$sdev^2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 0.1489294 0.2319364 0.2977720 0.3408323 0.3793002 0.4143671 0.4431287
##  [8] 0.4713030 0.4976867 0.5192567 0.5402571 0.5602793 0.5785838 0.5962576
## [15] 0.6129791 0.6290826 0.6448598 0.6594001 0.6738773 0.6879947 0.7017289
## [22] 0.7146592 0.7272638 0.7391037 0.7508988 0.7619925 0.7726091 0.7829132
## [29] 0.7930745 0.8030158 0.8126016 0.8219866 0.8307461 0.8394120 0.8477786
## [36] 0.8560582 0.8641702 0.8721606 0.8797465 0.8872086 0.8945074 0.9016548
## [43] 0.9086548 0.9154609 0.9221211 0.9284180 0.9346431 0.9405652 0.9460392
## [50] 0.9514103 0.9565874 0.9614860 0.9662284 0.9708055 0.9751019 0.9792776
## [57] 0.9832045 0.9868178 0.9901928 0.9931137 0.9955657 0.9979035 1.0000000
## [64] 1.0000000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;what’s in the prca_prcomp object&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;names(pca_prcomp)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;sdev&amp;quot;     &amp;quot;rotation&amp;quot; &amp;quot;center&amp;quot;   &amp;quot;scale&amp;quot;    &amp;quot;x&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## the first two PCs for the first 6 tissues
head(pca_prcomp$x[,1:2])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              PC1         PC2
## CNS    -19.79578   0.1152691
## CNS    -21.54610  -1.4573503
## CNS    -25.05662   1.5260929
## RENAL  -37.40954 -11.3894784
## BREAST -50.21864  -1.3461737
## CNS    -26.43520   0.4629819&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;PC1_and_PC2&amp;lt;- data.frame(PC1=pca_prcomp$x[,1], PC2= pca_prcomp$x[,2], type = rownames(pca_prcomp$x))

## plot PCA plot
library(ggplot2)
ggplot(PC1_and_PC2, aes(x=PC1, y=PC2, col=type)) + geom_point() + geom_text(aes(label = type), hjust=0, vjust=0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-18-pca-in-action_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#This returns each principal components loadings
pca_prcomp$rotation[1:6, 1:6]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            PC1           PC2         PC3          PC4          PC5
## 1 -0.005096247  0.0009839929 0.002116058  0.007628801 -0.012118316
## 2 -0.001642354  0.0034355664 0.008049350  0.004910196 -0.007412249
## 3 -0.002509243 -0.0015838271 0.004746350  0.008769557 -0.012426296
## 4  0.004940063  0.0078435347 0.013716214  0.011378816 -0.014851587
## 5 -0.003365039 -0.0002680479 0.010677453 -0.005249648 -0.003317312
## 6  0.001382038 -0.0034431320 0.003167842  0.007425971 -0.002879251
##             PC6
## 1  0.0061392242
## 2  0.0114429879
## 3 -0.0002860562
## 4 -0.0065009935
## 5 -0.0003513787
## 6  0.0003210365&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;use-singluar-value-decomposition&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Use singluar value decomposition&lt;/h3&gt;
&lt;p&gt;in a svd analysis, a matrix n x p matrix X is decomposed by &lt;code&gt;X = U*D*V&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;1.U is an m×n orthogonal matrix.&lt;br /&gt;
2.V is an n×n orthogonal matrix.&lt;br /&gt;
3.D is an n×n diagonal matrix.&lt;/p&gt;
&lt;p&gt;PCs: &lt;strong&gt;Z = XV or Z = UD (U are un-scaled PCs)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Some facts of PCA:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;k th column of Z, Z(k), is the k th PC.(the k th pattern)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;PC loadings: V k th column of V, V(k) is the k th PC loading (feature weights). aka. &lt;strong&gt;the k th column of V encodes the associated k th pattern in feature space.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;PC loadings: U k th column of U, U(k) is the k th PC loading (observation weights). aka. &lt;strong&gt;the k th column of U encodes the associated k th pattern in observation space.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Diagnal matrix: D diagnals in D: &lt;strong&gt;d(k) gives the strength of the k th pattern.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Variance explained by k th PC: d(k)^2 Total variance of the data: &lt;code&gt;sum(d(k1)^2 + d(k2)^2 + …..d(k)^2+….)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;proportion of variane explained by k th PC: &lt;code&gt;d(k)^2 / sum(d(k1)^2 + d(k2)^2 + …..d(k)^2+….)&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X&amp;lt;- t(scale(t(ncidat),center=TRUE,scale=FALSE))
# we transpose X again for svd
# usually there is no need to transpose the matrix and then transpose it back, but svd was written that rows are observations and columns are 
# features.however, most genomic data represent observations (e.g. samples) in columns and features (e.g. genes) in columns.

sv&amp;lt;- svd(t(X))
U&amp;lt;- sv$u
V&amp;lt;- sv$v
D&amp;lt;- sv$d


## U are un-scaled PC, Z is scaled
Z&amp;lt;- t(X)%*%V

## PCs
Z[1:6, 1:6]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             [,1]        [,2]       [,3]      [,4]       [,5]     [,6]
## CNS    -19.79578   0.1152691  -5.968917  4.753293  -4.882164 18.92591
## CNS    -21.54610  -1.4573503  -9.019584  6.767942  -2.247604 17.07273
## CNS    -25.05662   1.5260929  -6.959653  2.785913 -10.819648 16.45389
## RENAL  -37.40954 -11.3894784  -5.407097 15.442094 -16.011475 33.09651
## BREAST -50.21864  -1.3461737 -17.599944 15.099862 -13.852847 16.94340
## CNS    -26.43520   0.4629819 -16.931456 11.389195  -6.742920 11.85838&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## is the same as
pca_prcomp$x[1:6, 1:6]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              PC1         PC2        PC3       PC4        PC5      PC6
## CNS    -19.79578   0.1152691  -5.968917  4.753293  -4.882164 18.92591
## CNS    -21.54610  -1.4573503  -9.019584  6.767942  -2.247604 17.07273
## CNS    -25.05662   1.5260929  -6.959653  2.785913 -10.819648 16.45389
## RENAL  -37.40954 -11.3894784  -5.407097 15.442094 -16.011475 33.09651
## BREAST -50.21864  -1.3461737 -17.599944 15.099862 -13.852847 16.94340
## CNS    -26.43520   0.4629819 -16.931456 11.389195  -6.742920 11.85838&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## PC loadings
V[1:6, 1:6]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              [,1]          [,2]        [,3]         [,4]         [,5]
## [1,] -0.005096247  0.0009839929 0.002116058  0.007628801 -0.012118316
## [2,] -0.001642354  0.0034355664 0.008049350  0.004910196 -0.007412249
## [3,] -0.002509243 -0.0015838271 0.004746350  0.008769557 -0.012426296
## [4,]  0.004940063  0.0078435347 0.013716214  0.011378816 -0.014851587
## [5,] -0.003365039 -0.0002680479 0.010677453 -0.005249648 -0.003317312
## [6,]  0.001382038 -0.0034431320 0.003167842  0.007425971 -0.002879251
##               [,6]
## [1,]  0.0061392242
## [2,]  0.0114429879
## [3,] -0.0002860562
## [4,] -0.0065009935
## [5,] -0.0003513787
## [6,]  0.0003210365&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## is the same as 
pca_prcomp$rotation[1:6, 1:6]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            PC1           PC2         PC3          PC4          PC5
## 1 -0.005096247  0.0009839929 0.002116058  0.007628801 -0.012118316
## 2 -0.001642354  0.0034355664 0.008049350  0.004910196 -0.007412249
## 3 -0.002509243 -0.0015838271 0.004746350  0.008769557 -0.012426296
## 4  0.004940063  0.0078435347 0.013716214  0.011378816 -0.014851587
## 5 -0.003365039 -0.0002680479 0.010677453 -0.005249648 -0.003317312
## 6  0.001382038 -0.0034431320 0.003167842  0.007425971 -0.002879251
##             PC6
## 1  0.0061392242
## 2  0.0114429879
## 3 -0.0002860562
## 4 -0.0065009935
## 5 -0.0003513787
## 6  0.0003210365&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# plot PC1 vs PC2

pc_dat&amp;lt;- data.frame(type = rownames(Z), PC1 = Z[,1], PC2= Z[,2])
ggplot(pc_dat,aes(x=PC1, y=PC2, col=type)) + geom_point() + geom_text(aes(label = type), hjust=0, vjust=0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-18-pca-in-action_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We get the same results as from the &lt;code&gt;prcomp&lt;/code&gt; function.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;variance-explained-for-each-pc&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Variance explained for each PC&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;varex = 0
cumvar = 0
denom = sum(D^2)
for(i in 1:length(D)){
  varex[i] = D[i]^2/denom
  cumvar[i] = sum(D[1:i]^2)/denom
}

## variance explained by each PC cumulatively
cumvar&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 0.1489294 0.2319364 0.2977720 0.3408323 0.3793002 0.4143671 0.4431287
##  [8] 0.4713030 0.4976867 0.5192567 0.5402571 0.5602793 0.5785838 0.5962576
## [15] 0.6129791 0.6290826 0.6448598 0.6594001 0.6738773 0.6879947 0.7017289
## [22] 0.7146592 0.7272638 0.7391037 0.7508988 0.7619925 0.7726091 0.7829132
## [29] 0.7930745 0.8030158 0.8126016 0.8219866 0.8307461 0.8394120 0.8477786
## [36] 0.8560582 0.8641702 0.8721606 0.8797465 0.8872086 0.8945074 0.9016548
## [43] 0.9086548 0.9154609 0.9221211 0.9284180 0.9346431 0.9405652 0.9460392
## [50] 0.9514103 0.9565874 0.9614860 0.9662284 0.9708055 0.9751019 0.9792776
## [57] 0.9832045 0.9868178 0.9901928 0.9931137 0.9955657 0.9979035 1.0000000
## [64] 1.0000000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is the same as the result of &lt;code&gt;cumsum(pca_prcomp$sdev^2)/sum(pca_prcomp$sdev^2)&lt;/code&gt; above.&lt;/p&gt;
&lt;p&gt;Screeplot&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(mfrow=c(1,2))
plot(1:length(D),varex,type=&amp;quot;l&amp;quot;,lwd=2,xlab=&amp;quot;PC&amp;quot;,ylab=&amp;quot;% Variance Explained&amp;quot;)
plot(1:length(D),cumvar,type=&amp;quot;l&amp;quot;,lwd=2,xlab=&amp;quot;PC&amp;quot;,ylab=&amp;quot;Cummulative Variance Explained&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-12-18-pca-in-action_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Merge featureCount table from RNAseq</title>
      <link>/post/merge-featurecount-table-from-rnaseq/</link>
      <pubDate>Tue, 27 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/merge-featurecount-table-from-rnaseq/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;http://bioinf.wehi.edu.au/featureCounts/&#34; target=&#34;_blank&#34;&gt;featureCounts&lt;/a&gt; is a program to fast summarize counts from sequencing data. I use it to get gene-level RNAseq counts by&lt;/p&gt;

&lt;p&gt;&lt;code&gt;featureCounts -p -t exon -g gene_id -a annotation.gtf -o mysample_featureCount.txt mapping_results_PE.bam&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;If you have a lot of samples, you will get a lot of &lt;code&gt;*featureCount.txt&lt;/code&gt; and you will
need to merge them for downstream analysis.&lt;/p&gt;

&lt;p&gt;I will show you how to merge the tables using &lt;code&gt;R&lt;/code&gt;, &lt;code&gt;python&lt;/code&gt; and &lt;code&gt;unix&lt;/code&gt; below.&lt;/p&gt;

&lt;h4 id=&#34;r-solution&#34;&gt;R solution&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(purrr)
library(tidyverse)
f_files&amp;lt;- list.files(&amp;quot;results/superEnhancer/rna_expression/MSTC&amp;quot;, pattern = &amp;quot;featureCount.txt&amp;quot;, full.names = T)

read_in_feature_counts&amp;lt;- function(file){
        cnt&amp;lt;- read_tsv(file, col_names =T, comment = &amp;quot;#&amp;quot;)
        cnt&amp;lt;- cnt %&amp;gt;% dplyr::select(-Chr, -Start, -End, -Strand, -Length)
        return(cnt)
}
        
raw_counts&amp;lt;- map(f_files, read_in_feature_counts)
raw_counts_df&amp;lt;- purrr::reduce(raw_counts, inner_join) 
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;python-solution&#34;&gt;python solution&lt;/h4&gt;

&lt;p&gt;I am still very crude with python :)
It works for python2.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os
import csv
import glob

## after some google https://mail.python.org/pipermail/tutor/2004-November/033475.html
## The idea is to keep the count column into a list.

files = glob.glob(&amp;quot;*featureCount.txt&amp;quot;)
list_column = []
n = 1
for file in files:
    print n
    column_data = []
    with open(file, &#39;r&#39;) as f:
        reader = csv.reader(f, delimiter = &amp;quot;\t&amp;quot;)
            # skip the comment line
        comment = next(reader)
        if n &amp;lt;= 1:
            for row in reader:
                # for the first file, keep the gene column as well
                column_data.append(row[0] + &#39;\t&#39; + row[6])
        else:
            for row in reader:
                column_data.append(row[6])
        n = n + 1
    list_column.append(column_data)


# This creates a list of row lists from the list of column lists
# If any of the column lists are too short they will be padded with None
# map function is a gem :)
rows = map(None, *list_column)

with open(&#39;output.txt&#39;,&#39;w&#39;) as f_out:
     for row in rows:
         f_out.write(&#39;\t&#39;.join(row))
         f_out.write(&#39;\n&#39;)

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;unix-command-line-solution&#34;&gt;unix command line solution&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# get the count
ls -1  *featureCount.txt | parallel &#39;cat {} | sed &#39;1d&#39; | cut -f7 {} &amp;gt; {/.}_clean.txt&#39; 
ls -1  *featureCount.txt | head -1 | xargs cut -f1 &amp;gt; genes.txt
paste genes.txt *featureCount_clean.txt &amp;gt; output.txt

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Three gotchas when using R for Genomic data analysis</title>
      <link>/post/three-gotchas-when-using-r-for-genomic-data-analysis/</link>
      <pubDate>Tue, 27 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/three-gotchas-when-using-r-for-genomic-data-analysis/</guid>
      <description>

&lt;p&gt;During my daily work with R for genomic data analysis, I encountered several instances that R gives me some (bad) surprises.&lt;/p&gt;

&lt;h4 id=&#34;1-the-devil-1-and-0-coordinate-system&#34;&gt;1. The devil 1 and 0 coordinate system&lt;/h4&gt;

&lt;p&gt;read detail here &lt;a href=&#34;https://github.com/crazyhottommy/DNA-seq-analysis#tips-and-lessons-learned-during-my-dna-seq-data-analysis-journey&#34; target=&#34;_blank&#34;&gt;https://github.com/crazyhottommy/DNA-seq-analysis#tips-and-lessons-learned-during-my-dna-seq-data-analysis-journey&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;some files such as &lt;code&gt;bed&lt;/code&gt; file is 0 based. Two genomic regions:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;chr1    0    1000
chr1    1001    2000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;when you import that bed file into R using &lt;code&gt;rtracklayer::import()&lt;/code&gt;, it will become&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;chr1     1    1000
chr1    1000    2000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The function convert it to 1 based internally (R is 1 based unlike python).&lt;/p&gt;

&lt;p&gt;The problem is that when you read the bed file with &lt;code&gt;read.table&lt;/code&gt; and use &lt;code&gt;GenomicRanges::makeGRangesFromDataFrame()&lt;/code&gt; to convert it to a GRanges object, do not forget to add 1 to the start before doing it.&lt;/p&gt;

&lt;p&gt;Similarily, when you write a GRanges object to disk using &lt;code&gt;rtracklayer::export&lt;/code&gt;, you do not need to worry, R will convert it back to 0 based in file.&lt;/p&gt;

&lt;p&gt;However, if you make a dataframe out of the GRanges object, you need to remember do &lt;code&gt;start -1&lt;/code&gt; before writing to a file.&lt;/p&gt;

&lt;h4 id=&#34;2-read-tsv-column-types&#34;&gt;2. &lt;code&gt;read_tsv&lt;/code&gt; column types&lt;/h4&gt;

&lt;p&gt;If you use &lt;code&gt;read_tsv&lt;/code&gt; from &lt;a href=&#34;https://github.com/tidyverse/readr&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;readr&lt;/code&gt;&lt;/a&gt;, it will use the first 1000 rows to determine the column types (integer, charater etc). For genomic data, however, especially for the chromosome column, you may or may not have &lt;code&gt;chr&lt;/code&gt; prepending.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;1    0    1000    
1    1000    2000
.
.
.
X
Y
MT

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;you may fail to read rows for chromosome X, Y and MT. (To make things worse, UCSC uses chrM rather than chrMT&amp;hellip;)&lt;/p&gt;

&lt;p&gt;The solution is that read in all the data as characters.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(readr)
challenge2 &amp;lt;- read_tsv(&amp;quot;my.bed&amp;quot;, 
  col_types = cols(.default = col_character())
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;see &lt;a href=&#34;http://r4ds.had.co.nz/data-import.html&#34; target=&#34;_blank&#34;&gt;http://r4ds.had.co.nz/data-import.html&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;3-scientific-notation-for-genomic-coordinates&#34;&gt;3. Scientific notation for genomic coordinates&lt;/h4&gt;

&lt;p&gt;This is kind of related to 2. &lt;code&gt;1200000&lt;/code&gt; will be written as &lt;code&gt;1.2e6&lt;/code&gt; in a dataframe if R thinks it is an integer. So, you will need to read in the columns all as characters, or if you convert the character to numeric and wants to write to a file,
add &lt;code&gt;options(scipen=500)&lt;/code&gt; on the top of your script.&lt;/p&gt;

&lt;p&gt;The scientific notation can not be disabled in &lt;code&gt;write_csv&lt;/code&gt;: &lt;a href=&#34;https://github.com/tidyverse/readr/issues/671&#34; target=&#34;_blank&#34;&gt;https://github.com/tidyverse/readr/issues/671&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;one-more-gotcha-for-rownames-and-colnames&#34;&gt;One more gotcha for rownames and colnames&lt;/h4&gt;

&lt;p&gt;base R will change the name with &lt;code&gt;-&lt;/code&gt; to a &lt;code&gt;.&lt;/code&gt;. e.g. TCGA-06-ABCD will be changed to TCGA.06.ABCD. this can cause troubles when you use the name of the columns to match samples. &lt;code&gt;readr&lt;/code&gt; will maintain the &lt;code&gt;-&lt;/code&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>open files on remote with sublime by ssh</title>
      <link>/post/open-files-on-remote-with-sublime-by-ssh/</link>
      <pubDate>Wed, 10 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/open-files-on-remote-with-sublime-by-ssh/</guid>
      <description>

&lt;p&gt;I am still suck at &lt;code&gt;vim&lt;/code&gt; or &lt;code&gt;emacs&lt;/code&gt;. I use &lt;code&gt;nano&lt;/code&gt; to edit files on remote machines. But for more complicated editing, I prefer to use sublime.&lt;/p&gt;

&lt;p&gt;use this &lt;a href=&#34;https://github.com/randy3k/RemoteSubl&#34; target=&#34;_blank&#34;&gt;https://github.com/randy3k/RemoteSubl&lt;/a&gt; for editing remote files.&lt;/p&gt;

&lt;p&gt;Steps:&lt;/p&gt;

&lt;h3 id=&#34;on-remote-machine-install-rmate&#34;&gt;on remote machine, install &lt;code&gt;rmate&lt;/code&gt;&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ssh bio1
curl -o ~/bin/rmate https://raw.githubusercontent.com/aurora/rmate/master/rmate

chmod u+x bin/rmate
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;on-your-local-computer-install-remotesubl&#34;&gt;on your local computer, install &lt;code&gt;RemoteSubl&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;on your &lt;strong&gt;local&lt;/strong&gt; computer, open &lt;code&gt;sublime&lt;/code&gt;, click &lt;code&gt;tools&lt;/code&gt; &amp;ndash;&amp;gt; &lt;code&gt;Command Palette&lt;/code&gt; &amp;ndash;&amp;gt; type Package control:Install Package &amp;ndash;&amp;gt; type &lt;code&gt;RemoteSubl&lt;/code&gt; to install.&lt;/p&gt;

&lt;h3 id=&#34;change-your-ssh-config-file&#34;&gt;change your ssh config file&lt;/h3&gt;

&lt;p&gt;add &lt;code&gt;RemoteForward 52698 localhost:52698&lt;/code&gt; to your &lt;code&gt;~/.ssh/config&lt;/code&gt; file.&lt;/p&gt;

&lt;p&gt;Now,  ssh to remote, and you can do &lt;code&gt;rmate my.txt&lt;/code&gt; in your remote and open sublime in your local machine.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>set up odyssey HPC dot files</title>
      <link>/post/set-up-odyssey-hpc-dot-files/</link>
      <pubDate>Tue, 09 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/set-up-odyssey-hpc-dot-files/</guid>
      <description>

&lt;h3 id=&#34;dot-files&#34;&gt;dot files&lt;/h3&gt;

&lt;p&gt;Those files are originally got from &lt;a href=&#34;https://sbamin.com/about&#34; target=&#34;_blank&#34;&gt;Samir Amin&lt;/a&gt;, my labmate in &lt;a href=&#34;https://www.jax.org/research-and-faculty/faculty/roel-verhaak&#34; target=&#34;_blank&#34;&gt;Roel Verhaak&amp;rsquo;s lab&lt;/a&gt;. Thanks for sharing!&lt;/p&gt;

&lt;p&gt;&lt;code&gt;.screenrc&lt;/code&gt;&lt;br /&gt;
&lt;code&gt;.bashrc&lt;/code&gt;&lt;br /&gt;
&lt;code&gt;.bash_profile&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;and inside &lt;code&gt;.profile.d&lt;/code&gt; folder, there is a file named &lt;code&gt;01_odyssey_config.sh&lt;/code&gt;. It was executed when you login the shell.&lt;/p&gt;

&lt;p&gt;You can grab my dot files in my github &lt;a href=&#34;https://github.com/crazyhottommy/odyssey_dot_files&#34; target=&#34;_blank&#34;&gt;repo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Inside the &lt;code&gt;.bash_profile&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;if [ -d $HOME/.profile.d ]; then
  for i in $HOME/.profile.d/*.sh; do
    if [ -r $i ]; then
          if [ &amp;quot;${-#*i}&amp;quot; != &amp;quot;$-&amp;quot; ]; then
            . &amp;quot;$i&amp;quot; &amp;gt;/dev/null 2&amp;gt;&amp;amp;1
        else
            . &amp;quot;$i&amp;quot; &amp;gt;/dev/null 2&amp;gt;&amp;amp;1
        fi
    fi
  done
  unset i
fi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;add or remove path in the &lt;code&gt;01_odyssey_config.sh&lt;/code&gt; file. load modules in this file as well.&lt;/p&gt;

&lt;h3 id=&#34;install-conda&#34;&gt;install conda&lt;/h3&gt;

&lt;p&gt;install conda to my home directory &lt;code&gt;/n/home02/mtang&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;After finishing installing, it will ask&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Do you wish the installer to initialize Anaconda3
in your /n/home02/mtang/.bashrc ? [yes|no]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I chosed &lt;code&gt;no&lt;/code&gt;. It showed me&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;You may wish to edit your /n/home02/mtang/.bashrc to setup Anaconda3:

source /n/home02/mtang/anaconda3/etc/profile.d/conda.sh

Thank you for installing Anaconda3!
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I guess I got why Samir set up the dot files (has a .profile.d folder) like this. &lt;code&gt;conda&lt;/code&gt; is doing similar with &lt;code&gt;source /n/home02/mtang/anaconda3/etc/profile.d/conda.sh&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;add conda to PATH&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;In the &lt;code&gt;~/.profiled.d/01_odyssey_config.sh&lt;/code&gt;, add one line:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;mypathmunge ${HOME}/anaconda3/bin&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;mypathmunge&lt;/code&gt; is a function inside the &lt;code&gt;.bash_profile&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;
mypathmunge () {
    case &amp;quot;:${PATH}:&amp;quot; in
        *:&amp;quot;$1&amp;quot;:*)
            ;;
        *)
            if [ &amp;quot;$2&amp;quot; = &amp;quot;after&amp;quot; ] ; then
                PATH=$PATH:$1
            else
                PATH=$1:$PATH
            fi
    esac
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;it will add the &lt;code&gt;${HOME}/anaconda3/bin&lt;/code&gt; in front of the $PATH. If you want to append it to $PATH, do &lt;code&gt;mypathmunge ${HOME}/anaconda3/bin after&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;source .bash_profile
which conda
~/anaconda3/bin/conda
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A side note. see &lt;a href=&#34;https://apple.stackexchange.com/questions/51036/what-is-the-difference-between-bash-profile-and-bashrc&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; for the difference between &lt;code&gt;.bashrc&lt;/code&gt; and &lt;code&gt;.bash_profile&lt;/code&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;.bash_profile is executed for login shells, while .bashrc is executed for interactive non-login shells.&lt;/p&gt;

&lt;p&gt;When you login (type username and password) via console, either sitting at the machine, or remotely via ssh: .bash_profile is executed to configure your shell before the initial command prompt.&lt;/p&gt;

&lt;p&gt;But, if you’ve already logged into your machine and open a new terminal window (xterm) then .bashrc is executed before the window command prompt. .bashrc is also run when you start a new bash instance by typing /bin/bash in a terminal.&lt;/p&gt;

&lt;p&gt;On OS X, Terminal by default runs a login shell every time, so this is a little different to most other systems, but you can configure that in the preferences.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&#34;http://www.joshstaiger.org/archives/2005/07/bash_profile_vs.html&#34; target=&#34;_blank&#34;&gt;This&lt;/a&gt; is a very helpful blog post to understand the differences.&lt;/p&gt;

&lt;h3 id=&#34;dedicating-a-folder-for-installing-tools&#34;&gt;Dedicating a folder for installing tools&lt;/h3&gt;

&lt;p&gt;usually, install tools with &lt;code&gt;conda&lt;/code&gt;. If there is no recipe in conda. I will downlad the source to &lt;code&gt;~/apps&lt;/code&gt; and compile there.&lt;/p&gt;

&lt;p&gt;Then in the &lt;code&gt;~/.profiled.d/01_odyssey_config.sh&lt;/code&gt; file, add the executable to the PATH.&lt;/p&gt;

&lt;p&gt;e.g. I want to install &lt;code&gt;ncdu&lt;/code&gt; to check disk usage&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir apps
cd apps
mkdir ncdu; cd ncdu
wget https://dev.yorhel.nl/download/ncdu-1.13.tar.gz
tar xvzf  ncdu-1.13.tar.gz
cd ncdu-1.13

./configure --prefix=${HOME}/apps/ncdu/ncdu-1.13
make 
make install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the &lt;code&gt;~/.profiled.d/01_odyssey_config.sh&lt;/code&gt; file, add two lines:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;export ODYAPPS=&amp;quot;${HOME}/apps&lt;/code&gt;&lt;br /&gt;
&lt;code&gt;mypathmunge $ODYPPS/ncdu/ncdu-1.13/bin after&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;source ~/.bash_profile
# now ready to go
ncdu
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Histone deacetylase inhibitor targets CD123/CD47-positive cells and reverse chemoresistance phenotype in acute myeloid leukemia</title>
      <link>/publication/2018-10-05-hdac-inhibitor/</link>
      <pubDate>Fri, 05 Oct 2018 00:00:00 -0400</pubDate>
      
      <guid>/publication/2018-10-05-hdac-inhibitor/</guid>
      <description>&lt;p&gt;More detail can easily be written here using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>set up ssh odyssey HPC</title>
      <link>/post/set-up-ssh-odyssey-hpc/</link>
      <pubDate>Thu, 04 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/set-up-ssh-odyssey-hpc/</guid>
      <description>

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;request an account following &lt;a href=&#34;https://www.rc.fas.harvard.edu/resources/faq/how-do-i-get-a-research-computing-account/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Harvard odyssey HPC requires a two-factor security login. First set up the VPN following &lt;a href=&#34;https://www.rc.fas.harvard.edu/resources/vpn-setup/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Then read about OpenAuth &lt;a href=&#34;https://www.rc.fas.harvard.edu/resources/documentation/openauth/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;. One can download mobile apps such as &lt;code&gt;Duo&lt;/code&gt; and &lt;code&gt;google-Authenticator&lt;/code&gt; on your phone, but then each time you will need to type the password to the terminal. Or you can download the java program for desktop, if you have a FAS research computing account, you should be able to download it from the link FASRC send you. I downloaded a folder like &lt;code&gt;mtang-openauth&lt;/code&gt;. The prefix will be your HPC account name.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd mtang-openauth
./mtang-openauth.sh
No Java runtime present, requesting install.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You will have to install &lt;code&gt;java&lt;/code&gt; first. My mac prompt a window for downloading, click &lt;code&gt;More Info&lt;/code&gt;, it will bring you to a webpage for downloading.&lt;/p&gt;

&lt;p&gt;After you install &lt;code&gt;java&lt;/code&gt;, type &lt;code&gt;./mtang-openauth.sh&lt;/code&gt;, a little green box with the 6 digits verification code will show up in the upper-right corner of your screen.&lt;/p&gt;

&lt;p&gt;Fire-up iterm2:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ssh mtang@odyssey.rc.fas.harvard.edu

# it will prompt for password and then the verification code.
# type in the password for your account
# copy the 6-digits verification code and paste to your iterm window
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is kind of annoying if I have to do this everytime. It takes me ~2 seconds to type or copy/paste from the java desktop app, but what if I automate this. suppose I log into the HPC 10 times a day and 300 days per year. I save &lt;code&gt;2x10x300 = 6000&lt;/code&gt; seconds, that&amp;rsquo;s  100 minutes a year :) The following may take me ~1 hour to set up, but I hope it can save you some time by following this.&lt;/p&gt;

&lt;h4 id=&#34;generate-ssh-key-for-password-less-login&#34;&gt;generate ssh key for password-less login&lt;/h4&gt;

&lt;p&gt;Note, I have done this a couple of times, but I still need to google it everytime I set it up. I have told you googling is an essential skill for bioinformaticians :)&lt;/p&gt;

&lt;p&gt;On your mac:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ssh-keygen -b 2048

Generating public/private rsa key pair.
Enter file in which to save the key (/Users/mingtang/.ssh/id_rsa):
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /Users/mingtang/.ssh/id_rsa.
Your public key has been saved in /Users/mingtang/.ssh/id_rsa.pub.
The key fingerprint is:
SHA256:8LOJnp1rv5BZY9yoHVcrQarTnhW5Ih+eK8dA1+rxYao mingtang@huitadmins-MacBook-Pro.local
The key&#39;s randomart image is:
+---[RSA 2048]----+
|            .    |
|           o .   |
|      .   ..+ .  |
|       o.+.o.= . |
|       .S.@.* .  |
|       ..^oXo.   |
|      . B+B= .   |
|     . ooo=..    |
|      o.E*+.     |
+----[SHA256]-----+

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;tell &lt;code&gt;ssh-agent&lt;/code&gt; about our key, we use &lt;code&gt;ssh-add&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ssh-add
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This creates a private key at &lt;code&gt;~/.ssh/id_rsa&lt;/code&gt; and a public key at &lt;code&gt;~/.ssh/id_rsa.pub&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Now, &lt;code&gt;ssh&lt;/code&gt; to &lt;strong&gt;odyssey HPC&lt;/strong&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ssh mtang@odyssey.rc.fas.harvard.edu
# type in the passowrd
# copy paste the 6-digit verification code in the green box
# you will be logged in your home directory
 
cd .ssh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;append your public key file (id_rsa.pub, not your private key!) on your mac (open the file, copy it) to &lt;code&gt;~/.ssh/authorized_keys&lt;/code&gt; on the HPC.&lt;/p&gt;

&lt;p&gt;I asked Aaron in the group and it turns out one can not skip the 2-factor system for password-less login on the &lt;code&gt;odyssey.rc.fas.harvard.edu&lt;/code&gt; login node.&lt;/p&gt;

&lt;h4 id=&#34;otp-token-paster-for-os-x&#34;&gt;OTP Token Paster for OS X&lt;/h4&gt;

&lt;p&gt;Follow &lt;a href=&#34;https://github.com/jwm/os-x-otp-token-paster&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Install Homebrew&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;/usr/bin/ruby -e &amp;quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&amp;quot;
brew install oath-toolkit
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;If it isn&amp;rsquo;t already present, enter &lt;code&gt;secret=YOUR_BASE32_ENCODED_SECRET&lt;/code&gt; in &lt;code&gt;~/.JAuth.rc&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# I have Services folder in my mac
mkdir -p ~/Library/Services
git clone https://github.com/jwm/os-x-otp-token-paster
cd os-x-otp-token-paster
mv &#39;Enter Current TOTP Token.workflow&#39; ~/Library/Services
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Open System Preferences -&amp;gt; Keyboard -&amp;gt; Keyboard Shortcuts -&amp;gt; Services -&amp;gt; Enter Current OTP Token (probably way down at the bottom).&lt;/li&gt;
&lt;li&gt;Click &amp;lsquo;add shortcut&amp;rsquo; and enter the key combination you want to use.I use &lt;code&gt;control + shift + U&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ssh mtang@odyssey.rc.fas.harvard.edu
# type in password
# when prompt for verificartion code
# use the short-cut: control+shift+U 
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;controlmaster-for-ssh&#34;&gt;ControlMaster for ssh&lt;/h4&gt;

&lt;p&gt;Please follow &lt;a href=&#34;https://www.rc.fas.harvard.edu/resources/documentation/linux/using-ssh-controlmaster-for-single-sign-on/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; to set it up.&lt;/p&gt;

&lt;p&gt;with this, you only need to type in the password and verification code once. The subsequent logins will be password-less for the &lt;code&gt;odyssey.rc.fas.harvard.edu&lt;/code&gt; login node.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;OpenSSH has an option called ControlMaster that enables the sharing of multiple sessions over a single network connection. This means that you can connect to Odyssey once, enter your password and Verification code, and have all other subsequent ssh sessions (including svn, rsync, etc. that run over ssh) piggy-back off the initial connection without need for re-authentication. You can specify such options each time on the command line, but it&amp;rsquo;s easiest if you put it in your ssh client configuration file so that it applies every time.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>set up my new mac laptop</title>
      <link>/post/set-up-my-new-mac-laptop/</link>
      <pubDate>Wed, 03 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/set-up-my-new-mac-laptop/</guid>
      <description>

&lt;p&gt;I am starting my first day at Harvard FAS informatics and I will keep a note here on how I set up my new laptop.&lt;/p&gt;

&lt;h3 id=&#34;customize-terminal&#34;&gt;customize terminal&lt;/h3&gt;

&lt;p&gt;following &lt;a href=&#34;https://gist.github.com/kevin-smets/8568070&#34; target=&#34;_blank&#34;&gt;this gist&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;download iterm2 for mac &lt;a href=&#34;https://iterm2.com/downloads.html&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;install-on-my-zsh&#34;&gt;install on-my-zsh&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sh -c &amp;quot;$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You will have to install git first for the upper command to work.
Now, when you fire up your terminal, it looks much more prettier! (there are many other schemes for oh my zsh, I found the default is good. You can change it by modifying the .zshrc file in your home directory.)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Selecting a Theme&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Once you find a theme that you&amp;rsquo;d like to use, you will need to edit the ~/.zshrc file. You&amp;rsquo;ll see an environment variable (all caps) in there that looks like:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ZSH_THEME=&amp;quot;robbyrussell&amp;quot;&lt;/code&gt;
To use a different theme, simply change the value to match the name of your desired theme. For example:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ZSH_THEME=&amp;quot;agnoster&amp;quot;&lt;/code&gt; # (this is one of the fancy ones)
see &lt;a href=&#34;https://github.com/robbyrussell/oh-my-zsh/wiki/Themes#agnoster&#34; target=&#34;_blank&#34;&gt;https://github.com/robbyrussell/oh-my-zsh/wiki/Themes#agnoster&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;install-conda&#34;&gt;install conda&lt;/h3&gt;

&lt;p&gt;install &lt;code&gt;conda&lt;/code&gt;, go to &lt;a href=&#34;https://www.anaconda.com/download/#macos&#34; target=&#34;_blank&#34;&gt;https://www.anaconda.com/download/#macos&lt;/a&gt; and download the graphic installer. It is ~600 MB and take some time.&lt;/p&gt;

&lt;p&gt;Usually &lt;code&gt;conda&lt;/code&gt; is installed in the home directory. Somehow, it was installed in the &lt;code&gt;/&lt;/code&gt; root.&lt;/p&gt;

&lt;p&gt;add the following to the &lt;code&gt;~/.zshrc&lt;/code&gt; file&lt;/p&gt;

&lt;p&gt;put conda after the &lt;code&gt;$PATH&lt;/code&gt;, otherwise somehow &lt;code&gt;oh-my-zsh&lt;/code&gt; will not work properly (the folders are not displayed with color etc)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export PATH=$PATH:&amp;quot;/anaconda3/bin&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;file-editor&#34;&gt;file editor&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;sublime&lt;/code&gt; or &lt;code&gt;Atom&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;download &lt;code&gt;sublime&lt;/code&gt; from &lt;a href=&#34;https://www.sublimetext.com/3&#34; target=&#34;_blank&#34;&gt;https://www.sublimetext.com/3&lt;/a&gt; and install it.&lt;/p&gt;

&lt;p&gt;if you want to open sublime in terminal&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;open /Applications/Sublime\ Text.app/Contents/SharedSupport/bin/subl

# make a symbolic link for it
ln -s &amp;quot;/Applications/Sublime Text.app/Contents/SharedSupport/bin/subl&amp;quot; /usr/local/bin/sublime

# now you can
sublime my.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;install-r-and-rstudio&#34;&gt;install R and Rstudio&lt;/h3&gt;

&lt;p&gt;The current R version is R3.5.1. Download it from &lt;a href=&#34;https://cran.cnr.berkeley.edu&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Install Rstudio v1.2.1013-1.
I installed the &lt;a href=&#34;https://www.rstudio.com/products/rstudio/download/preview/&#34; target=&#34;_blank&#34;&gt;preview version&lt;/a&gt; of Rstudio because it can evalute python code directly throught &lt;a href=&#34;https://github.com/rstudio/reticulate&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;reticulate&lt;/code&gt;&lt;/a&gt;. I&amp;rsquo;ve used &lt;code&gt;pycharm&lt;/code&gt; before, but it is too clunky for me. One can of course set up both R and python inside &lt;code&gt;sublime&lt;/code&gt; or &lt;code&gt;Atom&lt;/code&gt;, but I do not want to leave &lt;code&gt;Rstudio&lt;/code&gt; :)&lt;/p&gt;

&lt;h3 id=&#34;install-docker&#34;&gt;install docker&lt;/h3&gt;

&lt;p&gt;follow &lt;a href=&#34;https://docs.docker.com/docker-for-mac/install/&#34; target=&#34;_blank&#34;&gt;https://docs.docker.com/docker-for-mac/install/&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;install-slack&#34;&gt;install slack&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://slack.com&#34; target=&#34;_blank&#34;&gt;Slack&lt;/a&gt; For team communication&lt;/p&gt;

&lt;h3 id=&#34;install-notion&#34;&gt;install Notion&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.notion.so&#34; target=&#34;_blank&#34;&gt;Notion&lt;/a&gt; For to-do list&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Compute averages/sums on GRanges or equal length bins</title>
      <link>/post/compute-averages-sums-on-granges-or-equal-length-bins/</link>
      <pubDate>Fri, 07 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/compute-averages-sums-on-granges-or-equal-length-bins/</guid>
      <description>&lt;p&gt;Googling is a required technique for programmers. Once I have a programming problem in mind, the first thing I do is to google to see if other people have encountered the same problem and maybe they already have a solution. Do not re-invent the wheels. Actually, reading other people’s code and mimicing their code is a great way of learning. Today, I am going to show you how to compute binned averages/sums along a genome or any genomic regions of interest. All the codes I am going to show I found them online.&lt;/p&gt;
&lt;div id=&#34;how-to-compute-binned-averages-along-a-genome&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;How to compute binned averages along a genome&lt;/h4&gt;
&lt;p&gt;I found it in the &lt;a href=&#34;https://bioconductor.org/packages/release/bioc/vignettes/GenomicRanges/inst/doc/GenomicRangesHOWTOs.pdf&#34;&gt;How to tutorial&lt;/a&gt; of the GRanges package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# using yeast with smaller genome
library(BSgenome.Scerevisiae.UCSC.sacCer2)
library(GenomicRanges)
set.seed(55)
my_var &amp;lt;- RleList(
        lapply(seqlengths(Scerevisiae),
        function(seqlen) {
        tmp &amp;lt;- sample(50L, seqlen, replace=TRUE) %/% 50L
        Rle(cumsum(tmp - rev(tmp)))
        }
        ),
        compress=FALSE)

my_var&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## RleList of length 18
## $chrI
## integer-Rle of length 230208 with 8693 runs
##   Lengths:  32  33  51  21  22   9   1  36 ...   1   9  22  21  51  33  33
##   Values :   0   1   2   1   0  -1   0   1 ...   0  -1   0   1   2   1   0
## 
## $chrII
## integer-Rle of length 813178 with 31959 runs
##   Lengths: 56 10 52 12 69  4 48 35 11  1 ...  1 11 35 48  4 69 12 52 10 57
##   Values :  0  1  0  1  0  1  2  1  2  3 ...  3  2  1  2  1  0  1  0  1  0
## 
## $chrIII
## integer-Rle of length 316617 with 12209 runs
##   Lengths:  20 116   9   2  21  16  43   3 ...  43  16  21   2   9 116  21
##   Values :   0  -1   0   1   0  -1  -2  -3 ...  -2  -1   0   1   0  -1   0
## 
## $chrIV
## integer-Rle of length 1531919 with 60091 runs
##   Lengths: 39 80 67 22 48 77 19 45 13  3 ...  3 13 45 19 77 48 22 67 80 40
##   Values :  0 -1  0  1  2  3  2  1  0  1 ...  1  0  1  2  3  2  1  0 -1  0
## 
## $chrV
## integer-Rle of length 576869 with 22903 runs
##   Lengths:  11  29   7   1  10  29  63  32 ...  63  29  10   1   7  29  12
##   Values :   0  -1  -2  -3  -4  -3  -4  -5 ...  -4  -3  -4  -3  -2  -1   0
## 
## ...
## &amp;lt;13 more elements&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;tile the whole genome to 100 bp bins&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bins &amp;lt;- tileGenome(seqinfo(Scerevisiae), tilewidth=100,cut.last.tile.in.chrom=TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;compute the binned average for my_var&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;binnedAverage(bins, my_var, &amp;quot;binned_var&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## GRanges object with 121639 ranges and 1 metadata column:
##            seqnames       ranges strand | binned_var
##               &amp;lt;Rle&amp;gt;    &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt; |  &amp;lt;numeric&amp;gt;
##        [1]     chrI   [  1, 100]      * |       1.03
##        [2]     chrI   [101, 200]      * |       0.75
##        [3]     chrI   [201, 300]      * |       0.92
##        [4]     chrI   [301, 400]      * |       2.75
##        [5]     chrI   [401, 500]      * |       6.06
##        ...      ...          ...    ... .        ...
##   [121635]  2micron [5901, 6000]      * |       4.76
##   [121636]  2micron [6001, 6100]      * |       2.62
##   [121637]  2micron [6101, 6200]      * |       0.87
##   [121638]  2micron [6201, 6300]      * |       0.03
##   [121639]  2micron [6301, 6318]      * |          0
##   -------
##   seqinfo: 18 sequences (2 circular) from sacCer2 genome&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The key is to convert any values (sequencing depth across the genome, RNA-seq counts etc) into a RleList object, then one can use the &lt;code&gt;binnedAverage&lt;/code&gt; to calculate the average across each small bin of the genome.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;transformation-of-grange-object-to-density-per-bin&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Transformation of GRange object to density per bin&lt;/h4&gt;
&lt;p&gt;see &lt;a href=&#34;https://stat.ethz.ch/pipermail/bioconductor/2013-January/050445.html&#34;&gt;post&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;### &amp;#39;x&amp;#39;: a GenomicRanges objects with non-NA seqlengths.
### &amp;#39;binsize&amp;#39;: a single positive integer.
### &amp;#39;mcolnames&amp;#39;: names of numeric metadata columns in &amp;#39;x&amp;#39; to &amp;quot;average&amp;quot;
###              i.e. to propagate to the result after averaging them
###              on each bin.
### Returns a GRanges object with: (a) the same seqinfo as &amp;#39;x&amp;#39;,
### (b) ranges of width &amp;#39;binsize&amp;#39; covering all the sequences in
### &amp;#39;seqinfo(x)&amp;#39;, and (c) the &amp;quot;averaged&amp;quot; metadata columns specified
### in &amp;#39;mcolnames&amp;#39;.

averagePerBin &amp;lt;- function(x, binsize, mcolnames=NULL)
{
     if (!is(x, &amp;quot;GenomicRanges&amp;quot;))
         stop(&amp;quot;&amp;#39;x&amp;#39; must be a GenomicRanges object&amp;quot;)
     if (any(is.na(seqlengths(x))))
         stop(&amp;quot;&amp;#39;seqlengths(x)&amp;#39; contains NAs&amp;quot;)
     bins &amp;lt;- IRangesList(lapply(seqlengths(x),
                                function(seqlen)
                                  IRanges(breakInChunks(seqlen, binsize))))
     ans &amp;lt;- as(bins, &amp;quot;GRanges&amp;quot;)
     seqinfo(ans) &amp;lt;- seqinfo(x)
     if (is.null(mcolnames))
         return(ans)
     averageMCol &amp;lt;- function(colname)
     {
         cvg &amp;lt;- coverage(x, weight=colname)
         views_list &amp;lt;- RleViewsList(
                           lapply(names(cvg),
                               function(seqname)
                                   Views(cvg[[seqname]], bins[[seqname]])))
         unlist(viewMeans(views_list), use.names=FALSE)
     }
     mcols(ans) &amp;lt;- DataFrame(lapply(mcols(x)[mcolnames], averageMCol))
     ans
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(BSgenome.Hsapiens.UCSC.hg19)

testset.gr&amp;lt;- GRanges(&amp;quot;chr1&amp;quot;, IRanges(start=seq( 50000, 55000,by = 100), width=50), strand = &amp;quot;+&amp;quot;)

## Set the sequence lengths.
seqlengths(testset.gr) &amp;lt;- seqlengths(Hsapiens)[seqlevels(testset.gr)]

## Add the density metadata col.
mcols(testset.gr)$density &amp;lt;- 100

## Compute the average per bin for the specified metadata cols.
avg_per_bin &amp;lt;- averagePerBin(testset.gr, 100, mcolnames=&amp;quot;density&amp;quot;)

avg_per_bin[avg_per_bin$density &amp;gt; 0]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## GRanges object with 52 ranges and 1 metadata column:
##        seqnames         ranges strand |   density
##           &amp;lt;Rle&amp;gt;      &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt; | &amp;lt;numeric&amp;gt;
##    [1]     chr1 [49901, 50000]      * |         1
##    [2]     chr1 [50001, 50100]      * |        50
##    [3]     chr1 [50101, 50200]      * |        50
##    [4]     chr1 [50201, 50300]      * |        50
##    [5]     chr1 [50301, 50400]      * |        50
##    ...      ...            ...    ... .       ...
##   [48]     chr1 [54601, 54700]      * |        50
##   [49]     chr1 [54701, 54800]      * |        50
##   [50]     chr1 [54801, 54900]      * |        50
##   [51]     chr1 [54901, 55000]      * |        50
##   [52]     chr1 [55001, 55100]      * |        49
##   -------
##   seqinfo: 1 sequence from an unspecified genome&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that calling &lt;code&gt;averagePerBin()&lt;/code&gt; without specifying ‘mcolnames’ is a convenient way to generate genomic bins covering the entire genome (and in that case the supplied GRanges doesn’t even need to contain ranges). similar to &lt;code&gt;tileGenome&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;empty_gr &amp;lt;- GRanges(seqinfo=seqinfo(Hsapiens))
empty_gr&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## GRanges object with 0 ranges and 0 metadata columns:
##    seqnames    ranges strand
##       &amp;lt;Rle&amp;gt; &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt;
##   -------
##   seqinfo: 93 sequences (1 circular) from hg19 genome&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;averagePerBin(empty_gr, 25000000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## GRanges object with 205 ranges and 0 metadata columns:
##               seqnames                 ranges strand
##                  &amp;lt;Rle&amp;gt;              &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt;
##     [1]           chr1 [        1,  25000000]      *
##     [2]           chr1 [ 25000001,  50000000]      *
##     [3]           chr1 [ 50000001,  75000000]      *
##     [4]           chr1 [ 75000001, 100000000]      *
##     [5]           chr1 [100000001, 125000000]      *
##     ...            ...                    ...    ...
##   [201] chrUn_gl000245             [1, 36651]      *
##   [202] chrUn_gl000246             [1, 38154]      *
##   [203] chrUn_gl000247             [1, 36422]      *
##   [204] chrUn_gl000248             [1, 39786]      *
##   [205] chrUn_gl000249             [1, 38502]      *
##   -------
##   seqinfo: 93 sequences (1 circular) from hg19 genome&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-compute-averages-of-a-meta-column-from-one-granges-on-the-other-granges&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;How to compute averages of a meta column from one GRanges on the other GRanges&lt;/h4&gt;
&lt;p&gt;see a &lt;a href=&#34;https://support.bioconductor.org/p/57956/&#34;&gt;post&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;size &amp;lt;- 50000
windowSize &amp;lt;- 10

dat &amp;lt;- GRanges(&amp;quot;chr1&amp;quot;, IRanges(start=1:size, width=2), strand=&amp;quot;+&amp;quot;,score=sample(1:size, size))

# windows
GRwin &amp;lt;- GRanges(&amp;quot;chr1&amp;quot;, IRanges(start=(0:(size/windowSize))*windowSize, width=windowSize), strand=&amp;quot;+&amp;quot;)

## make a RleList object from the data
score &amp;lt;- coverage(dat, weight=&amp;quot;score&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then to summarize ‘score’ on your fixed-size tiling windows, you need a summarizing function like the &lt;code&gt;binnedAverage()&lt;/code&gt; function shown in &lt;code&gt;?tileGenome&lt;/code&gt;. &lt;code&gt;binnedAverage()&lt;/code&gt; computes the average on each window but it’s easy to write a summarizing function that computes the sum:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;binnedSum &amp;lt;- function(bins, numvar, mcolname)
{
  stopifnot(is(bins, &amp;quot;GRanges&amp;quot;))
  stopifnot(is(numvar, &amp;quot;RleList&amp;quot;))
  stopifnot(identical(seqlevels(bins), names(numvar)))
  bins_per_chrom &amp;lt;- split(ranges(bins), seqnames(bins))
  sums_list &amp;lt;- lapply(names(numvar),
      function(seqname) {
          views &amp;lt;- Views(numvar[[seqname]],
                         bins_per_chrom[[seqname]])
          viewSums(views)
      })
  new_mcol &amp;lt;- unsplit(sums_list, as.factor(seqnames(bins)))
  mcols(bins)[[mcolname]] &amp;lt;- new_mcol
  bins
}


GRwin2 &amp;lt;- binnedSum(GRwin, score, &amp;quot;binned_score&amp;quot;)

GRwin2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## GRanges object with 5001 ranges and 1 metadata column:
##          seqnames         ranges strand | binned_score
##             &amp;lt;Rle&amp;gt;      &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt; |    &amp;lt;integer&amp;gt;
##      [1]     chr1       [ 0,  9]      + |       304897
##      [2]     chr1       [10, 19]      + |       517317
##      [3]     chr1       [20, 29]      + |       377486
##      [4]     chr1       [30, 39]      + |       274838
##      [5]     chr1       [40, 49]      + |       513542
##      ...      ...            ...    ... .          ...
##   [4997]     chr1 [49960, 49969]      + |       515986
##   [4998]     chr1 [49970, 49979]      + |       521740
##   [4999]     chr1 [49980, 49989]      + |       424913
##   [5000]     chr1 [49990, 49999]      + |       514258
##   [5001]     chr1 [50000, 50009]      + |        11963
##   -------
##   seqinfo: 1 sequence from an unspecified genome; no seqlengths&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;turning-a-granges-metadata-column-into-rlelist-object.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;turning a GRanges metadata column into RleList object.&lt;/h4&gt;
&lt;p&gt;see a &lt;a href=&#34;https://support.bioconductor.org/p/50014/&#34;&gt;post&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gr&amp;lt;- GRanges(c(&amp;quot;chr1&amp;quot;, &amp;quot;chr2&amp;quot;), IRanges(c(10, 50), c(16, 55)), scores= c(20, 10))
seqlengths(gr) &amp;lt;- c(100, 100)

coverage(gr, weight=gr$scores)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## RleList of length 2
## $chr1
## numeric-Rle of length 100 with 3 runs
##   Lengths:  9  7 84
##   Values :  0 20  0
## 
## $chr2
## numeric-Rle of length 100 with 3 runs
##   Lengths: 49  6 45
##   Values :  0 10  0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Depending on your needs, the ranges which aren’t present in the GRanges object may effectively have missing scores and need to be NA, and 0 is a valid score for the ranges which are present. One hack would be to add 1 to all of the scores, replace the zeros in the &lt;code&gt;coverage()&lt;/code&gt; result with NAs and subtract 1:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gr$scores &amp;lt;- gr$scores + 1L
cov &amp;lt;- coverage(gr, weight  = &amp;quot;scores&amp;quot;)
cov[cov == 0L] &amp;lt;- NA
cov &amp;lt;- cov - 1L&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Alternatively you could call &lt;code&gt;coverage()&lt;/code&gt; a 2nd time with no weights to find the regions with no coverage, and set them to NA:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cvg &amp;lt;- coverage(gr, weight=gr$scores)
cvg[coverage(gr) == 0] &amp;lt;- NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It turns out that there are functions to convert between meta data column and RleList. Just be careful with the different behaviors of different functions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# ?bindAsGRanges
# ?mcolAsRleList

mcolAsRleList(gr, varname = &amp;quot;scores&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## RleList of length 2
## $chr1
## numeric-Rle of length 100 with 3 runs
##   Lengths:  9  7 84
##   Values : NA 21 NA
## 
## $chr2
## numeric-Rle of length 100 with 3 runs
##   Lengths: 49  6 45
##   Values : NA 11 NA&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bindAsGRanges(cvg)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## GRanges object with 2 ranges and 1 metadata column:
##       seqnames    ranges strand |        V1
##          &amp;lt;Rle&amp;gt; &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt; | &amp;lt;numeric&amp;gt;
##   [1]     chr1  [10, 16]      * |        21
##   [2]     chr2  [50, 55]      * |        11
##   -------
##   seqinfo: 2 sequences from an unspecified genome&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bindAsGRanges(coverage(gr,weight=gr$scores))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## GRanges object with 6 ranges and 1 metadata column:
##       seqnames    ranges strand |        V1
##          &amp;lt;Rle&amp;gt; &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt; | &amp;lt;numeric&amp;gt;
##   [1]     chr1 [ 1,   9]      * |         0
##   [2]     chr1 [10,  16]      * |        21
##   [3]     chr1 [17, 100]      * |         0
##   [4]     chr2 [ 1,  49]      * |         0
##   [5]     chr2 [50,  55]      * |        11
##   [6]     chr2 [56, 100]      * |         0
##   -------
##   seqinfo: 2 sequences from an unspecified genome&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# or coerce using as
as(cvg, &amp;quot;GRanges&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## GRanges object with 6 ranges and 1 metadata column:
##       seqnames    ranges strand |     score
##          &amp;lt;Rle&amp;gt; &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt; | &amp;lt;numeric&amp;gt;
##   [1]     chr1 [ 1,   9]      * |      &amp;lt;NA&amp;gt;
##   [2]     chr1 [10,  16]      * |        21
##   [3]     chr1 [17, 100]      * |      &amp;lt;NA&amp;gt;
##   [4]     chr2 [ 1,  49]      * |      &amp;lt;NA&amp;gt;
##   [5]     chr2 [50,  55]      * |        11
##   [6]     chr2 [56, 100]      * |      &amp;lt;NA&amp;gt;
##   -------
##   seqinfo: 2 sequences from an unspecified genome&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;as(coverage(gr, weight = gr$scores), &amp;quot;GRanges&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## GRanges object with 6 ranges and 1 metadata column:
##       seqnames    ranges strand |     score
##          &amp;lt;Rle&amp;gt; &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt; | &amp;lt;numeric&amp;gt;
##   [1]     chr1 [ 1,   9]      * |         0
##   [2]     chr1 [10,  16]      * |        21
##   [3]     chr1 [17, 100]      * |         0
##   [4]     chr2 [ 1,  49]      * |         0
##   [5]     chr2 [50,  55]      * |        11
##   [6]     chr2 [56, 100]      * |         0
##   -------
##   seqinfo: 2 sequences from an unspecified genome&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;subset-rlelist-with-granges&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;subset RleList with GRanges&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cov[gr]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## RleList of length 2
## $chr1
## numeric-Rle of length 7 with 1 run
##   Lengths:  7
##   Values : 20
## 
## $chr2
## numeric-Rle of length 6 with 1 run
##   Lengths:  6
##   Values : 10&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>From cell line to command line: my journey to bioinformatics</title>
      <link>/talk/2018-uf-talk/</link>
      <pubDate>Fri, 31 Aug 2018 00:00:00 -0400</pubDate>
      
      <guid>/talk/2018-uf-talk/</guid>
      <description>&lt;p&gt;I was invited to give a talk to my PhD Genetics and Genomics program at the University of Florida. I talked about my personal experience on how I started doing bioinformatics and shared tips and resources to get the students started their own journey into bioinformatics.&lt;/p&gt;

&lt;p&gt;I am so glad to be back home!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/UF_talk.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Embed your slides or video here using &lt;a href=&#34;https://sourcethemes.com/academic/post/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;shortcodes&lt;/a&gt;. Further details can easily be added using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Positive Regulation of Transcription by Human ZMYND8 through Its Association with P-TEFb Complex</title>
      <link>/publication/2018-08-21-ptefb/</link>
      <pubDate>Tue, 21 Aug 2018 00:00:00 -0400</pubDate>
      
      <guid>/publication/2018-08-21-ptefb/</guid>
      <description>&lt;p&gt;More detail can easily be written here using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Tandem Duplicator Phenotype Is a Prevalent Genome-Wide Cancer Configuration Driven by Distinct Gene Mutations</title>
      <link>/publication/2018-07-12-tandem-duplicate/</link>
      <pubDate>Thu, 12 Jul 2018 00:00:00 -0400</pubDate>
      
      <guid>/publication/2018-07-12-tandem-duplicate/</guid>
      <description>&lt;p&gt;More detail can easily be written here using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2018 Next-Gen Sequence Analysis Workshop</title>
      <link>/talk/2018-dibsi-course/</link>
      <pubDate>Tue, 10 Jul 2018 00:00:00 -0400</pubDate>
      
      <guid>/talk/2018-dibsi-course/</guid>
      <description>&lt;p&gt;I taught the ChIP-seq lesson for 2018 ANGUS Next-Gen Sequence Analysis Workshop held in UC Davis from 7/1/2018 to 7/14/2018, and TAed for the rest of the sessions. You can find my class link &lt;a href=&#34;https://angus.readthedocs.io/en/2018/chip-seq.html&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; and all the rest materials &lt;a href=&#34;https://angus.readthedocs.io/en/2018/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;. This is the first formal teaching I have done after I became a certified instructor for Data Carpentry. The same teaching skills applied!&lt;/p&gt;

&lt;p&gt;Some tips for teaching:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Be slow in pace&lt;/li&gt;
&lt;li&gt;Pause and have students ask questions&lt;/li&gt;
&lt;li&gt;Draw on white borad. (I am a visual person)&lt;/li&gt;
&lt;li&gt;Use sticky notes to get an idea of how the class room feel. red sticker means problem. green sticker means OK!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;See how many students we have!&lt;/strong&gt;
&lt;img src=&#34;/img/teaching3.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Instructors and TAs group picture&lt;/strong&gt;
&lt;img src=&#34;/img/instructors_dibsi2018.jpg&#34; alt=&#34;&#34; /&gt;
Embed your slides or video here using &lt;a href=&#34;https://sourcethemes.com/academic/post/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;shortcodes&lt;/a&gt;. Further details can easily be added using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
