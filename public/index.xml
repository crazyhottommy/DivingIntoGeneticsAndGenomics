<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DNA confesses Data speak on DNA confesses Data speak</title>
    <link>/</link>
    <description>Recent content in DNA confesses Data speak on DNA confesses Data speak</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Ming Tang</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0400</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Mixing mouse and human 10x single cell RNAseq data</title>
      <link>/post/mixing-mouse-and-human-10x-single-cell-rnaseq-data/</link>
      <pubDate>Wed, 11 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/mixing-mouse-and-human-10x-single-cell-rnaseq-data/</guid>
      <description>&lt;p&gt;In a typical “barnyard” experiment in which cells from different species are mixed before loading to the 10x controller, the identification of the species of origin after mapping/counting with the hybrid reference is a problem. People tend to use the ratio of reads mapped to each reference genome to determine which species a cell is from.&lt;/p&gt;
&lt;p&gt;In this paper &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/630087v1.full&#34; class=&#34;uri&#34;&gt;https://www.biorxiv.org/content/10.1101/630087v1.full&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;To deconvolute species, detect doublets and low quality cells, the mixed-species mapped data was used. Cells for which &amp;gt;70% of the reads mapped to only one species were assigned to the corresponding species. The remaining cells (those for which &amp;lt;70% of the reads mapped to only one species) were removed from the downstream analysis.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;kallisto bustool &lt;a href=&#34;https://bustools.github.io/BUS_notebooks_R/10xv2.html&#34;&gt;https://bustools.github.io/BUS_notebooks_R/10xv2.html&lt;/a&gt; uses 90% as a cutoff.&lt;/p&gt;
&lt;p&gt;However, how to choose this cutoff is subjective. In this blog post, I will mix a mouse and a human 10x single cell RNAseq dataset in silicon and then map to the hybrid transriptome. We have the ground truth of which cell comes from which species so we can investigate the mapping rate.&lt;/p&gt;
&lt;div id=&#34;download-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Download data&lt;/h3&gt;
&lt;p&gt;Download 1k pbmc data and 1k mouse brain data from 10x website.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;cd /n/holylfs/LABS/informatics/mtang/projects/dj/10x_mouse_human_mixing
wget http://cf.10xgenomics.com/samples/cell-exp/3.0.0/neuron_1k_v3/neuron_1k_v3_fastqs.tar

wget http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v3/pbmc_1k_v3_fastqs.tar

## after tar xvf
ls neuron_1k_v3_fastqs/
neuron_1k_v3_S1_L001_I1_001.fastq.gz  neuron_1k_v3_S1_L001_R2_001.fastq.gz  neuron_1k_v3_S1_L002_R1_001.fastq.gz
neuron_1k_v3_S1_L001_R1_001.fastq.gz  neuron_1k_v3_S1_L002_I1_001.fastq.gz  neuron_1k_v3_S1_L002_R2_001.fastq.gz

ls pbmc_1k_v3_fastqs/
pbmc_1k_v3_S1_L001_I1_001.fastq.gz  pbmc_1k_v3_S1_L001_R2_001.fastq.gz  pbmc_1k_v3_S1_L002_R1_001.fastq.gz
pbmc_1k_v3_S1_L001_R1_001.fastq.gz  pbmc_1k_v3_S1_L002_I1_001.fastq.gz  pbmc_1k_v3_S1_L002_R2_001.fastq.gz&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;add-species-barcode-to-the-r1-fastq&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;add species barcode to the R1 fastq&lt;/h3&gt;
&lt;p&gt;Different experiment could have barcode collisions, let’s add additional barcode in front of the original cell barcode.&lt;/p&gt;
&lt;p&gt;save the below as a &lt;code&gt;add_species_barcode.sh&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;This script adds a 8 base pair barcode in front of the R1 reads (16bp cell barcode + 12 bp umi for 10x version3) and some dummy high quality score (I) to the quality line.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;#! /bin/bash
set -euo pipefail

zcat $1 |  awk -v barcode=&amp;quot;$2&amp;quot; &amp;#39;NR%4 == 2 {$0=barcode$0} NR%4==0 {$0=&amp;quot;IIIIIIII&amp;quot;$0} {print}&amp;#39; | gzip  &amp;gt; $3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I am adding &lt;code&gt;AAAAAAAA&lt;/code&gt; and &lt;code&gt;TTTTTTTT&lt;/code&gt; to mouse and human data, respectively.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;chmod u+x add_species_barcode.sh

./add_species_barcode.sh neuron_1k_v3_fastqs/neuron_1k_v3_S1_L001_R1_001.fastq.gz AAAAAAAA neuron_1k_v3_fastqs/neuron_1k_v3_S1_L001_R1_001_modified.fastq.gz


./add_species_barcode.sh neuron_1k_v3_fastqs/neuron_1k_v3_S1_L002_R1_001.fastq.gz AAAAAAAA neuron_1k_v3_fastqs/neuron_1k_v3_S1_L002_R1_001_modified.fastq.gz


./add_species_barcode.sh pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L001_R1_001.fastq.gz TTTTTTTT pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L001_R1_001_modified.fastq.gz


./add_species_barcode.sh pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L002_R1_001.fastq.gz TTTTTTTT pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L002_R1_001_modified.fastq.gz
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;build-a-hybrid-index-for-kallisto.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;build a hybrid index for kallisto.&lt;/h3&gt;
&lt;p&gt;kallisto uses cDNA for indexing.&lt;/p&gt;
&lt;p&gt;Note &lt;a href=&#34;https://www.kallistobus.tools/kb_transcriptome_index.html&#34;&gt;&lt;code&gt;kb-python&lt;/code&gt;&lt;/a&gt; uses genomics DNA and gtf file for making reference (it will extract the cDNA from genomic DNA based on gtf file). I tested &lt;code&gt;kb-python&lt;/code&gt; for a single species experiment and it worked well and saves you doing all the steps. However, &lt;code&gt;kb ref&lt;/code&gt; requires the fasta and gtf files to be merged for creating the hybrid reference. I may try it next time.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;## download the cDNA for mouse and human
wget ftp://ftp.ensembl.org/pub/release-96/fasta/mus_musculus/cdna/Mus_musculus.GRCm38.cdna.all.fa.gz
wget ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz

## download the gtf files
wget ftp://ftp.ensembl.org/pub/release-96/gtf/mus_musculus/Mus_musculus.GRCm38.96.gtf.gz
wget ftp://ftp.ensembl.org/pub/release-96/gtf/homo_sapiens/Homo_sapiens.GRCh38.96.gtf.gz

kallisto index -i GRCh38_GRCm38/GRCh38_GRCm38_96.idx Homo_sapiens.GRCh38.cdna.all.fa.gz Mus_musculus.GRCm38.cdna.all.fa.gz&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;kallisto-count-at-transcript-level&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;kallisto count at transcript level&lt;/h4&gt;
&lt;p&gt;Note 10x V2 R1 is 16bp cell barcode + 10 bp umi, V3 R1 is 16 bp cell barcode + 12 bp umi.&lt;/p&gt;
&lt;p&gt;See my previous post &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/post/understand-10x-scrnaseq-and-scatac-fastqs/&#34; class=&#34;uri&#34;&gt;https://divingintogeneticsandgenomics.rbind.io/post/understand-10x-scrnaseq-and-scatac-fastqs/&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;
kallisto bus -i /n/holylfs/INTERNAL_REPOS/INFORMATICS/reference_genome_by_tommy/kallisto_bus_ref/GRCh38_GRCm38_96.idx -o mouse_human_kallisto_out -x 0,0,24:0,24,36:1,0,0 -t8 \
neuron_1k_v3_fastqs/neuron_1k_v3_S1_L001_R1_001_modified.fastq.gz \
neuron_1k_v3_fastqs/neuron_1k_v3_S1_L001_R2_001.fastq.gz \
neuron_1k_v3_fastqs/neuron_1k_v3_S1_L002_R1_001_modified.fastq.gz \
neuron_1k_v3_fastqs/neuron_1k_v3_S1_L002_R2_001.fastq.gz \
pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L001_R1_001_modified.fastq.gz \
pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L001_R2_001.fastq.gz \
pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L002_R1_001_modified.fastq.gz \
pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L002_R2_001.fastq.gz

[index] k-mer length: 31
[index] number of targets: 307,242
[index] number of k-mers: 208,670,671
[index] number of equivalence classes: 1,276,238
[quant] will process sample 1: neuron_1k_v3_fastqs/neuron_1k_v3_S1_L001_R1_001_modified.fastq.gz
                               neuron_1k_v3_fastqs/neuron_1k_v3_S1_L001_R2_001.fastq.gz
[quant] will process sample 2: neuron_1k_v3_fastqs/neuron_1k_v3_S1_L002_R1_001_modified.fastq.gz
                               neuron_1k_v3_fastqs/neuron_1k_v3_S1_L002_R2_001.fastq.gz
[quant] will process sample 3: pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L001_R1_001_modified.fastq.gz
                               pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L001_R2_001.fastq.gz
[quant] will process sample 4: pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L002_R1_001_modified.fastq.gz
                               pbmc_1k_v3_fastqs/pbmc_1k_v3_S1_L002_R2_001.fastq.gz
[quant] finding pseudoalignments for the reads ... done
[quant] processed 159,504,118 reads, 97,750,679 reads pseudoaligned&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;bustools-count-at-gene-level&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;bustools count at gene level&lt;/h3&gt;
&lt;p&gt;we need a transcript to gene mapping tsv file making from gtf file. I could not find the &lt;code&gt;t2g.py&lt;/code&gt; script mentioned in the &lt;a href=&#34;https://www.kallistobus.tools/documentation&#34;&gt;tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;make a transcript to gene mapping file using unix command line. also read my previous blog post:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;zcat Homo_sapiens.GRCh38.96.gtf.gz | grep -v &amp;quot;#&amp;quot; | awk &amp;#39;$3==&amp;quot;transcript&amp;quot;&amp;#39; | cut -f9 | tr -s &amp;quot;;&amp;quot; &amp;quot; &amp;quot; | awk -v OFS=&amp;quot;\t&amp;quot; &amp;#39;{print$6&amp;quot;\t&amp;quot;$2&amp;quot;\t&amp;quot;$10}&amp;#39; | sort | uniq |  sed &amp;#39;s/\&amp;quot;//g&amp;#39; &amp;gt; Homo_sapiens.GRCh38.96.tsv


zcat Mus_musculus.GRCm38.96.gtf.gz | grep -v &amp;quot;#&amp;quot; | awk &amp;#39;$3==&amp;quot;transcript&amp;quot;&amp;#39; | cut -f9 | tr -s &amp;quot;;&amp;quot; &amp;quot; &amp;quot; | awk -v OFS=&amp;quot;\t&amp;quot; &amp;#39;{print$6&amp;quot;\t&amp;quot;$2&amp;quot;\t&amp;quot;$10}&amp;#39; | sort | uniq |  sed &amp;#39;s/\&amp;quot;//g&amp;#39; &amp;gt; Mus_musculus.GRCm38.96.tsv

## merge the tsv 
cat Homo_sapiens.GRCh38.96.tsv Mus_musculus.GRCm38.96.tsv &amp;gt; GRCh38_GRCm38.96.tsv&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;correct-to-the-whitelist-and-bustools-count-at-gene-level&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;correct to the whitelist and bustools count at gene level&lt;/h3&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;wget https://github.com/BUStools/getting_started/releases/download/species_mixing/10xv3_whitelist.txt

wc -l 10xv3_whitelist.txt
6794880 10xv3_whitelist.txt&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are valid 68k cell barcodes from 10x. we added the species barcode in front of them and use bustool to correct for sequencing errors.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;# add the same species barcode to it.
cat 10xv3_whitelist.txt | awk &amp;#39;{print &amp;quot;AAAAAAAA&amp;quot;$0}&amp;#39; &amp;gt; whitelist1.txt
cat 10xv3_whitelist.txt | awk &amp;#39;{print &amp;quot;TTTTTTTT&amp;quot;$0}&amp;#39; &amp;gt; whitelist2.txt
cat whitelist1.txt whitelist2.txt &amp;gt; whitelist.txt

mkdir tmp genecount

bustools correct -w whitelist.txt -p mouse_human_kallisto_out/output.bus | \
bustools sort -T tmp/ -t 4 -p - | \
bustools count -o genecount/genes \
-g /n/holylfs/INTERNAL_REPOS/INFORMATICS/reference_genome_by_tommy/kallisto_bus_ref/GRCh38_GRCm38.96.tsv \
-e mouse_human_kallisto_out/matrix.ec -t mouse_human_kallisto_out/transcripts.txt --genecounts -

Found 13589760 barcodes in the whitelist

Number of hamming dist 1 barcodes = 461228268
Processed 97750679 bus records
In whitelist = 94311259
Corrected = 329059
Uncorrected = 3110361
Read in 94640318 BUS records&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt; it is not working!! 0 genes were mapped when I checked the &lt;code&gt;genes.genes.txt&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The devil is that &lt;code&gt;kallisto&lt;/code&gt; infers the transcript id from the &lt;code&gt;cDNA&lt;/code&gt; fasta file which contains the &lt;code&gt;.2&lt;/code&gt; version number, but in the gtf file the version number is in the &lt;code&gt;transcript_version 2&lt;/code&gt; entry.&lt;/p&gt;
&lt;p&gt;The easiest way is to remove the version number in the &lt;code&gt;transcript.txt&lt;/code&gt; file from output.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;# make a backup
cp transcripts.txt transcripts.bc.txt

# check how the version number look like for all genes
cat transcripts.txt | cut -d. -f2 | sort | uniq
1
10
11
12
13
14
15
16
17
2
3
4
5
6
7
8
9

cat transcripts.txt | sed -r &amp;#39;s/\.[0-9]?//&amp;#39; &amp;gt; transcript2.txt

## rerun bustool but feeding the transcript2.txt
rm -rf genecount/*

bustools correct -w whitelist.txt -p mouse_human_kallisto_out/output.bus | \
bustools sort -T tmp/ -t 4 -p - | \
bustools count -o genecount/genes \
-g /n/holylfs/INTERNAL_REPOS/INFORMATICS/reference_genome_by_tommy/kallisto_bus_ref/GRCh38_GRCm38.96.tsv \
-e mouse_human_kallisto_out/matrix.ec -t mouse_human_kallisto_out/transcript2.txt --genecounts -&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;alternative-ways&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Alternative ways&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The R package &lt;a href=&#34;https://github.com/BUStools/BUSpaRse/blob/master/R/tr2g.R&#34;&gt;BUSpaRse&lt;/a&gt; has a function to take care of that to make a transcript to gene mapping file from cDNA fasta. &lt;a href=&#34;https://bustools.github.io/BUS_notebooks_R/10xv2.html&#34; class=&#34;uri&#34;&gt;https://bustools.github.io/BUS_notebooks_R/10xv2.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(BUSpaRse)
tr2g &amp;lt;- transcript2gene(fasta_file = c(&amp;quot;./data/hs_cdna.fa.gz&amp;quot;, &amp;quot;./data/mm_cdna.fa.gz&amp;quot;),
                        kallisto_out_path = &amp;quot;./output/out_hgmm1k&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;kb-python&lt;/code&gt; command &lt;code&gt;kb ref&lt;/code&gt; takes &lt;strong&gt;genomic DNA fasta&lt;/strong&gt; and gtf files and makes the index and a transcript to gene mapping file on the fly.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;load-in-to-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;load in to R&lt;/h3&gt;
&lt;p&gt;following &lt;a href=&#34;https://bustools.github.io/BUS_notebooks_R/10xv2.html&#34; class=&#34;uri&#34;&gt;https://bustools.github.io/BUS_notebooks_R/10xv2.html&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(BUSpaRse)
library(tidyverse)
library(DropletUtils)
library(Matrix)
library(Seurat)

res_mat &amp;lt;- read_count_output(&amp;quot;~/Downloads/genecount&amp;quot;,name = &amp;quot;genes&amp;quot;, tcc = FALSE)

dim(res_mat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  71600 731356&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;remove some of the empty droplets&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tot_counts &amp;lt;- Matrix::colSums(res_mat)
summary(tot_counts)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
##      0.00      1.00      1.00     34.89      5.00 142612.00&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Compute barcode rank from Dropletutils
bc_rank &amp;lt;- barcodeRanks(res_mat)

qplot(bc_rank$total, bc_rank$rank, geom = &amp;quot;line&amp;quot;) +
  geom_vline(xintercept = bc_rank$knee, color = &amp;quot;blue&amp;quot;, linetype = 2) +
  geom_vline(xintercept = bc_rank$inflection, color = &amp;quot;green&amp;quot;, linetype = 2) +
  annotate(&amp;quot;text&amp;quot;, y = 1000, x = 1.5 * c(bc_rank$knee, bc_rank$inflection),
           label = c(&amp;quot;knee&amp;quot;, &amp;quot;inflection&amp;quot;), color = c(&amp;quot;blue&amp;quot;, &amp;quot;green&amp;quot;)) +
  scale_x_log10() +
  scale_y_log10() +
  labs(y = &amp;quot;Barcode rank&amp;quot;, x = &amp;quot;Total UMI count&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-11-mixing-mouse-and-human-10x-single-cell-rnaseq-data_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;filter-the-cells&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;filter the cells&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Filter the matrix
res_mat &amp;lt;- res_mat[, tot_counts &amp;gt; bc_rank$inflection]
dim(res_mat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 71600  2375&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we get around 2000 cells.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gene_species &amp;lt;- ifelse(str_detect(rownames(res_mat), &amp;quot;^ENSMUSG&amp;quot;), &amp;quot;mouse&amp;quot;, &amp;quot;human&amp;quot;)
mouse_inds &amp;lt;- gene_species == &amp;quot;mouse&amp;quot;
human_inds &amp;lt;- gene_species == &amp;quot;human&amp;quot;
# mark cells as mouse or human
cell_species &amp;lt;- tibble(n_mouse_umi = Matrix::colSums(res_mat[mouse_inds,]),
                       n_human_umi = Matrix::colSums(res_mat[human_inds,]),
                       tot_umi = Matrix::colSums(res_mat),
                       prop_mouse = n_mouse_umi / tot_umi,
                       prop_human = n_human_umi / tot_umi)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;ground-truth&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;ground truth&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_detect(colnames(res_mat), &amp;quot;^AAAAAAAA&amp;quot;) %&amp;gt;% table()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## .
## FALSE  TRUE 
##  1169  1206&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_detect(colnames(res_mat), &amp;quot;^TTTTTTTT&amp;quot;) %&amp;gt;% table()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## .
## FALSE  TRUE 
##  1206  1169&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have 1206 mouse cells and 1169 human cells&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cell_species&amp;lt;- cell_species %&amp;gt;% 
  mutate(ground_truth = case_when(
    str_detect(colnames(res_mat), &amp;quot;^AAAAAAAA&amp;quot;) ~ &amp;quot;mouse&amp;quot;,
    str_detect(colnames(res_mat), &amp;quot;^TTTTTTTT&amp;quot;) ~ &amp;quot;human&amp;quot;
  )) 

p1&amp;lt;- ggplot(cell_species, aes(x = ground_truth, y = prop_mouse)) +
  geom_boxplot(aes(color = ground_truth))

p2&amp;lt;- ggplot(cell_species, aes(x = ground_truth, y = prop_human)) +
  geom_boxplot(aes(color = ground_truth))

p&amp;lt;- cowplot::plot_grid(
  p1 + theme(legend.position=&amp;quot;none&amp;quot;),
  p2 + theme(legend.position=&amp;quot;none&amp;quot;),
  align = &amp;#39;vh&amp;#39;)

## add back the legend
legend &amp;lt;- cowplot::get_legend(
  # create some space to the left of the legend
  p1 + theme(legend.box.margin = margin(0, 0, 0, 12))
)

# add the legend to the row we made earlier. Give it one-third of 
# the width of one plot (via rel_widths).
cowplot::plot_grid(p, legend, rel_widths = c(2, .4))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-11-mixing-mouse-and-human-10x-single-cell-rnaseq-data_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;minimal and maximal proportion for mapping rate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# min 95%
cell_species$prop_human[cell_species$ground_truth == &amp;quot;human&amp;quot;] %&amp;gt;%
  range()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9505135 0.9994325&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# max 5%
cell_species$prop_mouse[cell_species$ground_truth == &amp;quot;human&amp;quot;] %&amp;gt;%
  range()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0005675369 0.0494864613&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# min 97%
cell_species$prop_mouse[cell_species$ground_truth == &amp;quot;mouse&amp;quot;] %&amp;gt;%
  range()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9743096 1.0000000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# max 2%
cell_species$prop_human[cell_species$ground_truth == &amp;quot;mouse&amp;quot;] %&amp;gt;%
  range()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.00000000 0.02569043&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;assign species of origin by the proportion&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cell_species&amp;lt;- cell_species %&amp;gt;% 
  mutate(ground_truth = case_when(
    str_detect(colnames(res_mat), &amp;quot;^AAAAAAAA&amp;quot;) ~ &amp;quot;mouse&amp;quot;,
    str_detect(colnames(res_mat), &amp;quot;^TTTTTTTT&amp;quot;) ~ &amp;quot;human&amp;quot;
  )) %&amp;gt;%
  mutate(species = case_when(
    prop_mouse &amp;gt; 0.9 ~ &amp;quot;mouse&amp;quot;,
    prop_human &amp;gt; 0.9 ~ &amp;quot;human&amp;quot;,
    TRUE ~ &amp;quot;mixed&amp;quot;
  ))

table(cell_species$ground_truth, cell_species$species)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        
##         human mouse
##   human  1169     0
##   mouse     0  1206&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This makes a 100% match as expected.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;seurat-for-dimension-reduction-and-visualization&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Seurat for dimension reduction and visualization&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;seu &amp;lt;- CreateSeuratObject(res_mat, min.cells = 3) %&amp;gt;% 
  NormalizeData(verbose = FALSE) %&amp;gt;% 
  ScaleData(verbose = FALSE) %&amp;gt;% 
  FindVariableFeatures(verbose = FALSE)

seu &amp;lt;- AddMetaData(seu, metadata = cell_species$ground_truth, col.name = &amp;quot;species&amp;quot;)
seu &amp;lt;- RunPCA(seu, verbose = FALSE, npcs = 30)
seu &amp;lt;- RunTSNE(seu, dims = 1:20, check_duplicates = FALSE)
DimPlot(seu, reduction = &amp;quot;pca&amp;quot;, pt.size = 0.5, group.by = &amp;quot;species&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-11-mixing-mouse-and-human-10x-single-cell-rnaseq-data_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;DimPlot(seu, reduction = &amp;quot;tsne&amp;quot;, pt.size = 0.5, group.by = &amp;quot;species&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-12-11-mixing-mouse-and-human-10x-single-cell-rnaseq-data_files/figure-html/unnamed-chunk-19-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;conclusion&lt;/h3&gt;
&lt;p&gt;Using ratio of mapped reads for each cell to identify the cell of origin works pretty well for mouse and human mixtures. what if we use a more close species to human say chimpanzee or monkeys? Also, in a real experiment, one may have doublets from different species.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Modeling single cell RNAseq data with multinomial distribution </title>
      <link>/post/modeling-single-cell-rnaseq-data-with-multinomial-distribution/</link>
      <pubDate>Tue, 26 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/modeling-single-cell-rnaseq-data-with-multinomial-distribution/</guid>
      <description>&lt;p&gt;I was reading &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/574574v1&#34;&gt;Feature Selection and Dimension Reduction for Single Cell RNA-Seq based on a Multinomial Model&lt;/a&gt;. In the paper, the authors model the scRNAseq counts using a multinomial distribution.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/multinomial.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I was using negative binomial distribution for modeling in my last &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/post/negative-bionomial-distribution-in-single-cell-rnaseq/&#34;&gt;post&lt;/a&gt;, so I asked the question on twitter:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
for modeling RNAseq counts, what&#39;s the difference/advantages using negative binomial and multinomial distribution?
&lt;/p&gt;
— Ming Tang (&lt;span class=&#34;citation&#34;&gt;@tangming2005&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/tangming2005/status/1199340525188349952?ref_src=twsrc%5Etfw&#34;&gt;November 26, 2019&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;some quotes from the answers I get from Matthew&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;the true distribution is multinomial. The conditional distr has of each gene is Poisson. Since there are so many genes each gene is approximately independent so independent Poissons can be used.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;the marginal distribution of the true multinomial is binomial, which can be approximated by Poisson.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Real data is over dispersed since the Poisson only models technical variance not biological. To model the biological variance we use a mixture of poisons with a gamma prior — the gamma prior accounting for biological variability. The marginal distr of counts is negative binomial&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I am going to use multinomial distribution for the same data I used in my last post.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Seurat)
library(tidyverse)
# There is an error when using this function, need to use the dev branch.
# https://github.com/satijalab/seurat/issues/2060
svensson_data&amp;lt;- ReadH5AD(&amp;quot;~/Downloads/svensson_chromium_control.h5ad&amp;quot;)

raw_counts&amp;lt;- svensson_data@assays$RNA@counts

# there are two datasets, each with 2000 cells
colnames(raw_counts) %&amp;gt;% stringr::str_extract(&amp;quot;[0-9]+_&amp;quot;) %&amp;gt;% table()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## .
## 20311_ 20312_ 
##   2000   2000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# I am going to use only the second dataset sevensson et al 2
raw_counts2&amp;lt;- raw_counts[, grepl(pattern = &amp;quot;20312_&amp;quot;, x = colnames(raw_counts))]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;counts from a gene fit a binomial distribution in a cell.&lt;/p&gt;
&lt;p&gt;Given
&lt;span class=&#34;math inline&#34;&gt;\(\displaystyle \Pr(X=k)={\binom {n}{k}}p^{k}(1-p)^{n-k}\)&lt;/span&gt; for binomial distribution,&lt;/p&gt;
&lt;p&gt;the marginal mean for each gene is &lt;span class=&#34;math inline&#34;&gt;\(E[y_{ij}]=n_ip_{ij} = \mu_{ij}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the marginal variance is &lt;span class=&#34;math inline&#34;&gt;\(Var[y_{ij}] = n_ip_{ij}(1-p_{ij}) = \mu_{ij}- \frac1{n_i}\mu_{ij}^2\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the probability of seeing a 0 count for a gene is: &lt;span class=&#34;math inline&#34;&gt;\((1-p_{ij})^{n_i} = (1-\frac{\mu_{ij}}{n_i})^{n_i}\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# https://github.com/const-ae/sparseMatrixStats
library(sparseMatrixStats)
library(tidyverse)
gene_means&amp;lt;- sparseMatrixStats::rowMeans2(raw_counts2)


## total counts for each cell
lib_size&amp;lt;- sparseMatrixStats::colSums2(raw_counts2)

## https://github.com/willtownes/scrna2019/blob/master/real/zheng_2017_monocytes/02_exploratory.Rmd#L290
## why median though?
n_i&amp;lt;- median(lib_size)

# probability of 0 for each gene given binomial distribution 
zeros_bn&amp;lt;- (1- gene_means/n_i)^n_i 


## this is copied from last post, probability of 0 given negative binomiral distribution
phi &amp;lt;- 1/0.3725
zeros_nb&amp;lt;- (phi/(gene_means + phi))^phi

zeros_observed&amp;lt;- apply(raw_counts2, 1, function(x) mean(x ==0))

data.frame(zeros_bn = zeros_bn, zeros_nb = zeros_nb, zeros_observed = zeros_observed, 
           gene_means = gene_means) %&amp;gt;%
  ggplot(aes(x =log10(gene_means), y = zeros_observed)) +
  geom_point() +
  geom_line(aes(x = log10(gene_means), y = zeros_nb), color = &amp;quot;red&amp;quot;) +
  geom_line(aes(x = log10(gene_means), y = zeros_bn), color = &amp;quot;blue&amp;quot;) +
  theme_classic(base_size = 14) +
  ggtitle(&amp;quot;Svensson et al 2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-26-modeling-single-cell-rnaseq-data-with-multinomial-distribution_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;At least for this dataset, negative bionomial (red line) seems to fit the observed 0 count better. multinomial with marginal binomial (blue line) seems to support 0 inflated in single-cell RNAseq.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;UPDATE&lt;/strong&gt; 12/10/2019, as Will pointed out in the comment, we need to downsample the single cell data making each cell has roughly the same number of reads. He replicated my analysis at &lt;a href=&#34;https://github.com/willtownes/scrna2019/blob/master/real/svensson_2019/01_exploratory.Rmd&#34; class=&#34;uri&#34;&gt;https://github.com/willtownes/scrna2019/blob/master/real/svensson_2019/01_exploratory.Rmd&lt;/a&gt;&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
Hi thanks for your interest, in order to make those plots, you have to be able to treat all the cells/droplets as being drawn from same multinomial distribution meaning all the “n_i” terms have to be the same (or at least close). We used downsampling to achieve that…
&lt;/p&gt;
— Will (&lt;span class=&#34;citation&#34;&gt;@sandakano&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/sandakano/status/1199709577144623106?ref_src=twsrc%5Etfw&#34;&gt;November 27, 2019&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;I will put them in the same blog post for completeness.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## from https://github.com/willtownes/scrna2019/blob/master/util/functions.R#L67

Down_Sample_Matrix&amp;lt;-function(expr_mat,min_lib_size=NULL){
  #adapted from https://hemberg-lab.github.io/scRNA.seq.course/cleaning-the-expression-matrix.html#normalisations
  min_sz&amp;lt;-min(colSums(expr_mat))
  if(is.null(min_lib_size)){
    min_lib_size&amp;lt;-min_sz
  } else {
    stopifnot(min_lib_size&amp;lt;=min_sz)
  }
  down_sample&amp;lt;-function(x){
    prob &amp;lt;- min_lib_size/sum(x)
    unlist(lapply(x,function(y){rbinom(1, y, prob)}))
  }
  apply(expr_mat, 2, down_sample)
}


gg&amp;lt;-sparseMatrixStats::rowSums2(raw_counts2)&amp;gt;0 #exclude genes that are zero across all cells
Y&amp;lt;-raw_counts2[gg,]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To make the droplets comparable, we will exclude droplets with total count below 2,000 and downsample all other droplets to have approximately the same total counts.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;total_counts&amp;lt;- sparseMatrixStats::colSums2(Y)

hist(total_counts,breaks=100)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-26-modeling-single-cell-rnaseq-data-with-multinomial-distribution_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Yss&amp;lt;-Y[,total_counts&amp;gt;2000]
#downsample to normalize droplet size (total UMI)
Yds&amp;lt;-Down_Sample_Matrix(as.matrix(Yss))&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;using-the-downsampled-matrix-yss-for-plotting&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;using the downsampled matrix Yss for plotting&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Yds&amp;lt;-Yds[rowSums(Yds)&amp;gt;0,]

gene_means&amp;lt;- rowMeans(Yds)
gene_vars&amp;lt;- apply(Yds, 1, var)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;after downsampling, the mean and variance now are the same suggesting possion distribution&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df&amp;lt;- bind_cols(gene_means = gene_means, gene_vars = gene_vars)
 
df %&amp;gt;% ggplot(aes(x = log10(gene_means), y = log10(gene_vars))) +
        geom_point() +
        geom_abline(intercept = 0, slope = 1, color = &amp;quot;red&amp;quot;) + 
        theme_classic(base_size = 14) +
        ggtitle(&amp;quot;svensson et al 2 downsample&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-26-modeling-single-cell-rnaseq-data-with-multinomial-distribution_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This is consistent with &lt;a href=&#34;https://www.nxn.se/valent/2018/1/30/count-depth-variation-makes-poisson-scrna-seq-data-negative-binomial&#34;&gt;Count depth variation makes Poisson scRNA-seq data Negative Binomial&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Let’s see how the observed 0 counts fit each model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## total counts for each cell
lib_size&amp;lt;- colSums(Yds)

## https://github.com/willtownes/scrna2019/blob/master/real/zheng_2017_monocytes/02_exploratory.Rmd#L290

N&amp;lt;-median(colSums(Yds))
predict_zeros_binom&amp;lt;-function(x){(1-exp(x)/N)^N} #binomial
predict_zeros_poi&amp;lt;-function(x){exp(-exp(x))}
predict_zeros_nb&amp;lt;-function(x,phi=100){
  exp(-phi*log1p(exp(x-log(phi))))
}

## note it is natural log here.
data.frame(zeros_observed = rowMeans(Yds==0), 
           x = log(gene_means)) %&amp;gt;%
  ggplot(aes(x , y = zeros_observed), alpha = 0.5) +
  geom_point() +
  stat_function(aes(x,color=&amp;quot;bin&amp;quot;),fun=predict_zeros_binom) +
  stat_function(aes(x,color=&amp;quot;poi&amp;quot;),fun=predict_zeros_poi) +
  stat_function(aes(x,color=&amp;quot;nb&amp;quot;),fun=predict_zeros_nb) +
  scale_color_manual(&amp;quot;model&amp;quot;,breaks=c(&amp;quot;bin&amp;quot;,&amp;quot;poi&amp;quot;,&amp;quot;nb&amp;quot;),values=c(&amp;quot;blue&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;red&amp;quot;)) +
  theme_classic(base_size = 14) +
  ggtitle(&amp;quot;Svensson et al 2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-26-modeling-single-cell-rnaseq-data-with-multinomial-distribution_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;After downsampling&lt;/strong&gt;, “Poisson, binomial and negative binomial models all fit the data about the same.”&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>negative bionomial distribution in (single-cell) RNAseq </title>
      <link>/post/negative-bionomial-distribution-in-single-cell-rnaseq/</link>
      <pubDate>Thu, 21 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/negative-bionomial-distribution-in-single-cell-rnaseq/</guid>
      <description>&lt;p&gt;This post is inspired by two posts written by Valentine Svensson:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.nxn.se/valent/2017/11/16/droplet-scrna-seq-is-not-zero-inflated&#34; class=&#34;uri&#34;&gt;http://www.nxn.se/valent/2017/11/16/droplet-scrna-seq-is-not-zero-inflated&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.nxn.se/valent/2018/1/30/count-depth-variation-makes-Poisson-scrna-seq-data-negative-binomial&#34; class=&#34;uri&#34;&gt;http://www.nxn.se/valent/2018/1/30/count-depth-variation-makes-Poisson-scrna-seq-data-negative-binomial&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The original ipython notebook can be found at &lt;a href=&#34;https://github.com/vals/Blog/blob/master/171116-zero-inflation/Negative%20control%20analysis.ipynb&#34; class=&#34;uri&#34;&gt;https://github.com/vals/Blog/blob/master/171116-zero-inflation/Negative%20control%20analysis.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thanks for writing those and put both the data and code in public. After I read &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/582064v1&#34;&gt;Droplet scRNA-seq is not zero-inflated&lt;/a&gt; by Valentine Svensson, I want to gain some understanding of it. This post is an effort to replicate some of the analysis in the preprint using &lt;code&gt;R&lt;/code&gt;. The original analysis was carried out in &lt;code&gt;python&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;I am going to use the same negative control scRNAseq data used in the paper. Negative control data are generated by adding a solution of RNA to the fluid in microfluidic systems so that each droplet contains the same RNA content.&lt;/p&gt;
&lt;p&gt;The negative control data can be downloaded from &lt;a href=&#34;https://figshare.com/projects/Zero_inflation_in_negative_control_data/61292&#34; class=&#34;uri&#34;&gt;https://figshare.com/projects/Zero_inflation_in_negative_control_data/61292&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Seurat)
library(tidyverse)
# There is an error when using this function, need to use the dev branch.
# https://github.com/satijalab/seurat/issues/2060
svensson_data&amp;lt;- ReadH5AD(&amp;quot;~/Downloads/svensson_chromium_control.h5ad&amp;quot;)

raw_counts&amp;lt;- svensson_data@assays$RNA@counts

# there are two datasets, each with 2000 cells
colnames(raw_counts) %&amp;gt;% stringr::str_extract(&amp;quot;[0-9]+_&amp;quot;) %&amp;gt;% table()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## .
## 20311_ 20312_ 
##   2000   2000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# I am going to use only the second dataset sevensson et al 2
raw_counts2&amp;lt;- raw_counts[, grepl(pattern = &amp;quot;20312_&amp;quot;, x = colnames(raw_counts))]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, let’s check the mean and variance relationship for all the genes&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# https://github.com/const-ae/sparseMatrixStats
library(sparseMatrixStats)
library(tidyverse)
gene_means&amp;lt;- sparseMatrixStats::rowMeans2(raw_counts2)
gene_vars&amp;lt;- sparseMatrixStats::rowVars(raw_counts2)

df&amp;lt;- bind_cols(gene_means = gene_means, gene_vars = gene_vars)
 
df %&amp;gt;% ggplot(aes(x = log10(gene_means), y = log10(gene_vars))) +
        geom_point() +
        theme_classic(base_size = 14) +
        ggtitle(&amp;quot;svensson et al 2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-21-negative-bionomial-distribution-in-single-cell-rnaseq_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We see when the gene expression level is bigger, the variance is also bigger- a quadratic relationship as opposed to possion distribution in which the mean is equal to variance.&lt;/p&gt;
&lt;p&gt;Poisson distribution is a common model for count data as well.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Poisson distribution, named after French mathematician Siméon Denis Poisson, is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time or space if these events occur with a known constant rate and independently of the time since the last event.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The probability density function is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[{\displaystyle P(k{\text{ events in interval}})={\frac {\lambda ^{k}e^{-\lambda }}{k!}}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;with only one positive real &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; as the parameter.&lt;/p&gt;
&lt;p&gt;One can prove mathematically the mean is equal to the variance and equal to &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[E(X)= Var(X) = \lambda\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Remember from my last &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/post/negative-binomial-distribution-in-scrnaseq/&#34;&gt;post&lt;/a&gt;, for negative binomial distribution, the Variance is in a quadratic relationship with the mean. It seems that &lt;strong&gt;for each gene&lt;/strong&gt;, the counts across all cells in scRNAseq data can be modeled with negative binomial distribution better than possion since we observed mean not equal to variance according to the scatter plot.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Var = \mu + \frac {\mu^2}{\phi}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In fact, &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; is always postive, so we will always have &lt;span class=&#34;math inline&#34;&gt;\(Var &amp;gt; \mu\)&lt;/span&gt;. When &lt;span class=&#34;math inline&#34;&gt;\(\frac {1}{\phi} = 0\)&lt;/span&gt;, it is the possion distribution.&lt;/p&gt;
&lt;p&gt;Let’s assume each gene follows negative binomial distribution and we can fit a linear regression line.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model&amp;lt;- lm(gene_vars ~  1* gene_means + I(gene_means^2) + 0, data =df )
summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = gene_vars ~ 1 * gene_means + I(gene_means^2) + 0, 
##     data = df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1457.42     0.00     0.00     0.02   802.42 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&amp;gt;|t|)    
## I(gene_means^2) 3.725e-01  6.352e-05    5863   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 11.24 on 24115 degrees of freedom
## Multiple R-squared:  0.9993, Adjusted R-squared:  0.9993 
## F-statistic: 3.438e+07 on 1 and 24115 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see the coefficient estimate is &lt;code&gt;0.3725&lt;/code&gt; for the &lt;span class=&#34;math inline&#34;&gt;\(\mu^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac 1\phi = 0.3725\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is the same value as calculated in the preprint by Valentine Svensson:
&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/582064v1&#34;&gt;Droplet scRNA-seq is not zero-inflated&lt;/a&gt; table 1.&lt;/p&gt;
&lt;p&gt;Let’s plot the fitted line to the mean variance plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predicted_df&amp;lt;- data.frame(mean = df$gene_means, var_predict = 
                            df$gene_means + 0.3725 * (df$gene_means)^2 )

df %&amp;gt;%  ggplot(aes(x = log10(gene_means), y = log10(gene_vars))) +
        geom_point() +
        geom_line(color = &amp;quot;red&amp;quot;, data = predicted_df, aes(x = log10(gene_means), y =log10(var_predict))) + 
        theme_classic(base_size = 14) +
        ggtitle(&amp;quot;svensson et al&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-21-negative-bionomial-distribution-in-single-cell-rnaseq_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Given the &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; and mean of a gene, we can calculate the probability of observing 0 count for that gene:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\Pr(X=0) = \left(\frac{\phi} {\mu + \phi}\right)^{\phi}\]&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;is-single-cell-rnaseq-data-0-inflated&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Is single cell RNAseq data 0 inflated?&lt;/h3&gt;
&lt;p&gt;Now, let’s plot the observed 0s vs the theoretical 0s given the data fit negative binomial distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;phi &amp;lt;- 1/0.3725

zeros_nb&amp;lt;- (phi/(gene_means + phi))^phi
zeros_observed&amp;lt;- apply(raw_counts2, 1, function(x) mean(x ==0))

data.frame(zeros_nb = zeros_nb, zeros_observed = zeros_observed, 
           gene_means = gene_means) %&amp;gt;%
  ggplot(aes(x =log10(gene_means), y = zeros_observed)) +
  geom_point() +
  geom_line(aes(x = log10(gene_means), y = zeros_nb), color = &amp;quot;red&amp;quot;) +
  theme_classic(base_size = 14) +
  ggtitle(&amp;quot;Svensson et al 2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-21-negative-bionomial-distribution-in-single-cell-rnaseq_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We see it fits very well. That’s why Valentine says this scRNAseq data is &lt;strong&gt;NOT&lt;/strong&gt; 0 inflated.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>negative binomial distribution</title>
      <link>/post/negative-binomial-distribution-in-scrnaseq/</link>
      <pubDate>Wed, 13 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/negative-binomial-distribution-in-scrnaseq/</guid>
      <description>&lt;p&gt;“Every model is wrong, but some are useful”— George Box&lt;/p&gt;
&lt;p&gt;In an effort to better understand the distribution of single-cell RNAseq counts,
I dived a bit deeper into the negative binomial distribution in the context of &lt;code&gt;R&lt;/code&gt;. I am by no means an
expert in statistics and writing this post is for myself to better understand it.&lt;/p&gt;
&lt;div id=&#34;what-is-a-negative-binomial-distribution&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;what is a negative binomial distribution&lt;/h3&gt;
&lt;p&gt;I will quote from &lt;a href=&#34;https://en.wikipedia.org/wiki/Negative_binomial_distribution&#34;&gt;wiki&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Suppose there is a sequence of independent Bernoulli trials. Thus, each trial has two potential outcomes called “success” and “failure”. In each trial the probability of success is p and of failure is (1 − p). We are observing this sequence until a predefined number r of failures have occurred. Then the random number of successes we have seen, X, will have the negative binomial (or Pascal) distribution:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[X\sim \mathrm {NB} (r,\,p)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The probability mass function of the negative binomial distribution is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[{\displaystyle f(k;r,p)\equiv \Pr(X=k)={\binom {k+r-1}{k}}(1-p)^{r}p^{k}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Sometimes the distribution is parameterized in terms of its mean &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and variance &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; :&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[{\displaystyle {\begin{aligned}&amp;amp;p={\frac {\sigma ^{2}-\mu }{\sigma ^{2}}},\\[6pt]&amp;amp;r={\frac {\mu ^{2}}{\sigma ^{2}-\mu }},\\[3pt]&amp;amp;\Pr(X=k)={k+{\frac {\mu ^{2}}{\sigma ^{2}-\mu }}-1 \choose k}\left({\frac {\sigma ^{2}-\mu }{\sigma ^{2}}}\right)^{k}\left({\frac {\mu }{\sigma ^{2}}}\right)^{\mu ^{2}/(\sigma ^{2}-\mu )}.\end{aligned}}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Let’s see how it is implemented in &lt;code&gt;R&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;Open the help page &lt;code&gt;?rnbinom&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;rnbinom(n, size, prob, mu)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[{\displaystyle f(x;n,p)\equiv \Pr(X=x)={\binom {n+x-1}{n-1}}(1-p)^{x}p^{n}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This represents the number of failures which occur in a sequence of Bernoulli trials before a target number of successes (n) is reached.&lt;/strong&gt; The mean is μ = n(1-p)/p and variance n(1-p)/p^2.&lt;/p&gt;
&lt;p&gt;Notice the difference from the definition from wiki above.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;size&lt;br /&gt;
target for number of successful trials, or dispersion parameter (the shape parameter of the gamma mixing distribution). Must be strictly positive, need not be integer.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is the n in the formula.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;prob&lt;br /&gt;
probability of success in each trial. 0 &amp;lt; prob &amp;lt;= 1.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is the p in the formula.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;mu
alternative parametrization via mean: see ‘Details’.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Details:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;An alternative parametrization (often used in ecology) is by the mean mu (see above), and size, the dispersion parameter, where prob = size/(size+mu). The variance is mu + mu^2/size in this parametrization.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It is a bit confusing since we can define it in different ways. We can verify it by ourselves.&lt;/p&gt;
&lt;p&gt;Suppose we do independent Bernoulli trails 10 times, with a success probability of 0.4, what’s the probability we see 4 failures before the 6th success?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## this is the total number of failures, the random variable X 
x&amp;lt;- 4

p&amp;lt;- 0.4

## size, the number of successful trials we are targeting
size &amp;lt;- 10 - x

dnbinom(x= x, size = size, prob = p)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.06688604&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;one possible outcome is:&lt;/p&gt;
&lt;p&gt;SSSSSFFFFS&lt;/p&gt;
&lt;p&gt;The last trail has to be a success.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## this is the same as 
choose(size + x -1, size-1) * p^(size) * (1-p)^x&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.06688604&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## and 
choose(size + x -1, x) * p^(size) * (1-p)^x&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.06688604&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;we can simulate the negative binomial distribution counts by&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

rnbinom(10000, size = size, prob =p) %&amp;gt;%
        enframe(name = &amp;quot;seq&amp;quot;, value = &amp;quot;num&amp;quot;) %&amp;gt;%
        ggplot(aes(x = num)) +
        geom_histogram(col=&amp;quot;white&amp;quot;, bins = 30) +
        geom_vline(xintercept = x, linetype = 2, col= &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-11-13-negative-binomial-distribution-in-scrnaseq_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(rnbinom(10000, size = size, prob =p) == x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0664&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see it is close to the exact probability.&lt;/p&gt;
&lt;p&gt;An alternative parametrization (often used in ecology) is by the mean mu (see above), and size, the dispersion parameter, where prob = size/(size+mu). The variance is mu + mu^2/size in this parametrization.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[X\sim \mathrm {NB} (\mu,\,\sigma)\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mu&amp;lt;- size/p - size 
mu&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;variance&amp;lt;- mu + mu^2/size 
variance&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 22.5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dnbinom(x= x, size = size, mu = mu)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.06688604&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see it is the same result.&lt;/p&gt;
&lt;p&gt;with&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[{\displaystyle f(x;n,p)\equiv \Pr(X=x)={\binom {n+x-1}{n-1}}(1-p)^{x}p^{n}}\]&lt;/span&gt;
we can calculate the probablity when x = 0
i.e. the probability that we see a 0 count in RNAseq data.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[{\displaystyle\Pr(X=0)=p^{n}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and we know prob = size/(size+mu)&lt;/p&gt;
&lt;p&gt;The size or &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; is dispersion parameter in gamma distribution (the shape parameter of the gamma mixing distribution). let’s replace the p using &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\Pr(X=0) = \left(\frac{\phi} {\mu + \phi}\right)^{\phi}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The variance is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Var = \mu + \frac {\mu^2}{\phi}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>My opinionated selection of books/urls for bioinformatics/data science curriculum</title>
      <link>/post/my-opinionated-selection-of-books-for-bioinformatics-data-science-curriculum/</link>
      <pubDate>Thu, 12 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/my-opinionated-selection-of-books-for-bioinformatics-data-science-curriculum/</guid>
      <description>

&lt;p&gt;There was a paper on this topic: &lt;a href=&#34;https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003662&#34; target=&#34;_blank&#34;&gt;A New Online Computational Biology Curriculum&lt;/a&gt;.&lt;br /&gt;
I am going to provide a biased list below (I have read most of the books if not all). I say it is biased because you will see many books of R are from Hadely Wickham. I now use &lt;a href=&#34;https://www.tidyverse.org/&#34; target=&#34;_blank&#34;&gt;tidyverse&lt;/a&gt; most of the time.&lt;/p&gt;

&lt;h2 id=&#34;unix&#34;&gt;Unix&lt;/h2&gt;

&lt;p&gt;I suggest people who want to learn bioinformatics starting to learn unix commands first. It is so powerful and also omnipresent in high-performance computing settings (clouding computing etc). You can not survive without knowing it.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://linuxcommand.org/tlcl.php&#34; target=&#34;_blank&#34;&gt;The linux command line&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://nostarch.com/howlinuxworks2&#34; target=&#34;_blank&#34;&gt;How Linux works&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.datascienceatthecommandline.com/&#34; target=&#34;_blank&#34;&gt;Data science at the command line&lt;/a&gt;
It was a fun reading for me and learned many tricks from this book.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rik.smith-unna.com/command_line_bootcamp&#34; target=&#34;_blank&#34;&gt;command line bootcamp&lt;/a&gt; interactive online session to learn unix. it is not working anymore unfortunately.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;computational-biology&#34;&gt;Computational biology&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://library.open.oregonstate.edu/computationalbiology/&#34; target=&#34;_blank&#34;&gt;A Primer for Computational Biology&lt;/a&gt; by Shawn T. O&amp;rsquo;Neil&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://practicalcomputing.org/&#34; target=&#34;_blank&#34;&gt;Practical computing for biologist&lt;/a&gt; by  Steven H.D Haddock and Casey W. Dunn This was the first book that I used to learn unix, regex and python.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://shop.oreilly.com/product/0636920030157.do&#34; target=&#34;_blank&#34;&gt;Bioinformatics data skills&lt;/a&gt; by Vince Buffalo. This is a must have! once you have some experience on bioinformatics.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;r-programming&#34;&gt;R programming&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://r4ds.had.co.nz/&#34; target=&#34;_blank&#34;&gt;R for data science&lt;/a&gt; by Garrett Grolemund and Hadley Wickham.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://adv-r.had.co.nz/&#34; target=&#34;_blank&#34;&gt;Advanced R&lt;/a&gt; by Hadley Wickham.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://r-pkgs.had.co.nz/&#34; target=&#34;_blank&#34;&gt;R packages&lt;/a&gt; by Hadley Wickham. If you want to transit from an R user to developer, writing an R package will get you started.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;stats-r-focused&#34;&gt;Stats  (R focused)&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://rafalab.github.io/pages/harvardx.html&#34; target=&#34;_blank&#34;&gt;Data analysis for the life science with R&lt;/a&gt; by Micheal Love and Rafael A. Irizarry. I took the course on edx for 3 times! learned a ton! You can buy a paper book at &lt;a href=&#34;https://www.crcpress.com/Data-Analysis-for-the-Life-Sciences-with-R/Irizarry-Love/p/book/9781498775670&#34; target=&#34;_blank&#34;&gt;https://www.crcpress.com/Data-Analysis-for-the-Life-Sciences-with-R/Irizarry-Love/p/book/9781498775670&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://compgenomr.github.io/book/&#34; target=&#34;_blank&#34;&gt;Computational Genomics with R&lt;/a&gt; by Altuna Akalin.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://web.stanford.edu/class/bios221/book/&#34; target=&#34;_blank&#34;&gt;Mordern statistics for mordern biology&lt;/a&gt; by Susan Holmes and Wolfgang Huber.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;python-programming&#34;&gt;Python programming&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://pythonforbiologists.com/advanced-python-for-biologists&#34; target=&#34;_blank&#34;&gt;(Advanced) python for biologist&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://wesmckinney.com/pages/book.html&#34; target=&#34;_blank&#34;&gt;Python for data analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.oreilly.com/library/view/data-science-from/9781492041122/&#34; target=&#34;_blank&#34;&gt;Data science from scratch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;machine-learning&#34;&gt;Machine learning&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://faculty.marshall.usc.edu/gareth-james/ISL/&#34; target=&#34;_blank&#34;&gt;An intro to statistical learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.manning.com/books/practical-data-science-with-r&#34; target=&#34;_blank&#34;&gt;Practical Data science with R&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.manning.com/books/deep-learning-with-r&#34; target=&#34;_blank&#34;&gt;Deeping learning with R&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;visualization&#34;&gt;Visualization&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://serialmentor.com/dataviz/&#34; target=&#34;_blank&#34;&gt;Fundamentals of Data Visualization&lt;/a&gt; by Claus O.Wilke&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.amazon.com/Visual-Display-Quantitative-Information/dp/1930824130&#34; target=&#34;_blank&#34;&gt;The Visual Display of Quantitative Information&lt;/a&gt; by Edward R. Tufte as well.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Those two books are not teaching you how to make figures programmatically (although the book by Claus was generated by Rmarkdown and the codes for all the figures can be found at &lt;a href=&#34;https://github.com/clauswilke/dataviz&#34; target=&#34;_blank&#34;&gt;https://github.com/clauswilke/dataviz&lt;/a&gt;). They teach you what kind of figures are informative and pleasant to eyes. &lt;a href=&#34;https://www.data-to-viz.com/&#34; target=&#34;_blank&#34;&gt;From data to viz&lt;/a&gt; is a website guiding you to choose the right graph for your data.&lt;/p&gt;

&lt;p&gt;I am still using R/ggplot2 for visualization.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://socviz.co/&#34; target=&#34;_blank&#34;&gt;Data Visualization&lt;/a&gt; by Kieran Healy.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cookbook-r.com/Graphs/&#34; target=&#34;_blank&#34;&gt;R Graphics Cookbook&lt;/a&gt; by Winston Chang.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/ggplot2-Elegant-Graphics-Data-Analysis/dp/0387981403&#34; target=&#34;_blank&#34;&gt;ggplot2: Elegant Graphics for Data Analysis&lt;/a&gt; by Hadely Wickham.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Finally, I have compiled many useful links at &lt;a href=&#34;https://github.com/crazyhottommy/getting-started-with-genomics-tools-and-resources&#34; target=&#34;_blank&#34;&gt;https://github.com/crazyhottommy/getting-started-with-genomics-tools-and-resources&lt;/a&gt; .&lt;/p&gt;

&lt;p&gt;What&amp;rsquo;s your favorite book that I have missed? Comment below!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/books.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Harvard FAS informatics nanocourse</title>
      <link>/talk/2019-harvard-fas-workshop/</link>
      <pubDate>Mon, 19 Aug 2019 00:00:00 -0400</pubDate>
      
      <guid>/talk/2019-harvard-fas-workshop/</guid>
      <description>&lt;p&gt;In this 2-week long Harvard FAS informatics nanocourse, I co-taught snakemake
for one afternoon and lead-instructed scRNAseq analysis for a full day.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The snakemake workshop material was adapted from Titus Brown and can be found at
&lt;a href=&#34;https://github.com/crazyhottommy/2019-snakemake-Harvard-Informatics-nanocourse&#34; target=&#34;_blank&#34;&gt;https://github.com/crazyhottommy/2019-snakemake-Harvard-Informatics-nanocourse&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The scRNAseq workshop material was developed using &lt;a href=&#34;https://github.com/jdblischak/workflowr&#34; target=&#34;_blank&#34;&gt;workflowr&lt;/a&gt; and can be found at
&lt;a href=&#34;https://crazyhottommy.github.io/scRNA-seq-workshop-Fall-2019/&#34; target=&#34;_blank&#34;&gt;https://crazyhottommy.github.io/scRNA-seq-workshop-Fall-2019/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The rest of the nanocourse material can be found at &lt;a href=&#34;https://github.com/harvardinformatics/micro-course&#34; target=&#34;_blank&#34;&gt;https://github.com/harvardinformatics/micro-course&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I used the &lt;a href=&#34;https://carpentries.org/&#34; target=&#34;_blank&#34;&gt;carpentries&lt;/a&gt; teaching style. A blue sticky note means OK and a red sticky note means having problems.&lt;/p&gt;

&lt;p&gt;Snakemake in action!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/snakemake_wp.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;scRNAseq workshop in a lamont library.
&lt;img src=&#34;/img/scRNAseq_wp.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Embed your slides or video here using &lt;a href=&#34;https://sourcethemes.com/academic/post/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;shortcodes&lt;/a&gt;. Further details can easily be added using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Develop Bioconductor packages with docker container</title>
      <link>/post/develop-bioconductor-packages-with-docker-container/</link>
      <pubDate>Tue, 06 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/develop-bioconductor-packages-with-docker-container/</guid>
      <description>

&lt;h3 id=&#34;readings&#34;&gt;Readings&lt;/h3&gt;

&lt;p&gt;links to read:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.bioconductor.org/developers/package-guidelines/#rcode&#34; target=&#34;_blank&#34;&gt;https://www.bioconductor.org/developers/package-guidelines/#rcode&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/Bioconductor/Contributions&#34; target=&#34;_blank&#34;&gt;https://github.com/Bioconductor/Contributions&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;use container  &lt;a href=&#34;https://github.com/Bioconductor/bioconductor_full&#34; target=&#34;_blank&#34;&gt;https://github.com/Bioconductor/bioconductor_full&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I am following the last link.&lt;/p&gt;

&lt;h3 id=&#34;pull-the-container&#34;&gt;pull the container&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker pull bioconductor/bioconductor_full:devel
docker images 

REPOSITORY                       TAG                  IMAGE ID            CREATED             SIZE
bioconductor/bioconductor_full   devel                ae3ec2be7376        3 hours ago         5.7GB
seuratv3                         latest               9b358ab1fd63        2 days ago          2.76GB
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It is 5.7G in size.&lt;/p&gt;

&lt;p&gt;start the Rstuido from the image. I have another Rstudio instance using port 8787, let me use a different one (e.g. 8080).  docker Rstudio default port is &lt;code&gt;8787&lt;/code&gt;, change the host port to &lt;code&gt;8080&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir -p ~/R/host-site-library

docker run                                      \
  -e PASSWORD=&amp;quot;xyz&amp;quot;                   \
  -p 8080:8787                                \
  -v ~/R/host-site-library:/usr/local/lib/R/host-site-library  \
  -v ~/github_repos:/home/rstudio \
  bioconductor/bioconductor_full:devel
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;NOTE: The path &lt;code&gt;~/R/host-site-library&lt;/code&gt; is mapped to .libPaths() in R. So, when R is started, all the libraries in the host directory &lt;code&gt;host-site-library&lt;/code&gt; are available to R. It is stored on your machine mounted from the volume you fill in place of host-site-library.&lt;/p&gt;

&lt;p&gt;The mounted path must be an &lt;strong&gt;absolute path&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;I also mounted the &lt;code&gt;github_repo&lt;/code&gt; folder in my host machine to the docker home directory. Because every time you exit a container and start it again, the modification you did to the container will be gone (unless you make an modified image and use that for the next time). I will save the R package in my &lt;code&gt;~/github_repo&lt;/code&gt; folder in the host machine.&lt;/p&gt;

&lt;p&gt;type &lt;code&gt;localhost:8080&lt;/code&gt;, you should see the Rstudio login page. username is &lt;code&gt;rstudio&lt;/code&gt;, password is &lt;code&gt;xyz&lt;/code&gt; in this dummy example.&lt;/p&gt;

&lt;p&gt;In Rstudio:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;gt; .libPaths()
[1] &amp;quot;/usr/local/lib/R/host-site-library&amp;quot; &amp;quot;/usr/local/lib/R/site-library&amp;quot;     
[3] &amp;quot;/usr/local/lib/R/library&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;you will see &lt;code&gt;/usr/local/lib/R/host-site-library&lt;/code&gt; is in the &lt;code&gt;libpath&lt;/code&gt;, that corresponds to the &lt;code&gt;~/R/host-site-library&lt;/code&gt; in the host machine, if you do package installation, it will be installed in the&lt;code&gt;~/R/host-site-library&lt;/code&gt; .&lt;/p&gt;

&lt;h3 id=&#34;start-an-r-package-use-usethis&#34;&gt;start an R package use usethis&lt;/h3&gt;

&lt;p&gt;follow these two blog posts and &lt;a href=&#34;http://r-pkgs.had.co.nz/&#34; target=&#34;_blank&#34;&gt;R packages book&lt;/a&gt; by Hadley Wickham:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://blog.methodsconsultants.com/posts/developing-r-packages-using-gitlab-ci-part-i/&#34; target=&#34;_blank&#34;&gt;https://blog.methodsconsultants.com/posts/developing-r-packages-using-gitlab-ci-part-i/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.hvitfeldt.me/blog/usethis-workflow-for-package-development/&#34; target=&#34;_blank&#34;&gt;https://www.hvitfeldt.me/blog/usethis-workflow-for-package-development/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(c(&amp;quot;devtools&amp;quot;, &amp;quot;roxygen2&amp;quot;, &amp;quot;usethis&amp;quot;, &amp;quot;available&amp;quot;, &amp;quot;rmarkdown&amp;quot;))

## check if the package name is avaiable (not used by others)
library(available)
available(&amp;quot;myawesomepackage&amp;quot;)

library(usethis)
usethis::create_package(&amp;quot;~/myawesomepackage&amp;quot;)

use_git()
use_github()
use_mit_license(&amp;quot;Ming Tang&amp;quot;)
usethis::use_pipe()

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Add a function&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;usethis::use_r(&amp;quot;myawesomefunc&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;On mac:&lt;br /&gt;
&lt;code&gt;command + option + shift + R&lt;/code&gt; for inserting roxygen comment.&lt;br /&gt;
&lt;code&gt;command + shift + D&lt;/code&gt; for documentation.&lt;br /&gt;
&lt;code&gt;command + shfit + B&lt;/code&gt; for building package.&lt;/p&gt;

&lt;p&gt;add more functions, repeat.&lt;/p&gt;

&lt;h3 id=&#34;next&#34;&gt;Next&lt;/h3&gt;

&lt;p&gt;Next is to add test and setup some continuous integration. Read this &lt;a href=&#34;https://jef.works/blog/2019/02/17/automate-testing-of-your-R-package/&#34; target=&#34;_blank&#34;&gt;Automate testing of your R package using Travis CI, Codecov, and testthat&lt;/a&gt; by Jean Fan.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Snakemake pipeline post-processing scATAC-seq</title>
      <link>/project/single-cell-atacseq/</link>
      <pubDate>Wed, 17 Jul 2019 00:00:00 -0400</pubDate>
      
      <guid>/project/single-cell-atacseq/</guid>
      <description>

&lt;h3 id=&#34;what-does-it-do&#34;&gt;What does it do?&lt;/h3&gt;

&lt;p&gt;For single cell ATACseq experiment, one gets a merged bam file for all cells. After going through clustering, one groups similar cells into cell types (cell states). This workflow will split the bam by clusters to create a pseudo bulk bam for each cluster, create bigwig tracks for visulization, call peaks for each cluster and merge the peaks across the clusters. Finally it will count reads per peak per cell from the original bam file on the merged peaks.&lt;/p&gt;

&lt;p&gt;In the future, the peak calling software should be barcode aware, so one does not need to split the bam file by cluster. But for now, I have this work for me.&lt;/p&gt;

&lt;p&gt;You can find the workflow at my &lt;a href=&#34;https://github.com/crazyhottommy/pyflow-scATACseq&#34; target=&#34;_blank&#34;&gt;github&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/rulegraph_scATAC.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Run Rstudio server with singularity on HPC</title>
      <link>/post/run-rstudio-server-with-singularity-on-hpc/</link>
      <pubDate>Sun, 09 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/run-rstudio-server-with-singularity-on-hpc/</guid>
      <description>

&lt;h3 id=&#34;background&#34;&gt;Background&lt;/h3&gt;

&lt;p&gt;Please read the following before go ahead:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;what is &lt;a href=&#34;https://www.docker.com/&#34; target=&#34;_blank&#34;&gt;docker&lt;/a&gt;?&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;what is &lt;a href=&#34;https://www.rocker-project.org/&#34; target=&#34;_blank&#34;&gt;Rocker&lt;/a&gt;?&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;what is &lt;a href=&#34;https://www.sylabs.io/docs/&#34; target=&#34;_blank&#34;&gt;singularity&lt;/a&gt;?&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;from Harvard Research computing website: &lt;a href=&#34;https://www.rc.fas.harvard.edu/resources/documentation/software/singularity-on-odyssey/&#34; target=&#34;_blank&#34;&gt;Odyssey has singularity installed&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Why Singularity?
There are some important differences between Docker and Singularity:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Docker and Singularity have their own container formats.&lt;/li&gt;
&lt;li&gt;Docker containers may be imported to run via Singularity.&lt;/li&gt;
&lt;li&gt;Docker containers need root privileges for full functionality which is not suitable for a shared HPC environment.&lt;/li&gt;
&lt;li&gt;Singularity allows working with containers as a regular user. No sudo is required,&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Our &lt;a href=&#34;https://informatics.fas.harvard.edu/&#34; target=&#34;_blank&#34;&gt;informatics group&lt;/a&gt; has several big memory (1TB) computing nodes that allow us to run interactive jobs. I want to have big memory to run Rstudio for my scRNAseq data.&lt;/p&gt;

&lt;h3 id=&#34;run-rstudio-server-with-singularity&#34;&gt;Run Rstudio server with singularity&lt;/h3&gt;

&lt;p&gt;I basically followed this tutorial &lt;a href=&#34;https://www.rocker-project.org/use/singularity/&#34; target=&#34;_blank&#34;&gt;https://www.rocker-project.org/use/singularity/&lt;/a&gt; written by my colleague Nathan Weeks sitting in the same office with me. Thanks!&lt;/p&gt;

&lt;p&gt;First, go to &lt;a href=&#34;https://www.rocker-project.org/images/&#34; target=&#34;_blank&#34;&gt;https://www.rocker-project.org/images/&lt;/a&gt; choose the image you want. I use &lt;code&gt;tidyverse&lt;/code&gt; heavily, so I downloaded the &lt;code&gt;tidyverse&lt;/code&gt; image buit upon &lt;code&gt;Rstudio&lt;/code&gt; image&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;## ssh to remote HPC and pull the docker image by singularity
ssh bio1
mkdir singularity-images; cd !$
singularity pull --name rstudio.simg docker://rocker/tidyverse:latest


# This example bind mounts the /project directory on the host into the Singularity container.
# By default the only host file systems mounted within the container are $HOME, /tmp, /proc, /sys, and /dev.
# type in the password you want to set, make it more complicated than this dummy one
PASSWORD=&#39;xyz&#39; singularity exec --bind=/project  rstudio.simg rserver --auth-none=0  --auth-pam-helper-path=pam-helper --www-address=127.0.0.1

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;back to my mac and connect to it via &lt;a href=&#34;https://www.ssh.com/ssh/tunneling/&#34; target=&#34;_blank&#34;&gt;SSH tunnel&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;Nathan explained by drawing the following.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/ssh_tunnel.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ssh -Nf -L 8787:localhost:8787 bio1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;on my local mac, open &lt;code&gt;localhost:8787&lt;/code&gt; in web browser, type in the Odyssey (HPC) user name and password (xyz in this dummy example). Rstudio server now is ready for me! Magic!!!&lt;/p&gt;

&lt;p&gt;Note: if mulitple people using the same node for Rstudio sever, you will need to pick a different
port than &lt;code&gt;8787&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;one-more-note-on-r-packages&#34;&gt;One more note on R packages&lt;/h3&gt;

&lt;p&gt;create an &lt;code&gt;.Renviron&lt;/code&gt; file in your home diretory&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# User-installed R packages go into their home directory
echo &#39;R_LIBS_USER=~/R/%p-library/%v&#39; &amp;gt;&amp;gt; ${HOME}/.Renviron
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The platform and version will be replaced by the corresponding R versions&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ls ~/R/x86_64-pc-linux-gnu-library/
3.6
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;install packages inside Rstudio and the packages will be installed to &lt;code&gt;~/R/x86_64-pc-linux-gnu-library/3.6&lt;/code&gt;. R version in this singularity image is R3.6. Note that if you use R on command line at the remote machine and use the same version of R. the library may not be compatible. e.g. singularity container is based on debian （Ubuntu) and HPC is based on RPM (CentOS). One may need to have mulitiple &lt;code&gt;.Renviron&lt;/code&gt; file and switch back and forth depending on which R one is using. If you have better options, please let me know!&lt;/p&gt;

&lt;h3 id=&#34;jump-to-other-folders&#34;&gt;Jump to other folders&lt;/h3&gt;

&lt;p&gt;by default, Rstudio opens the home directory. if you want to go to other folders, you can click &lt;code&gt;...&lt;/code&gt; in the file pane.
You can then type in the path you want to jump to.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/change_path.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;submit-a-slurm-job&#34;&gt;Submit a slurm job&lt;/h3&gt;

&lt;p&gt;If you do not have a big computing node that you can run interactive job, you can follow Nathan&amp;rsquo;s &lt;a href=&#34;https://www.rocker-project.org/use/singularity/&#34; target=&#34;_blank&#34;&gt;tutorial&lt;/a&gt; on how to submit slurm job to run Rstudio server with singularity.&lt;/p&gt;

&lt;h3 id=&#34;fix-home-directory-filled-up-issue&#34;&gt;Fix home directory filled up issue&lt;/h3&gt;

&lt;p&gt;I am enjoying Rstudio with my HPC large computing nodes and suddenly I got emails from the HPC staff saying I am using up my home directory space. It turns out Rstudio writes the suspended session files to &lt;code&gt;~/.rstudio/&lt;/code&gt; folder. I &lt;code&gt;ncdu&lt;/code&gt; the folder and it is 34G! I googled around and found exactly this &lt;a href=&#34;https://support.rstudio.com/hc/en-us/articles/218417097-Filling-up-the-home-directory-with-RStudio-Server&#34; target=&#34;_blank&#34;&gt;Filling up the home directory with RStudio Server&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;One of the solution is to turn off session time out.&lt;/p&gt;

&lt;p&gt;put  &lt;code&gt;session-timeout-minutes=0&lt;/code&gt; in the &lt;code&gt;/etc/rstudio/rsession.conf&lt;/code&gt; file.&lt;/p&gt;

&lt;p&gt;Let me take a look at the file inside the container:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;singularity shell rstudio.simg

cat /etc/rstudio/rsession.conf
# R Session Configuration File

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It is an empty file. I will make a
rsession.conf file in the home directory of the host machine
adding that one line.&lt;/p&gt;

&lt;p&gt;Now, bind the modified rsession.conf file in host to the ression.conf file
inside the container:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cat ~/resession.conf
# R Session Configuration File
session-timeout-minutes=0

# now open rstudio server
PASSWORD=&#39;xyz&#39; singularity exec --bind=~/rsession.conf:/etc/rstudio/rsession.conf  rstudio.simg rserver --auth-none=0  --auth-pam-helper-path=pam-helper --www-address=127.0.0.1

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This should fix the problem :)&lt;/p&gt;

&lt;p&gt;Nathan dived into the source code of Rsutido server &lt;a href=&#34;https://github.com/rstudio/rstudio/blob/master/src/cpp/server/ServerSessionManager.cpp#L111&#34; target=&#34;_blank&#34;&gt;https://github.com/rstudio/rstudio/blob/master/src/cpp/server/ServerSessionManager.cpp#L111&lt;/a&gt;
and documentation &lt;a href=&#34;https://docs.rstudio.com/ide/server-pro/r-sessions.html#user-and-group-profiles&#34; target=&#34;_blank&#34;&gt;https://docs.rstudio.com/ide/server-pro/r-sessions.html#user-and-group-profiles&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The enironment name of time out is &lt;code&gt;RSTUDIO_SESSION_TIMEOUT&lt;/code&gt;, so one can do&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;PASSWORD=&#39;xyz&#39; RSTUDIO_SESSION_TIMEOUT=&#39;0&#39; singularity exec rstudio.simg rserver --auth-none=0  --auth-pam-helper-path=pam-helper --www-address=127.0.0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to have the same effect of setting up the &lt;code&gt;rsession.conf&lt;/code&gt; file.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Calculate scATACseq TSS enrichment score</title>
      <link>/post/calculate-scatacseq-tss-enrichment-score/</link>
      <pubDate>Wed, 29 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/calculate-scatacseq-tss-enrichment-score/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;https://www.encodeproject.org/data-standards/terms/#enrichment&#34; target=&#34;_blank&#34;&gt;TSS enrichment score&lt;/a&gt; serves as an important quality control metric for ATACseq data. I want to write a script for single cell ATACseq data.&lt;/p&gt;

&lt;p&gt;From the Encode page:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Transcription Start Site (TSS) Enrichment Score - The TSS enrichment calculation is a signal to noise calculation. The reads around a reference set of TSSs are collected to form an aggregate distribution of reads centered on the TSSs and extending to 1000 bp in either direction (for a total of 2000bp). This distribution is then normalized by taking the average read depth in the 100 bps at each of the end flanks of the distribution (for a total of 200bp of averaged data) and calculating a fold change at each position over that average read depth. This means that the flanks should start at 1, and if there is high read signal at transcription start sites (highly open regions of the genome) there should be an increase in signal up to a peak in the middle. We take the signal value at the center of the distribution after this normalization as our TSS enrichment metric. Used to evaluate ATAC-seq.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It was not so clear to me from the definition on how &lt;strong&gt;EXACTLY&lt;/strong&gt; this score is calculated.&lt;/p&gt;

&lt;p&gt;I inspected the &lt;a href=&#34;https://github.com/jianhong/ATACseqQC/blob/master/R/TSSEscore.R#L80&#34; target=&#34;_blank&#34;&gt;source code&lt;/a&gt; of  &lt;code&gt;ATACseqQC&lt;/code&gt; which calculates the TSS enrichment score for bulk ATACseq data, but I think it is not calculating it the right way as described by the ENCODE page.&lt;/p&gt;

&lt;p&gt;I reached out to &lt;a href=&#34;https://twitter.com/Satpathology&#34; target=&#34;_blank&#34;&gt;Ansu Satpathy&lt;/a&gt; (thanks!), and got a script written by Jeffrey Granja, who are the authors of this recent scATACseq paper:
&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/610550v1&#34; target=&#34;_blank&#34;&gt;Massively parallel single-cell chromatin landscapes of human immune cell development and intratumoral T cell exhaustion (2019)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I studied the script and also got the confirmation from ENCODE how they calculate the TSS enrichment score
&lt;a href=&#34;https://github.com/ENCODE-DCC/atac-seq-pipeline/issues/50&#34; target=&#34;_blank&#34;&gt;https://github.com/ENCODE-DCC/atac-seq-pipeline/issues/50&lt;/a&gt; by a python script.&lt;/p&gt;

&lt;p&gt;To work with this coverage type of data in R, I want to take advantage of the data structure &lt;code&gt;View&lt;/code&gt; in bioconductor, so I borrowed some codes from &lt;a href=&#34;https://bioconductor.org/packages/release/bioc/vignettes/genomation/inst/doc/GenomationManual.html&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;genomation::ScoreMatrix&lt;/code&gt;&lt;/a&gt; instead of using the script sent by Ansu. It is a very nice package by &lt;a href=&#34;https://twitter.com/AltunaAkalin&#34; target=&#34;_blank&#34;&gt;Altuna Akalin&lt;/a&gt;. A side note, he has a very nice book you might be interested in: &lt;a href=&#34;http://compgenomr.github.io/book/how-to-contribute.html&#34; target=&#34;_blank&#34;&gt;Computational Genomics with R&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Below, I ended up with a hybrid script from multiple sources.
Now it works with the 10x cellranger-atac output &lt;code&gt;fragment.tsv.gz&lt;/code&gt;. One can tweak it to work with the bam file. However, the bam file is 25G, R takes a long time to parse it.&lt;/p&gt;

&lt;p&gt;I explain what the script does:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;for each TSS, get per base coverage for the 1000 bp flanking region(flank = 1000).&lt;/li&gt;
&lt;li&gt;do this for all TSSs, We get a matrix of #TSS x 2000 bp dimension.&lt;/li&gt;
&lt;li&gt;do a column sum of the matrix.&lt;/li&gt;
&lt;li&gt;sum of the coverage of the endFlank (100bp) at both ends and divide by 200 bp to get a
normalization factor.&lt;/li&gt;
&lt;li&gt;divide the the normalization factor for -1900 to + 1900 bp to get per base normalized coverage.&lt;/li&gt;
&lt;li&gt;do a smoothing with a defined window (50bp by default) using &lt;code&gt;zoo::rollmean&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;select the highest value within a window (highest_tss_flank, 50 bp by default) around the TSS because the highest peak is not necessary at exactly the TSS site (position 0)&lt;/li&gt;
&lt;li&gt;repeat 1-7 for all cells.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;extra-technical-notes&#34;&gt;Extra technical notes:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;One thing to note is that one needs to filter out the TSSs which are not within the coverage. e.g. A TSS with 1000 bp flanking regions fall out of the coverage.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;use only the common chromosomes between coverage and the txs.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;convert GRanges to IntergerRangesList does not maintain the order of the GRanges.
so a unique id was given for each Ranges, and the matrix can be reordered according to this unique id. That&amp;rsquo;s what &lt;code&gt;constrainRanges()&lt;/code&gt; does. read this thread for more &lt;a href=&#34;https://stat.ethz.ch/pipermail/bioc-devel/2016-June/009433.html&#34; target=&#34;_blank&#34;&gt;https://stat.ethz.ch/pipermail/bioc-devel/2016-June/009433.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;how-long-it-takes&#34;&gt;How long it takes.&lt;/h3&gt;

&lt;p&gt;It took me around ~15 seconds to calculate the TSS enrichment score for a single cell.
1.213291 hours for 5000 PBMC cells using 15 workers (not too bad :).&lt;/p&gt;

&lt;h3 id=&#34;r-code&#34;&gt;R code&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(GenomicRanges)
library(dplyr)

#&#39; checkClass function
#&#39; 
#&#39; check whether the x object corresponds to the given class
#&#39;
#&#39; @param x object
#&#39; @param class.name class name
#&#39; @param var.name uses x object
#&#39; @keywords internal
checkClass = function(x, class.name, var.name = deparse(substitute(x))){
  
  fun.name = match.call(call=sys.call(sys.parent(n=1)))[[1]]
  if(!class(x) %in% class.name)
    stop(paste(fun.name,&#39;: &#39;, 
               var.name, 
               &#39; is not of class: &#39;, 
               paste(class.name, collapse=&#39; &#39;), 
               &#39;\n&#39;, sep=&#39;&#39;))
}

### remove the tss that do not have coverage
### I took some code from the ScoreMatrix.R function in the genomation package.
### give the credit due :)
### see https://github.com/BIMSBbioinfo/genomation/blob/master/R/scoreMatrix.R#L113
constrainRanges = function(target, windows){
  
  checkClass(target, c(&#39;SimpleRleList&#39;,&#39;RleList&#39;,&#39;CompressedRleList&#39;))
  checkClass(windows, &#39;GRanges&#39;)
  
  mcols(windows)$X_rank = 1:length(windows)
  r.chr.len = elementNROWS(target)
  constraint = GRanges(seqnames=names(r.chr.len),
                       IRanges(start=rep(1,length(r.chr.len)),
                               end=as.numeric(r.chr.len)))
  # suppressWarnings is done becuause GenomicRanges function give warnings 
  #if you don&#39;t have the same seqnames in both objects
  win.list.chr = suppressWarnings(subsetByOverlaps(windows, 
                                                   constraint,
                                                   type = &amp;quot;within&amp;quot;,
                                                   ignore.strand = TRUE))
  
  if(length(win.list.chr) == 0)
    stop(&#39;All windows fell have coordinates outside windows boundaries&#39;)
  return(win.list.chr)
}



#&#39; Calculate tss enrichment score from 10xscATAC fragment file
#&#39;
#&#39; @param frag_gz_file  fragment.tsv.gz file from 10x cellranger-atac output or 
#&#39; anyother tool but in the same format.
#&#39; @param txs  a txdb object
#&#39; @param flank flanking bp of tss (upstream and downstream)
#&#39; @param endFlank  bp end flanks of flank for local noise control
#&#39;     flank               flank
#&#39;  ---------------|-----------------
#&#39;                tss
#&#39;  ---                           ---
#&#39;  endFlank                     endFlank
#&#39;  
#&#39; @param highest_tss_flank bp flanking tss windown for choosing the highest tss score.
#&#39; The highest tss enrichment score is not always exactly at tss.
#&#39; @param barcodeList valid barcode list, a file with one column 
#&#39; @param smooth window size to smooth 
#&#39; @param strand.aware consider tss strandness when calculating 
#&#39;
#&#39; @return
#&#39; @export
#&#39;
#&#39; @examples
#&#39; library(TxDb.Hsapiens.UCSC.hg19.knownGene)
#&#39; library(dplyr); library(readr); library(BiocParallel)
#&#39; txs &amp;lt;- transcripts(TxDb.Hsapiens.UCSC.hg19.knownGene)
#&#39; scores&amp;lt;- TssEnrichmentFromFrags(&amp;quot;fragment.tsv.gz&amp;quot;, txs = txs)

TssEnrichmentFromFrags &amp;lt;- function(frag_gz_file,
                               txs,
                               flank = 1000,
                               endFlank = 100,
                               highest_tss_flank= 50,
                               smooth = 50,
                               strand.aware = TRUE,
                               workers = 1,
                               barcodeList = NULL){
        
        # Make GRanges of fragments that are solid for the cells that we care about
        frags_valid &amp;lt;- data.table::fread(paste0(&amp;quot;zcat &amp;lt; &amp;quot;, frag_gz_file)) %&amp;gt;% 
                data.frame() %&amp;gt;% 
                mutate(V2 = V2 + 1) %&amp;gt;% # make it 1 based for R
                GenomicRanges::makeGRangesFromDataFrame(seqnames.field = &amp;quot;V1&amp;quot;, start.field = &amp;quot;V2&amp;quot;, end.field = &amp;quot;V3&amp;quot;, keep.extra.columns = TRUE)
        if (!is.null(barcodeList)){
                validBarcodes&amp;lt;- read_tsv(barcodeList, col_names = F)
                frags_valid&amp;lt;- frags_valid[frags_valid$V4 %in% validBarcodes$X1]
        }
        
        # common chromosome names, do it per cell instead, see TssEnrichmentSingleCell
        seqlev&amp;lt;- intersect(seqlevels(frags_valid), seqlevels(txs))
        frags_valid&amp;lt;- keepSeqlevels(frags_valid, seqlev, pruning.mode=&amp;quot;coarse&amp;quot;)
        
        # calculate coverage per cell
        frags_valid_per_cell&amp;lt;- split(frags_valid, frags_valid$V4)
        
       
        # this step can take minutes 
        multicoreParam &amp;lt;- BiocParallel::MulticoreParam(workers = workers)
        # can add the chromosome length as additional argument for `coverage`
        # to get 0 coverages if there are no reads there. 
        cvgs&amp;lt;- bplapply(frags_valid_per_cell, function(x) coverage(x), BPPARAM = multicoreParam)
        
        txs &amp;lt;- unique(txs)
        
        txs.flanks&amp;lt;- promoters(txs, upstream = flank, 
                            downstream = flank)
        txs.length&amp;lt;- length(txs.flanks)
        
        TssEnrichmentScores&amp;lt;- BiocParallel::bplapply(cvgs, TssEnrichmentSingleCell, txs.flanks, strand.aware = strand.aware, endFlank = endFlank, flank = flank, highest_tss_flank, smooth = smooth, BPPARAM = multicoreParam)

        enrichment&amp;lt;- do.call(&amp;quot;rbind&amp;quot;, TssEnrichmentScores)
        return(enrichment)
}    

TssEnrichmentSingleCell&amp;lt;- function(cvg, txs.flanks, strand.aware = TRUE, flank = 1000,
                               endFlank = 100,
                               highest_tss_flank= 50,
                               smooth = 50 ){
        ## remove tss not in the coverage and assign a unique id for each tss: X_rank
        txs.flanks&amp;lt;- constrainRanges(cvg, txs.flanks)
        txs.length&amp;lt;- length(txs.flanks)
        if(length(txs.flanks)!=txs.length){
              warning(paste0(txs.length-length(txs.flanks),
                             &amp;quot; Tss removed because they fall out of the coverage&amp;quot;))
            }
        # common chromosomes
        chrs&amp;lt;- sort(intersect(names(cvg), as.character(unique(seqnames(txs.flanks)))))
        
        # convert GRanges to IntergerRangesList does not maintain the order
        # a unique id was given for each Ranges
        myViews&amp;lt;- Views(cvg[chrs],as(txs.flanks,&amp;quot;IntegerRangesList&amp;quot;)[chrs]) # get subsets of RleList
        mat = lapply(myViews,function(x) t(viewApply(x,as.vector)) )
        mat = do.call(&amp;quot;rbind&amp;quot;,mat)
        
        r.list=split(mcols(txs.flanks)[,&amp;quot;X_rank&amp;quot;], as.vector(seqnames(txs.flanks))  )
        r.list=r.list[order(names(r.list))]
        ranks=do.call(&amp;quot;c&amp;quot;,r.list)
        rownames(mat) = ranks
        
        if(strand.aware == TRUE){
              orig.rows=txs.flanks[strand(txs.flanks) == &#39;-&#39;,]$X_rank
              mat[rownames(mat) %in% orig.rows,] = mat[rownames(mat) %in% 
                                                         orig.rows, ncol(mat):1]
        }
        
        # reorder according to the original Granges (txs)
        mat = mat[order(ranks),]
        
  
        ### normlization by the endFlank local noise
        profile &amp;lt;- colSums(mat)
        profile_norm &amp;lt;- profile/mean(profile[c(1:endFlank,(flank*2-endFlank+1):(flank*2))])

        #smooth
        profile_norm_smooth &amp;lt;- zoo::rollmean(profile_norm, smooth, fill = 1)
        

        #enrichment
        max_finite &amp;lt;- function(x){
        suppressWarnings(max(x[is.finite(x)], na.rm=TRUE))
        }
        
        e &amp;lt;- max_finite(profile_norm_smooth[(flank-highest_tss_flank):(flank+highest_tss_flank)])
        return(e)
}


&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>clustering scATACseq data: the TF-IDF way</title>
      <link>/post/clustering-scatacseq-data-the-tf-idf-way/</link>
      <pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/clustering-scatacseq-data-the-tf-idf-way/</guid>
      <description>&lt;p&gt;scATACseq data are very sparse. It is sparser than scRNAseq. To do clustering of
scATACseq data, there are some preprocessing steps need to be done.&lt;/p&gt;
&lt;p&gt;I want to reproduce what has been done after reading the method section of these two recent scATACseq paper:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/30078704&#34;&gt;A Single-Cell Atlas of In Vivo Mammalian Chromatin Accessibility&lt;/a&gt;
Darren et.al Cell 2018&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Latent Semantic Indexing Cluster Analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In order to get an initial sense of the relationship between individual cells, &lt;strong&gt;we first broke the genome into 5kb windows and then scored each cell for any insertions in these windows, generating a large, sparse, binary matrix of 5kb windows by cells for each tissue.&lt;/strong&gt; Based on this matrix, we retained the top 20,000 most commonly used sites in each tissue (this number could extend a little above 20,000 because we included tied sites at the threshold) and then filtered out the bottom 5% of cells in terms of the number of 5kb windows with any insertions. We then reduced the dimensionality of these large binary matrices using a term &lt;strong&gt;frequency-inverse document frequency (‘‘TF-IDF’’) transformation.&lt;/strong&gt; To do this, we first weighted all the sites for individual cells by the total number of sites accessible in that cell (‘‘term frequency’’). We then multiplied these weighted values by log(1 + the inverse frequency of each site across all cells), the ‘‘inverse document frequency.’’ We then used singular value decomposition on the TF-IDF matrix to generate a lower dimensional representation of the data by only retaining the 2nd through 10th dimensions (because the first dimension tends to be highly correlated with read depth). These LSI-transformed scores of accessibility were then standardized by row (i.e., mean subtracted and divided by standard deviation), capped at ± 1.5, and used to bi-cluster cells and windows based on cosine distances using the ward algorithm in R. Visual examination of the resulting heatmaps identified between 2 and 7 distinct clusters of cells, de- pending on the tissue. These relatively crude groups of cells were used for peak calling (described below) to maintain enough cells in each group for identifying peaks while also retaining sufficient sensitivity to identify peaks that were restricted to subset of cells.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;t-distributed Stochastic Neighbor Embedding and Iterative Cluster Analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To take a more holistic approach to understanding the relationships of different cell types across the entire dataset, we combined all cells from all tissues and used the t-distributed stochastic neighbor embedding dimensionality reduction technique to visualize the full dataset and identify clusters of cells representing individual cell types. &lt;strong&gt;As with the LSI analysis above, we started by generating a large binary matrix of sites by cells, but instead of scoring cells for reads overlapping 5kb windows in the genome we scored cells for reads overlapping the master list of potential regulatory elements we had previously identified based on LSI clusters.&lt;/strong&gt; Starting with all cells that passed our nucleosome signal and read depth thresholds, we again wanted to remove the most sparsely sampled sites and cells to more clearly define differences between cell types. To do so, we first filtered out any sites that were not observed as accessible in at least 5% of cells in at least one LSI cluster and then filtered out cells that were more than 1 standard deviation below the mean number of sites observed. We then transformed this matrix with the TF-IDF algorithm described above. Finally, we generated a lower dimen- sional representation of the data by including the first 50 dimensions of the singular value decomposition of this TF-IDF-transformed matrix. This representation was then used as input for the Rtsne package in R (Krijthe, 2015). To identify clusters of cells in this two dimensional representation of the data, we used the Louvain clustering algorithm implemented in Seurat (Satija et al., 2015). Resolu- tion and K parameters for Louvain clustering were chosen for each major cluster to produce reasonable groupings of cells that are well- separated in each t-SNE embedding. This analysis identified 30 distinct clusters of cells, but to get at even finer structure, we subset TF-IDF normalized data on each of these 30 clusters of cells and repeated SVD and t-SNE to identify subclusters, again using Louvain clustering. Through this round of ‘‘iterative’’ t-SNE, we identified a total of 85 distinct clusters. Note that for one major cluster, major cluster 12, we found that Monocle 20s implementation of density peak clustering (Qiu et al., 2017; Trapnell et al., 2014) seemed to produce more reasonable clusters. Rho and delta parameters were set in the same manner as for Louvain clustering.&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/610550v1&#34;&gt;Massively parallel single-cell chromatin landscapes of human immune cell development and intratumoral T cell exhaustion&lt;/a&gt;
Ansuman et.al 2019 biorxiv&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;ATAC-seq-centric Latent Semantic Indexing clustering and visualization&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We clustered scATAC-seq data using an approach that does not require bulk data or prior
knowledge. To achieve this, we adopted the strategy by Cusanovich et. al9, to compute
the term frequency-inverse document frequency (“TF-IDF”) transformation. Briefly we
divided each index by the colSums of the matrix to compute the cell “term frequency.”
Next, we multiplied these values by log(1 + ncol(matrix) / rowSums(matrix)), which
represents the “inverse document frequency.” This resulted in a TF-IDF matrix that was
used as input to irlba’s singular value decomposition (SVD) implementation in R. We then
used the first 50 reduced dimensions as input into a Seurat object and then crude clusters
were identified by using Seurat’s (v2.3) SNN graph clustering “FindClusters” with a default
resolution of 0.8. We found that there was detectable batch effect that confounded further
analyses. To attenuate this batch effect, we calculated the cluster sums from the binarized
accessibility matrix and then log-normalized by using edgeR’s “cpm(matrix , log = TRUE,
prior.count = 3)” in R. Next, we identified the top 25,000 varying peaks across all clusters
using “rowVars” in R. This was done on the cluster log-normalized matrix vs the sparse
binary matrix because: (1) it reduced biases due to cluster cell sizes, and (2) it attenuated
the mean-variability relationship by converting to log space with a scaled prior count.
These 25,000 variable peaks were then used to subset the sparse binarized accessibility
matrix and recomputed the “TF-IDF” transform. We used singular value decomposition
on the TF-IDF matrix to generate a lower dimensional representation of the data by
retaining the first 50 dimensions. We then used these reduced dimensions as input into
a Seurat object and then crude clusters were identified by using Seurat’s (v2.3) SNN
graph clustering “FindClusters” with a default resolution of 0.8. These same reduced
dimensions were used as input to Seurat’s “RunUMAP” with default parameters and
plotted in ggplot2 using R&lt;/p&gt;
&lt;p&gt;Both papers used the so called &lt;code&gt;Latent Semantic Indexing&lt;/code&gt; or &lt;a href=&#34;https://en.wikipedia.org/wiki/Latent_semantic_analysis&#34;&gt;LSI method&lt;/a&gt; and used a transformation of the
binarized scATAC count matrix called ’TF-IDF` (term frequency–inverse document frequency) which is
used in text mining. TF-IDF can be used for scRNAseq data as well. see &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6101073/&#34;&gt;Single cell RNA-seq data clustering using TF-IDF based methods&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The transformation is not complicated as described above:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Briefly we divided each index by the colSums of the matrix to compute the cell “term frequency.”
Next, we multiplied these values by log(1 + ncol(matrix) / rowSums(matrix)), which
represents the “inverse document frequency.” This resulted in a TF-IDF matrix&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;Seurat&lt;/code&gt; version 3 has a function called &lt;a href=&#34;https://github.com/satijalab/seurat/blob/master/R/preprocessing.R#L1253&#34;&gt;&lt;code&gt;TF.IDF&lt;/code&gt;&lt;/a&gt; for that purpose.&lt;/p&gt;
&lt;p&gt;But note that, it does not do the log transformation in this function, but do it at &lt;a href=&#34;https://github.com/satijalab/seurat/blob/master/R/dimensional_reduction.R#L669&#34; class=&#34;uri&#34;&gt;https://github.com/satijalab/seurat/blob/master/R/dimensional_reduction.R#L669&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I will first show you the long way to do the clustering through which I want to gain some more
deep understanding of the whole process and I will show you how to use &lt;code&gt;Seurat&lt;/code&gt; V3 for that.&lt;/p&gt;
&lt;p&gt;I am going to use the 10k pbmc scATAC data from 10x for demonstration. You can download the data from
&lt;a href=&#34;https://support.10xgenomics.com/single-cell-atac/datasets/1.1.0/atac_v1_pbmc_10k&#34; class=&#34;uri&#34;&gt;https://support.10xgenomics.com/single-cell-atac/datasets/1.1.0/atac_v1_pbmc_10k&lt;/a&gt;&lt;/p&gt;
&lt;div id=&#34;the-long-way&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The long way&lt;/h3&gt;
&lt;p&gt;read in the sparse matrix&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Matrix)
library(readr)
library(dplyr)
mat&amp;lt;- readMM(&amp;quot;/Users/mingtang/github_repos/blogdown_data/filtered_peak_bc_matrix/matrix.mtx&amp;quot;)
peaks&amp;lt;- read_tsv(&amp;quot;/Users/mingtang/github_repos/blogdown_data/filtered_peak_bc_matrix/peaks.bed&amp;quot;, col_names = F)
peaks&amp;lt;- peaks %&amp;gt;%
        mutate(id1 = paste(X2, X3, sep = &amp;quot;-&amp;quot;)) %&amp;gt;%
        mutate(id = paste(X1, id1, sep = &amp;quot;:&amp;quot;))
        
barcodes&amp;lt;- read_tsv(&amp;quot;/Users/mingtang/github_repos/blogdown_data/filtered_peak_bc_matrix/barcodes.tsv&amp;quot;, col_names =F)

rownames(mat)&amp;lt;- peaks$id1
colnames(mat)&amp;lt;- barcodes$X1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;binarize the data and do TF-IDF transformation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# binarize the matrix 
mat@x[mat@x &amp;gt;0]&amp;lt;- 1 

TF.IDF.custom &amp;lt;- function(data, verbose = TRUE) {
  if (class(x = data) == &amp;quot;data.frame&amp;quot;) {
    data &amp;lt;- as.matrix(x = data)
  }
  if (class(x = data) != &amp;quot;dgCMatrix&amp;quot;) {
    data &amp;lt;- as(object = data, Class = &amp;quot;dgCMatrix&amp;quot;)
  }
  if (verbose) {
    message(&amp;quot;Performing TF-IDF normalization&amp;quot;)
  }
  npeaks &amp;lt;- Matrix::colSums(x = data)
  tf &amp;lt;- t(x = t(x = data) / npeaks)
  # log transformation
  idf &amp;lt;- log(1+ ncol(x = data) / Matrix::rowSums(x = data))
  norm.data &amp;lt;- Diagonal(n = length(x = idf), x = idf) %*% tf
  norm.data[which(x = is.na(x = norm.data))] &amp;lt;- 0
  return(norm.data)
}


mat&amp;lt;- TF.IDF.custom(mat)

# what&amp;#39;s the range after transformation?
range(mat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.00000000 0.01111942&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(mat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 89796  8728&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Dimension reduction with SVD, use &lt;code&gt;irlba::irlba&lt;/code&gt; for approximated calculation.&lt;/p&gt;
&lt;p&gt;Note: &lt;code&gt;svd&lt;/code&gt; singular value decomposition gives the same results as &lt;code&gt;prcomp&lt;/code&gt;for exact PC calculation.
see my previous &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/post/pca-in-action/&#34;&gt;blog post&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(irlba)
set.seed(123)
mat.lsi&amp;lt;- irlba(mat, 50)

d_diagtsne &amp;lt;- matrix(0, 50, 50)
diag(d_diagtsne) &amp;lt;- mat.lsi$d
mat_pcs &amp;lt;- t(d_diagtsne %*% t(mat.lsi$v))
dim(mat_pcs)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 8728   50&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## PCA plot PC1 vs PC2
plot(mat_pcs[,1], mat_pcs[,2])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-05-03-clustering-scatacseq-data-the-tf-idf-way_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rownames(mat_pcs)&amp;lt;- colnames(mat)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;clustering in the PCA space using KNN.&lt;/p&gt;
&lt;p&gt;I took some code from &lt;a href=&#34;https://jef.works/blog/2017/09/13/graph-based-community-detection-for-clustering-analysis/&#34;&gt;Jean Fan’s blog post&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(RANN)
knn.info&amp;lt;- RANN::nn2(mat_pcs, k = 30)

## convert to adjacancy matrix
knn &amp;lt;- knn.info$nn.idx

adj &amp;lt;- matrix(0, nrow(mat_pcs), nrow(mat_pcs))
rownames(adj) &amp;lt;- colnames(adj) &amp;lt;- rownames(mat_pcs)

for(i in seq_len(nrow(mat_pcs))) {
    adj[i,rownames(mat_pcs)[knn[i,]]] &amp;lt;- 1
}

## convert to graph
library(igraph)
g &amp;lt;- igraph::graph.adjacency(adj, mode=&amp;quot;undirected&amp;quot;)
g &amp;lt;- simplify(g) ## remove self loops

## identify communities, many algorithums. Use the Louvain clustering

km &amp;lt;- igraph::cluster_louvain(g)

com &amp;lt;- km$membership
names(com) &amp;lt;- km$names

# cluster id for each barcode
head(com)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## AAACGAAAGAGCGAAA-1 AAACGAAAGAGTTTGA-1 AAACGAAAGCGAGCTA-1 
##                  7                 14                  2 
## AAACGAAAGGCTTCGC-1 AAACGAAAGTGCTGAG-1 AAACGAACAAGGGTAC-1 
##                 11                  1                 10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## total 13 clusters
table(com)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## com
##    1    2    3    4    5    6    7    8    9   10   11   12   13   14 
## 1776  389  482   34 1100  520  491  640  781  487  204  888  173  763&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;t-SNE for visualization&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Rtsne)
library(ggplot2)
library(tibble)
set.seed(345)

mat_tsne&amp;lt;- Rtsne(mat_pcs,  dims = 2, perplexity = 30, verbose = TRUE, 
               max_iter = 1000, check_duplicates = FALSE, is_distance = FALSE, 
               theta = 0.5, pca = FALSE, exaggeration_factor = 12)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Read the 8728 x 50 data matrix successfully!
## OpenMP is working. 1 threads.
## Using no_dims = 2, perplexity = 30.000000, and theta = 0.500000
## Computing input similarities...
## Building tree...
## Done in 1.81 seconds (sparsity = 0.015574)!
## Learning embedding...
## Iteration 50: error is 94.027001 (50 iterations in 1.63 seconds)
## Iteration 100: error is 80.430931 (50 iterations in 1.34 seconds)
## Iteration 150: error is 77.384844 (50 iterations in 1.10 seconds)
## Iteration 200: error is 76.435871 (50 iterations in 1.12 seconds)
## Iteration 250: error is 75.985857 (50 iterations in 1.16 seconds)
## Iteration 300: error is 2.655848 (50 iterations in 1.02 seconds)
## Iteration 350: error is 2.321504 (50 iterations in 1.02 seconds)
## Iteration 400: error is 2.140627 (50 iterations in 1.05 seconds)
## Iteration 450: error is 2.024543 (50 iterations in 1.06 seconds)
## Iteration 500: error is 1.944114 (50 iterations in 1.06 seconds)
## Iteration 550: error is 1.884803 (50 iterations in 1.10 seconds)
## Iteration 600: error is 1.840703 (50 iterations in 1.14 seconds)
## Iteration 650: error is 1.806387 (50 iterations in 1.06 seconds)
## Iteration 700: error is 1.780991 (50 iterations in 1.07 seconds)
## Iteration 750: error is 1.761708 (50 iterations in 1.07 seconds)
## Iteration 800: error is 1.747014 (50 iterations in 1.10 seconds)
## Iteration 850: error is 1.735953 (50 iterations in 1.07 seconds)
## Iteration 900: error is 1.728716 (50 iterations in 1.11 seconds)
## Iteration 950: error is 1.725798 (50 iterations in 1.13 seconds)
## Iteration 1000: error is 1.724810 (50 iterations in 1.21 seconds)
## Fitting performed in 22.62 seconds.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_tsne&amp;lt;- as.data.frame(mat_tsne$Y)
colnames(df_tsne)&amp;lt;- c(&amp;quot;tSNE1&amp;quot;, &amp;quot;tSNE2&amp;quot;)
df_tsne$barcode&amp;lt;- rownames(mat_pcs)

df_tsne&amp;lt;- left_join(df_tsne, enframe(com), by = c(&amp;quot;barcode&amp;quot; = &amp;quot;name&amp;quot;)) %&amp;gt;%
        dplyr::rename(cluster = value) %&amp;gt;%
        mutate(cluster = as.factor(cluster))


ggplot(df_tsne, aes(x = tSNE1, y = tSNE2)) + 
        geom_point(aes(col = cluster), size = 0.5) +
        theme_bw(base_size = 14)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-05-03-clustering-scatacseq-data-the-tf-idf-way_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This looks pretty good :)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-easier-way-use-seurat&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The easier way: use Seurat&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Seurat)
peaks &amp;lt;- Read10X_h5(filename = &amp;quot;/Users/mingtang/github_repos/blogdown_data/atac_v1_pbmc_10k_filtered_peak_bc_matrix.h5&amp;quot;)

# binarize the matrix
peaks@x[peaks@x &amp;gt;0]&amp;lt;- 1 

## create a seurat object
atac.lsi &amp;lt;- CreateSeuratObject(counts = peaks, assay = &amp;#39;ATAC&amp;#39;, project = &amp;#39;10k_pbmc&amp;#39;)

atac.lsi &amp;lt;- RunLSI(object = atac.lsi, n = 50, scale.max = NULL)

# atac.lsi@reductions

atac.lsi&amp;lt;- FindNeighbors(atac.lsi, reduction = &amp;quot;lsi&amp;quot;, dims = 1:50)
atac.lsi&amp;lt;- FindClusters(atac.lsi, resolution = 0.8)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck
## 
## Number of nodes: 8728
## Number of edges: 246454
## 
## Running Louvain algorithm...
## Maximum modularity in 10 random starts: 0.9129
## Number of communities: 20
## Elapsed time: 0 seconds&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;atac.lsi &amp;lt;- RunTSNE(object = atac.lsi, reduction = &amp;quot;lsi&amp;quot;, dims = 1:50)
DimPlot(object = atac.lsi, reduction = &amp;#39;tsne&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-05-03-clustering-scatacseq-data-the-tf-idf-way_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You may argue those two t-SNE graphs look very different in terms of number of clusters
and the shape of the clusters. And I agree. There are many reasons for that.
I hope &lt;code&gt;Seurat&lt;/code&gt; team can give some insights.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The &lt;code&gt;TF-IDF&lt;/code&gt; function in &lt;code&gt;Seurat&lt;/code&gt; does not do log transformation
as in the papers: &lt;code&gt;idf &amp;lt;- log(1+ ncol(x = data) / Matrix::rowSums(x = data))&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;but rather do a log transformation &lt;a href=&#34;https://github.com/satijalab/seurat/blob/master/R/dimensional_reduction.R#L669&#34;&gt;later&lt;/a&gt;: &lt;code&gt;tf.idf &amp;lt;- LogNorm(data = tf.idf, display_progress = verbose, scale_factor = 1e4)&lt;/code&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;I am not an expert in the graph clustering, but the clustering algorithm in
&lt;code&gt;Seurat&lt;/code&gt; is probably not exactly the same with &lt;code&gt;igraph::cluster_louvain&lt;/code&gt;.
Moreover, one can always tweak the k.param and resolution parameters, and the cluster number changes.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We can compare the cell identities for each cluster&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# https://github.com/crazyhottommy/scclusteval
library(scclusteval)

# takes two named vector, and calculate the pairwise Jaccard similarity score
# for all clusters
PairWiseJaccardSetsHeatmap(com, Idents(atac.lsi))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-05-03-clustering-scatacseq-data-the-tf-idf-way_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;some-other-notes&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Some other notes&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;It is known that first dimension is correlated with sequencing depth (although Ansuman et.al did not find such). Nevertheless, if you see such correlation, when cluster
cells in the PC space, you can exclude the first PC. e.g. &lt;code&gt;atac.lsi&amp;lt;- FindNeighbors(atac.lsi, reduction = &amp;quot;lsi&amp;quot;, dims = 2:50)&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I did not do &lt;code&gt;LSI&lt;/code&gt; first for crude clustering using the titled 5kb genome bin matrix and call peaks for each crude cluster and then get the count matrix per peak per cell. I am not sure how much this extra work can benefit the clustering.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;It turns out the &lt;code&gt;TF-IDF&lt;/code&gt; transformation is critical for this sparse matrix. If you do not do it, you will find your t-SNE plot looks really funky! do not trust me, try it yourself:)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;for clustering scATAC data, one can use the peak x cell matrix or derive a gene activity score by tools such as &lt;a href=&#34;https://cole-trapnell-lab.github.io/cicero-release/&#34;&gt;&lt;code&gt;Cicero&lt;/code&gt;&lt;/a&gt; to generate a gene x cell matrix. This is useful when you want to transfer the RNAseq cell type labels to the scATACseq data. see more details in the &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/460147v1&#34;&gt;Seurat V3 paper&lt;/a&gt;. The question is then, which matrix should we use for clustering? The clustering of these two different matrix can be different but there should be no surprise. We can use the gene activity score matrix as a label transferring mediator and get the cell labels and then super-impose the cluster id to the t-SNE plot clustered by the peak x cell matrix.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;acknowledgements&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Acknowledgements&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;I want to thank 10x genomics for making the data publicly available.&lt;/li&gt;
&lt;li&gt;I want to thank &lt;a href=&#34;https://jef.works/blog/2017/09/13/graph-based-community-detection-for-clustering-analysis/&#34;&gt;Jean Fan&lt;/a&gt; for putting up some nice posts.&lt;/li&gt;
&lt;li&gt;I want to thank Tim Stuart for answering questions with &lt;code&gt;Seurat&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;I got some ideas from &lt;a href=&#34;https://github.com/jaychung10010/Mammary_snATAC-seq&#34; class=&#34;uri&#34;&gt;https://github.com/jaychung10010/Mammary_snATAC-seq&lt;/a&gt; as well. Thanks for posting the codes.&lt;/li&gt;
&lt;li&gt;I want to thank everyone else who give help and suggestions along my adventure of analyzing scATACseq data.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;update&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;UPDATE&lt;/h3&gt;
&lt;p&gt;Do the IF-IDF Seurat way&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(Matrix)
library(readr)
library(dplyr)
mat&amp;lt;- readMM(&amp;quot;/Users/mingtang/github_repos/blogdown_data/filtered_peak_bc_matrix/matrix.mtx&amp;quot;)
peaks&amp;lt;- read_tsv(&amp;quot;/Users/mingtang/github_repos/blogdown_data/filtered_peak_bc_matrix/peaks.bed&amp;quot;, col_names = F)
peaks&amp;lt;- peaks %&amp;gt;%
        mutate(id1 = paste(X2, X3, sep = &amp;quot;-&amp;quot;)) %&amp;gt;%
        mutate(id = paste(X1, id1, sep = &amp;quot;:&amp;quot;))
        
barcodes&amp;lt;- read_tsv(&amp;quot;/Users/mingtang/github_repos/blogdown_data/filtered_peak_bc_matrix/barcodes.tsv&amp;quot;, col_names =F)

rownames(mat)&amp;lt;- peaks$id1
colnames(mat)&amp;lt;- barcodes$X1
# binarize the matrix 
mat@x[mat@x &amp;gt;0]&amp;lt;- 1 
# Seurat version TF-IDF
mat&amp;lt;- TF.IDF(mat)
mat&amp;lt;- LogNormalize(mat,scale_factor = 1e4)

### SVD
library(irlba)
set.seed(123)
mat.lsi&amp;lt;- irlba(mat, 50)

d_diagtsne &amp;lt;- matrix(0, 50, 50)
diag(d_diagtsne) &amp;lt;- mat.lsi$d
mat_pcs &amp;lt;- t(d_diagtsne %*% t(mat.lsi$v))
dim(mat_pcs)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 8728   50&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## PCA plot PC1 vs PC2
plot(mat_pcs[,1], mat_pcs[,2])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-05-03-clustering-scatacseq-data-the-tf-idf-way_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rownames(mat_pcs)&amp;lt;- colnames(mat)

library(RANN)
knn.info&amp;lt;- RANN::nn2(mat_pcs, k = 30)

## convert to adjacancy matrix
knn &amp;lt;- knn.info$nn.idx

adj &amp;lt;- matrix(0, nrow(mat_pcs), nrow(mat_pcs))
rownames(adj) &amp;lt;- colnames(adj) &amp;lt;- rownames(mat_pcs)

for(i in seq_len(nrow(mat_pcs))) {
    adj[i,rownames(mat_pcs)[knn[i,]]] &amp;lt;- 1
}

## convert to graph
library(igraph)
g &amp;lt;- igraph::graph.adjacency(adj, mode=&amp;quot;undirected&amp;quot;)
g &amp;lt;- simplify(g) ## remove self loops

## identify communities, many algorithums. Use the Louvain clustering

km &amp;lt;- igraph::cluster_louvain(g)

com &amp;lt;- km$membership
names(com) &amp;lt;- km$names

# cluster id for each barcode
head(com)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## AAACGAAAGAGCGAAA-1 AAACGAAAGAGTTTGA-1 AAACGAAAGCGAGCTA-1 
##                 13                  7                 12 
## AAACGAAAGGCTTCGC-1 AAACGAAAGTGCTGAG-1 AAACGAACAAGGGTAC-1 
##                 14                 13                 16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## total 13 clusters
table(com)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## com
##    1    2    3    4    5    6    7    8    9   10   11   12   13   14   15 
##  801  376  617  629  572   56  607  435  280  390  131  417 2554  490  241 
##   16 
##  132&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;### T-sne visualization
library(Rtsne)
library(ggplot2)
library(tibble)
set.seed(345)

mat_tsne&amp;lt;- Rtsne(mat_pcs,  dims = 2, perplexity = 30, verbose = TRUE, 
               max_iter = 1000, check_duplicates = FALSE, is_distance = FALSE, 
               theta = 0.5, pca = FALSE, exaggeration_factor = 12)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Read the 8728 x 50 data matrix successfully!
## OpenMP is working. 1 threads.
## Using no_dims = 2, perplexity = 30.000000, and theta = 0.500000
## Computing input similarities...
## Building tree...
## Done in 2.57 seconds (sparsity = 0.014984)!
## Learning embedding...
## Iteration 50: error is 94.871477 (50 iterations in 1.48 seconds)
## Iteration 100: error is 84.409610 (50 iterations in 1.50 seconds)
## Iteration 150: error is 82.319098 (50 iterations in 1.18 seconds)
## Iteration 200: error is 81.831573 (50 iterations in 1.35 seconds)
## Iteration 250: error is 81.608255 (50 iterations in 1.40 seconds)
## Iteration 300: error is 3.039995 (50 iterations in 1.20 seconds)
## Iteration 350: error is 2.691975 (50 iterations in 1.14 seconds)
## Iteration 400: error is 2.508723 (50 iterations in 1.24 seconds)
## Iteration 450: error is 2.390684 (50 iterations in 1.14 seconds)
## Iteration 500: error is 2.308249 (50 iterations in 1.16 seconds)
## Iteration 550: error is 2.248218 (50 iterations in 1.12 seconds)
## Iteration 600: error is 2.201765 (50 iterations in 1.27 seconds)
## Iteration 650: error is 2.166028 (50 iterations in 1.21 seconds)
## Iteration 700: error is 2.137659 (50 iterations in 1.13 seconds)
## Iteration 750: error is 2.115987 (50 iterations in 1.11 seconds)
## Iteration 800: error is 2.098913 (50 iterations in 1.16 seconds)
## Iteration 850: error is 2.086752 (50 iterations in 1.08 seconds)
## Iteration 900: error is 2.079435 (50 iterations in 1.07 seconds)
## Iteration 950: error is 2.078012 (50 iterations in 1.14 seconds)
## Iteration 1000: error is 2.076638 (50 iterations in 1.12 seconds)
## Fitting performed in 24.21 seconds.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_tsne&amp;lt;- as.data.frame(mat_tsne$Y)
colnames(df_tsne)&amp;lt;- c(&amp;quot;tSNE1&amp;quot;, &amp;quot;tSNE2&amp;quot;)
df_tsne$barcode&amp;lt;- rownames(mat_pcs)

df_tsne&amp;lt;- left_join(df_tsne, enframe(com), by = c(&amp;quot;barcode&amp;quot; = &amp;quot;name&amp;quot;)) %&amp;gt;%
        dplyr::rename(cluster = value) %&amp;gt;%
        mutate(cluster = as.factor(cluster))

ggplot(df_tsne, aes(x = tSNE1, y = tSNE2)) + 
        geom_point(aes(col = cluster), size = 0.5) +
        theme_bw(base_size = 14)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-05-03-clustering-scatacseq-data-the-tf-idf-way_files/figure-html/unnamed-chunk-8-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Well, it still looks different from the &lt;code&gt;Seurat&lt;/code&gt; output. Any comments?&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>plot 10x scATAC coverage by cluster/group</title>
      <link>/post/plot-10x-scatac-coverage-by-cluster-group/</link>
      <pubDate>Mon, 29 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/plot-10x-scatac-coverage-by-cluster-group/</guid>
      <description>&lt;p&gt;This post was inspired by &lt;a href=&#34;https://twitter.com/ahill_tweets&#34;&gt;Andrew Hill&lt;/a&gt;’s &lt;a href=&#34;http://andrewjohnhill.com/blog/2019/04/12/streamlining-scatac-seq-visualization-and-analysis/&#34;&gt;recent blog post&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Inspired by some nice posts by &lt;a href=&#34;https://twitter.com/timoast?ref_src=twsrc%5Etfw&#34;&gt;@timoast&lt;/a&gt; and &lt;a href=&#34;https://twitter.com/tangming2005?ref_src=twsrc%5Etfw&#34;&gt;@tangming2005&lt;/a&gt; and work from &lt;a href=&#34;https://twitter.com/10xGenomics?ref_src=twsrc%5Etfw&#34;&gt;@10xGenomics&lt;/a&gt;. Would still definitely have to split BAM files for other tasks, so easy to use tools for that are super useful too!&lt;/p&gt;&amp;mdash; Andrew J Hill (@ahill_tweets) &lt;a href=&#34;https://twitter.com/ahill_tweets/status/1116875339303493634?ref_src=twsrc%5Etfw&#34;&gt;April 13, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;p&gt;Andrew wrote that blog post in light of my other &lt;a href=&#34;https://divingintogeneticsandgenomics.rbind.io/post/split-a-10xscatac-bam-file-by-cluster/&#34;&gt;recent blog post&lt;/a&gt; and &lt;a href=&#34;https://twitter.com/timoast&#34;&gt;Tim&lt;/a&gt;’s (developer of the almighty &lt;a href=&#34;https://satijalab.org/seurat/&#34;&gt;Seurat&lt;/a&gt; package) &lt;a href=&#34;https://timoast.github.io/blog/sinto/&#34;&gt;blog post&lt;/a&gt;. Writing blog post is fun and I am happy to see so many new ideas can be generated through online communications.&lt;/p&gt;
&lt;p&gt;I took Andrew’s idea of reading in the reads in a certain window by taking advantages of tabix indexed file fragment.tsv.gz which is an output from 10x &lt;code&gt;cellranger-atac&lt;/code&gt;. I then split the reads by a grouping file which specifies which group each cell belongs to and a total number of reads in each cell. For visualization, instead of using ggplot2, I used the awesome &lt;a href=&#34;https://bernatgel.github.io/karyoploter_tutorial/&#34;&gt;karyoploteR&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I experimented a bit and came up with a function below. Note the script is fast as only the reads fall in the specified region are read into R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(readr)
library(tidyr)
library(dplyr)
library(tibble)
library(Rsamtools)
library(karyoploteR)
library(org.Hs.eg.db)
library(org.Mm.eg.db)
library(TxDb.Hsapiens.UCSC.hg19.knownGene)
library(TxDb.Mmusculus.UCSC.mm10.knownGene)


extend &amp;lt;- function(x, upstream=0, downstream=0)     
{
        if (any(strand(x) == &amp;quot;*&amp;quot;))
                warning(&amp;quot;&amp;#39;*&amp;#39; ranges were treated as &amp;#39;+&amp;#39;&amp;quot;)
        on_plus &amp;lt;- strand(x) == &amp;quot;+&amp;quot; | strand(x) == &amp;quot;*&amp;quot;
        new_start &amp;lt;- start(x) - ifelse(on_plus, upstream, downstream)
        new_end &amp;lt;- end(x) + ifelse(on_plus, downstream, upstream)
        ranges(x) &amp;lt;- IRanges(new_start, new_end)
        trim(x)
}


addGeneNameToTxdb&amp;lt;- function(txdb = TxDb.Hsapiens.UCSC.hg19.knownGene, 
                             eg.db = org.Hs.eg.db){
        gene&amp;lt;- genes(txdb)
        ## 1: 1 mapping
        ss&amp;lt;- AnnotationDbi::select(eg.db, keys = gene$gene_id,  
                              keytype=&amp;quot;ENTREZID&amp;quot;, columns = &amp;quot;SYMBOL&amp;quot; )
        gene$symbol&amp;lt;- ss[, 2]
        return(gene)
}


plotCoverageByGroup&amp;lt;- function(chrom = NULL, start = NULL, end = NULL, gene_name = NULL, upstream = 2000,
                               downstream = 2000, fragment, grouping,
                               genome =&amp;#39;hg19&amp;#39;, txdb = TxDb.Hsapiens.UCSC.hg19.knownGene,
                               eg.db = org.Hs.eg.db,
                               ymax = NULL, label_cex = 1, 
                               yaxis_cex = 1, track_col = &amp;quot;cadetblue2&amp;quot;,
                               tick.dist = 10000, minor.tick.dist = 2000,
                               tick_label_cex = 1){
        grouping&amp;lt;- readr::read_tsv(grouping)
        if(! all(c(&amp;quot;cell&amp;quot;, &amp;quot;cluster&amp;quot;, &amp;quot;depth&amp;quot;) %in% colnames(grouping))) {
                stop(&amp;#39;Grouping dataframe must have cell, cluster, and depth columns.&amp;#39;)
        }
        ## get number of reads per group for normalization. 
        ## not furthur normalize by the cell number in each group.
        grouping&amp;lt;-  grouping %&amp;gt;%
                group_by(cluster) %&amp;gt;%
                dplyr::mutate(cells_in_group = n(), total_depth_in_group = sum(depth)) %&amp;gt;%
                # reads per million (RPM)
                dplyr::mutate(scaling_factor = 1e6/(total_depth_in_group)) %&amp;gt;%
                ungroup() %&amp;gt;%
                dplyr::select(cell, cluster, scaling_factor)
        
        
        if (is.null(chrom) &amp;amp; is.null(start) &amp;amp; is.null(end) &amp;amp; !is.null(gene_name)){
                gene &amp;lt;- genes(txdb)
                gene &amp;lt;- addGeneNameToTxdb(txdb = txdb, eg.db = eg.db)
                gr&amp;lt;- gene[which(gene$symbol == gene_name)]
                if (length(gr) == 0){
                        stop(&amp;quot;gene name is not found in the database&amp;quot;)
                } else if (length(gr) &amp;gt; 1) {
                        gr&amp;lt;- gr[1]
                        warning(&amp;quot;multiple GRanges found for the gene, using the first one&amp;quot;)
                } else {
                        gr&amp;lt;- extend(gr, upstream = upstream, downstream = downstream)
                } 
                
        } else if (!is.null(chrom) &amp;amp; !is.null(start) &amp;amp; !is.null(end)){
                gr&amp;lt;- GRanges(seq = chrom, IRanges(start = start, end = end ))
        }
        
        
        ## read in the fragment.tsv.gz file
        ## with &amp;quot;chr&amp;quot;, &amp;quot;start&amp;quot;, &amp;quot;end&amp;quot;, &amp;quot;cell&amp;quot;, &amp;quot;duplicate&amp;quot; columns. output from cellranger-atac
        # this returns a list
        reads&amp;lt;- scanTabix(fragment, param = gr)
        
        reads&amp;lt;- reads[[1]] %&amp;gt;% 
                tibble::enframe() %&amp;gt;% 
                dplyr::select(-name) %&amp;gt;%
                tidyr::separate(value, into = c(&amp;quot;chr&amp;quot;, &amp;quot;start&amp;quot;, &amp;quot;end&amp;quot;, &amp;quot;cell&amp;quot;, &amp;quot;duplicate&amp;quot;), sep = &amp;quot;\t&amp;quot;) %&amp;gt;%
                dplyr::mutate_at(.vars = c(&amp;quot;start&amp;quot;, &amp;quot;end&amp;quot;), as.numeric) %&amp;gt;% 
                # make it 1 based for R, the fragment.tsv is 0 based
                dplyr::mutate(start = start + 1) %&amp;gt;% 
                inner_join(grouping) %&amp;gt;%
                makeGRangesFromDataFrame(keep.extra.columns = TRUE)
        # GRangesList object by group/cluster
        reads_by_group&amp;lt;- split(reads, reads$cluster)
        
        ## plotting
        pp &amp;lt;- getDefaultPlotParams(plot.type=1)
        pp$leftmargin &amp;lt;- 0.15
        pp$topmargin &amp;lt;- 15
        pp$bottommargin &amp;lt;- 15
        pp$ideogramheight &amp;lt;- 5
        pp$data1inmargin &amp;lt;- 10
        kp &amp;lt;- plotKaryotype(genome = genome, zoom = gr, plot.params = pp)
        kp&amp;lt;- kpAddBaseNumbers(kp, tick.dist = tick.dist, minor.tick.dist = minor.tick.dist,
                              add.units = TRUE, cex= tick_label_cex, digits = 6)
        ## calculate the normalized coverage
        normalized_coverage&amp;lt;- function(x){
                if (!is(x, &amp;quot;GRangesList&amp;quot;))
                        stop(&amp;quot;&amp;#39;x&amp;#39; must be a GRangesList object&amp;quot;)
                # specify the width to the whole chromosome to incldue the 0s
                cvgs&amp;lt;- lapply(x, function(x) coverage(x, width = kp$chromosome.lengths) * x$scaling_factor[1])
                return(cvgs)
        }
        
        coverage_norm&amp;lt;- normalized_coverage(reads_by_group)
        
        ## calculate the max coverage if not specified 
        if (is.null(ymax)) {
                yaxis_common&amp;lt;- ceiling(max(lapply(coverage_norm, max) %&amp;gt;% unlist()))
        } else {
                yaxis_common&amp;lt;- ymax
        }
        ## add gene information
        genes.data &amp;lt;- makeGenesDataFromTxDb(txdb,
                                            karyoplot=kp,
                                            plot.transcripts = TRUE, 
                                            plot.transcripts.structure = TRUE)
        genes.data &amp;lt;- addGeneNames(genes.data)
        genes.data &amp;lt;- mergeTranscripts(genes.data)
        
        kp&amp;lt;- kpPlotGenes(kp, data=genes.data, r0=0, r1=0.05, gene.name.cex = 1)
        
        for(i in seq_len(length(coverage_norm))) {
                read &amp;lt;- coverage_norm[[i]]
                at &amp;lt;- autotrack(i, length(coverage_norm), r0=0.1, r1=1, margin = 0.1)
                kp &amp;lt;- kpPlotCoverage(kp, data=read,
                                     r0=at$r0, r1=at$r1, col = track_col, ymax = yaxis_common)
                kpAxis(kp, ymin=0, ymax=yaxis_common, numticks = 2, r0=at$r0, r1=at$r1, cex = yaxis_cex, labels = c(&amp;quot;&amp;quot;, yaxis_common))
                kpAddLabels(kp, labels = names(coverage_norm)[i], r0=at$r0, r1=at$r1, 
                            cex=label_cex, label.margin = 0.005)
        }
        
}&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;usage&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Usage&lt;/h3&gt;
&lt;p&gt;The example files can be downloaded from &lt;a href=&#34;https://osf.io/q5dwj/&#34; class=&#34;uri&#34;&gt;https://osf.io/q5dwj/&lt;/a&gt;.
&lt;code&gt;atac_v1_pbmc_10k_fragments.tsv.gz&lt;/code&gt; is the 10k pbmc atac data downloaded from 10x website. Thanks for making the
data public available. Make sure put the tabix index &lt;code&gt;atac_v1_pbmc_10k_fragments.tsv.gz.tbi&lt;/code&gt; in the same folder.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;grouping.txt&lt;/code&gt; is a 3 column tsv file containing header: cell, cluster, and depth. The cluster label was transferred from the 10x pbmc scRNAseq data set using &lt;code&gt;Seurat&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;LYZ gene is a marker for CD16+ cells.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## LYZ gene 
chrom&amp;lt;-  &amp;quot;chr12&amp;quot;
start&amp;lt;-  69730394
end&amp;lt;- 69760971

plotCoverageByGroup(chrom = chrom, start = start, end = end, fragment = &amp;quot;atac_v1_pbmc_10k_fragments.tsv.gz&amp;quot;,
                    grouping = &amp;quot;grouping.txt&amp;quot;, track_col = &amp;quot;red&amp;quot;, label_cex = 0.75)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-04-29-plot-10x-scatac-coverage-by-cluster-group_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;NKG7 is a marker for NK cells.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plotCoverageByGroup(gene_name = &amp;quot;NKG7&amp;quot;, fragment = &amp;quot;atac_v1_pbmc_10k_fragments.tsv.gz&amp;quot;,
                    grouping = &amp;quot;grouping.txt&amp;quot;, tick_label_cex = 1, tick.dist = 5000,
                    minor.tick.dist = 1000, label_cex = 0.75)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-04-29-plot-10x-scatac-coverage-by-cluster-group_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;what I did for some extra work:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;I normalized each track by total number of reads in that group in reads per million. I did not do
any further normalization on the cell number of each group as Andrew did. I am open to discussion on how to
best normalize the tracks.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I calculated the max value of all the tracks and set a common y-axis for all the tracks. Users can set a customized &lt;code&gt;ymax&lt;/code&gt; as well.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I added some functionality of specifying only a gene name, and one can extend that gene ranges by padding upstream (from transcription start site) and downstream (from transcription end site) bps.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;One can either plot Human or Mouse data. Other organisms can be easily supported by modifying the script.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;what-to-do-next&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;what to do next&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;customer specified cluster (a subset of clusters in a certain order) to plot.
When one has a lot of clusters (e.g. over 50), one probably does not want to plot all of them.&lt;/li&gt;
&lt;li&gt;specify color for each cluster track.&lt;/li&gt;
&lt;li&gt;bam support by using&lt;code&gt;Rsamtools::ScanBam&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;smooth window? The plots showed above were not smoothed and they look good to me. Not sure needed.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Any suggestions/discussions are welcomed!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Reproducible research in bioinformatics</title>
      <link>/talk/2019-bunkerhill-talk/</link>
      <pubDate>Thu, 28 Mar 2019 14:30:00 -0400</pubDate>
      
      <guid>/talk/2019-bunkerhill-talk/</guid>
      <description>&lt;p&gt;I was invited to give a talk on reproducible bioinformatics research to the students in the &lt;a href=&#34;https://www.bhcc.edu/&#34; target=&#34;_blank&#34;&gt;Bunker Hill Community College&lt;/a&gt; in Boston, MA. I was so glad to introduce bioinformatics to the students and share my own perspectives on reproducible research.&lt;/p&gt;

&lt;p&gt;The movie &lt;a href=&#34;https://en.wikipedia.org/wiki/Good_Will_Hunting&#34; target=&#34;_blank&#34;&gt;Good Will Hunting&lt;/a&gt; was shot there :)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/bunkerhill-talk.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Embed your slides or video here using &lt;a href=&#34;https://sourcethemes.com/academic/post/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;shortcodes&lt;/a&gt;. Further details can easily be added using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>KRAS-IRF2 Axis Drives Immune Suppression and Immune Therapy Resistance in Colorectal Cancer</title>
      <link>/publication/2019-03-20-irf2/</link>
      <pubDate>Wed, 20 Mar 2019 00:00:00 -0400</pubDate>
      
      <guid>/publication/2019-03-20-irf2/</guid>
      <description>&lt;p&gt;More detail can easily be written here using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Use docopt to write command line R utilities </title>
      <link>/post/use-docopt-to-write-command-line-r-utilities/</link>
      <pubDate>Fri, 22 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/use-docopt-to-write-command-line-r-utilities/</guid>
      <description>&lt;p&gt;I was writing an R script to plot the ATACseq fragment length distribution and wanted
to turn the R script to a command line utility.&lt;/p&gt;

&lt;p&gt;I then (re)discovered this awesome &lt;a href=&#34;https://github.com/docopt/docopt.R&#34; target=&#34;_blank&#34;&gt;docopt.R&lt;/a&gt;.
One just needs to write the help message the you want to display and &lt;code&gt;docopt()&lt;/code&gt; will
parse the options, arguments and return a named list which can be accessed inside the
R script. check &lt;a href=&#34;http://docopt.org/&#34; target=&#34;_blank&#34;&gt;http://docopt.org/&lt;/a&gt; for more information as well.&lt;/p&gt;

&lt;p&gt;See below for an example. You can download it at &lt;a href=&#34;https://github.com/crazyhottommy/scATACutils/blob/master/R/plot_atac_frag_distribution.R&#34; target=&#34;_blank&#34;&gt;https://github.com/crazyhottommy/scATACutils/blob/master/R/plot_atac_frag_distribution.R&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;
#! /usr/bin/env Rscript
&#39;Plot fragment length distribution from ATACseq data
Usage:
    plot_atac_fragment_len_distribution.R (--poly | --hist) (--pdf | --png) [--width=&amp;lt;width&amp;gt; --height=&amp;lt;height&amp;gt; --bin=&amp;lt;bp&amp;gt;] &amp;lt;input&amp;gt; &amp;lt;output&amp;gt;
    
Options:
    -h --help  Show this screen.
    -v --version  Show version.
    --bin=&amp;lt;bp&amp;gt;  Bin size [default: 5]
    --poly  Plot frequency polygon.
    --hist  Plot histogram.
    --pdf  Save to pdf.
    --png  Save to png.
    --width=&amp;lt;width&amp;gt;  Width of the output [default: 4]
    --height=&amp;lt;height&amp;gt; Height of the output [default: 4]

Arguments:
    input  fragment length in a one column dataframe without header or stdin
    output  output filename
&#39; -&amp;gt; doc

suppressMessages(library(ggplot2))
# check this awesome docoptR https://github.com/docopt/docopt.R
## make sure use the development version, the CRAN version not working for me
# library(devtools) 
# devtools::install_github(&amp;quot;docopt/docopt.R&amp;quot;)
suppressMessages(library(docopt))
suppressMessages(library(dplyr))

# this will give error if try interactively, because no input and output argument are given
# https://github.com/docopt/docopt.R/issues/27
arguments &amp;lt;- docopt(doc, version = &#39;plot_atac_frag_distribution v1.0\n\n&#39;)

# for testing interactively
#arguments &amp;lt;- docopt(doc, version = &#39;FragmentSizeDistribution v1.0&#39;, args = c(&amp;quot;scripts/fragment3.txt&amp;quot;,&amp;quot;my.pdf&amp;quot;))
#print(arguments)

## File Read ##
# taken from https://stackoverflow.com/questions/26152998/how-to-make-r-script-takes-input-from-pipe-and-user-given-parameter
# if the input is stdin one can do 
# cat fragment.txt | ./plot_atac_frag_distribution.R --poly --pdf stdin  out.pdf
# cat fragment.txt | ./plot_atac_frag_distribution.R --poly --pdf - out.pdf
# ./plot_atac_frag_distribution.R --poly --pdf &amp;lt;(cat fragment.txt)  out.pdf


OpenRead &amp;lt;- function(arg) {
    if (arg %in% c(&amp;quot;-&amp;quot;, &amp;quot;/dev/stdin&amp;quot;)) {
        file(&amp;quot;stdin&amp;quot;, open = &amp;quot;r&amp;quot;)
    } else if (grepl(&amp;quot;^/dev/fd/&amp;quot;, arg)) {
        fifo(arg, open = &amp;quot;r&amp;quot;)
    } else {
        file(arg, open = &amp;quot;r&amp;quot;)
    }
}

dat.con &amp;lt;- OpenRead(arguments$input)
fragment &amp;lt;- read.table(dat.con, header = FALSE)

#fragment&amp;lt;- read.table(arguments$input, header = F)

names(fragment)&amp;lt;- c(&amp;quot;length&amp;quot;)

plot_hist&amp;lt;- function(fragment, bin) {
        g&amp;lt;- ggplot(fragment %&amp;gt;% filter(length &amp;lt;=2000), aes(x = length)) + 
                geom_histogram(binwidth = bin, aes(y=..density..), fill = &amp;quot;red&amp;quot;) +
                geom_density(alpha=.2, fill=&amp;quot;#FF6666&amp;quot;, col = &amp;quot;black&amp;quot;) +
                coord_cartesian(xlim = c(0,1000)) +
                scale_x_continuous(breaks = c(0, 100, 200, 300, 400, 800)) +
                theme_minimal(base_size = 14)
        return(g)
        
}

plot_polygon&amp;lt;- function(fragment, bin){
        g&amp;lt;- ggplot(fragment %&amp;gt;% filter(length &amp;lt;=2000), aes(x = length, stat(density))) + 
                geom_freqpoly(binwidth = bin, col = &amp;quot;blue&amp;quot;) +
                coord_cartesian(xlim = c(0,1000)) +
                scale_x_continuous(breaks = c(0, 100, 200, 300, 400, 800)) +
                theme_minimal(base_size = 14)
        return(g)
}


main&amp;lt;- function(fragment, arguments){
    if (arguments$poly){
        g&amp;lt;- plot_polygon(fragment, as.numeric(arguments$bin))
    } else if (arguments$hist){
        g&amp;lt;- plot_hist(fragment, as.numeric(arguments$bin))
    }
    device&amp;lt;- ifelse(arguments$pdf, &amp;quot;pdf&amp;quot;, &amp;quot;png&amp;quot;)
    
    ggsave(arguments$output, plot = g,  device = device, width =as.numeric(arguments$width), 
           height = as.numeric(arguments$height) )
    
}

main(fragment, arguments)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;save it to &lt;code&gt;plot_atac_frag_distribution.R&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;on command line, one can do:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;
./plot_atac_frag_distribution.R -h
Plot fragment length distribution from ATACseq data
Usage:
    plot_atac_fragment_len_distribution.R (--poly | --hist) (--pdf | --png) [--width=&amp;lt;width&amp;gt; --height=&amp;lt;height&amp;gt; --bin=&amp;lt;bp&amp;gt;] &amp;lt;input&amp;gt; &amp;lt;output&amp;gt;

Options:
    -h --help  Show this screen.
    -v --version  Show version.
    --bin=&amp;lt;bp&amp;gt;  Bin size [default: 5]
    --poly  Plot frequency polygon.
    --hist  Plot histogram.
    --pdf  Save to pdf.
    --png  Save to png.
    --width=&amp;lt;width&amp;gt;  Width of the output [default: 4]
    --height=&amp;lt;height&amp;gt; Height of the output [default: 4]

Arguments:
    input  fragment length in a one column dataframe without header or stdin
    output  output filename

./plot_atac_frag_distribution.R --poly --png  --bin 10 fragment.txt out.png
cat fragment.txt | ./plot_atac_frag_distribution.R --poly --pdf stdin  out.pdf
cat fragment.txt | ./plot_atac_frag_distribution.R --hist --pdf - out.pdf
./plot_atac_frag_distribution.R --hist --pdf &amp;lt;(cat fragment.txt)  out.pdf

samtools view my.bam | awk &#39;$9&amp;gt;0&#39; | cut -f 9 |./plot_atac_frag_distribution.R --poly --pdf - out.pdf

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;histogram:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/posts_img/out2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;polygon:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/posts_img/out3.png&#34; alt=&#34;&#34; /&gt;
Pretty cool!!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Important notes:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;[default: 4]  The space after &lt;code&gt;:&lt;/code&gt; is needed.&lt;/li&gt;
&lt;li&gt;use two spaces to separate the option and the explanation&lt;/li&gt;
&lt;li&gt;use four spaces to indent&lt;/li&gt;
&lt;li&gt;use the development version of optdoc.R&lt;/li&gt;
&lt;li&gt;when testing interactively. docopt() may give error when the mandatory arguments
are not specified, but running on command line is fine.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;see &lt;a href=&#34;https://github.com/docopt/docopt.R/issues/24&#34; target=&#34;_blank&#34;&gt;https://github.com/docopt/docopt.R/issues/24&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Also check &lt;a href=&#34;http://dirk.eddelbuettel.com/code/littler.examples.html&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;littler&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;littler provides the r program, a simplified command-line interface for GNU R. This allows direct execution of commands, use in piping where the output of one program supplies the input of the next, as well as adding the ability for writing hash-bang scripts, i.e. creating executable files starting with, say, #!/usr/bin/r.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
  </channel>
</rss>
