<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DNA confesses and Data speak on DNA confesses and Data speak</title>
    <link>/</link>
    <description>Recent content in DNA confesses and Data speak on DNA confesses and Data speak</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Ming Tang</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0500</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Backup automatically with cron</title>
      <link>/post/crontab-for-backup/</link>
      <pubDate>Wed, 27 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/crontab-for-backup/</guid>
      <description>

&lt;p&gt;Data backup is an essential step in the data analysis life cycle. As shown in a pic below.&lt;/p&gt;

&lt;p&gt;There are so many important things you may want to back up: your raw/processed data, your code, and your dot configuration files. While for every project, I have git version control my scripts (not the data) and push it to github or gitlab to have a backup, big files can not be hosted on github or gitlab.&lt;/p&gt;

&lt;p&gt;I usually back up my &lt;code&gt;projects&lt;/code&gt; folder (containg all my scripts, raw data, processed data etc) to our high performance computing cluster in the &lt;code&gt;/rsch1&lt;/code&gt; folder here at MD Anderson Cancer Center. IT stuff back up the contents there every week. In that essense, I have a copy in my local computer, a backup copy in the remote cluster and one more copy that IT stuffs backed up. I used to do &lt;code&gt;rsync -avhP ~/projects mdaris337:/rsch1/genomic_med/mtang1/tommy_mac_backup&lt;/code&gt; once a week, but then sometimes I foget about it. I need a tool to do it every once a while for me. Here comes &lt;code&gt;cron&lt;/code&gt; to help.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;cron is a Unix, solaris, Linux utility that allows tasks to be automatically run in the background at regular intervals by the cron daemon.&lt;/p&gt;

&lt;p&gt;Crontab (CRON TABle) is a file which contains the schedule of cron entries to be run and at specified times. File location varies by operating systems, See Crontab file location at the end of this document.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;commands for &lt;code&gt;crontab&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# It took me forever to quit vim :) so avoiding it now.
export EDITOR=nano ;to specify a editor to open crontab file.

crontab -e    Edit crontab file, or create one if it doesnâ€™t already exist.
crontab -l    crontab list of cronjobs , display crontab file contents.
crontab -r    Remove your crontab file.
crontab -v    Display the last time you edited your crontab file. (This option is only available on a few systems.)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;crontab-file&#34;&gt;crontab file&lt;/h3&gt;

&lt;p&gt;crontab syntax&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;*     *     *   *    *        command to be executed
-     -     -   -    -
|     |     |   |    |
|     |     |   |    +----- day of week (0 - 6) (Sunday=0)
|     |     |   +------- month (1 - 12)
|     |     +--------- day of        month (1 - 31)
|     +----------- hour (0 - 23)
+------------- min (0 - 59)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;cron-not-working&#34;&gt;Cron not working?&lt;/h3&gt;

&lt;p&gt;It happend to me that my cron job is not running. I googled around and found
a comprehensive checking list that you can do to debug.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. Is the Cron daemon running?
* Run ps ax | grep cron and look for cron.
* Debian: service cron start or service cron restart

2. Is cron working?
* * * * * /bin/echo &amp;quot;cron works&amp;quot; &amp;gt;&amp;gt; /file
Syntax correct? See above.

3. Is the command working standalone?
Check if the script has an error, by doing a dry run on the CLI
when testing your command, test as the user whose crontab you are editing, which might not be your login or root

4. Can cron run your job?
Check /var/log/cron.log or /var/log/messages for errors.
Ubuntu: grep CRON /var/log/syslog
Redhat: /var/log/cron

5. Check permissions
set executable flag on the command: chmod +x /var/www/app/cron/do-stuff.php
if you redirect the output of your command to a file, verify you have permission to write to that file/directory

6. Check paths
check she-bangs / hashbangs line
do not rely on environment variables like PATH, as their value will likely not be the same under cron as under an interactive session

7. Don&#39;t Suppress Output, while debugging
commonly used is this suppression: 30 1 * * * command &amp;gt; /dev/null 2&amp;gt;&amp;amp;1
re-enable the standard output or standard error message output
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It turns out my ubuntu&lt;/p&gt;

&lt;h3 id=&#34;links-for-further-reading&#34;&gt;links for further reading&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://www.adminschoice.com/crontab-quick-reference&#34; target=&#34;_blank&#34;&gt;http://www.adminschoice.com/crontab-quick-reference&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://stackoverflow.com/questions/22743548/cronjob-not-running&#34; target=&#34;_blank&#34;&gt;https://stackoverflow.com/questions/22743548/cronjob-not-running&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to upload files to GEO</title>
      <link>/post/how-to-upload-files-to-geo/</link>
      <pubDate>Fri, 22 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/how-to-upload-files-to-geo/</guid>
      <description>

&lt;h3 id=&#34;readings&#34;&gt;readings&lt;/h3&gt;

&lt;p&gt;links:
&lt;a href=&#34;http://yeolab.github.io/onboarding/geo.html&#34; target=&#34;_blank&#34;&gt;http://yeolab.github.io/onboarding/geo.html&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.hildeschjerven.net/Protocols/Submission_of_HighSeq_data_to_GEO.pdf&#34; target=&#34;_blank&#34;&gt;http://www.hildeschjerven.net/Protocols/Submission_of_HighSeq_data_to_GEO.pdf&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/geo/info/submissionftp.html&#34; target=&#34;_blank&#34;&gt;https://www.ncbi.nlm.nih.gov/geo/info/submissionftp.html&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;1-create-account&#34;&gt;1. create account&lt;/h3&gt;

&lt;p&gt;Goto NCBI GEO: &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/geo/&#34; target=&#34;_blank&#34;&gt;http://www.ncbi.nlm.nih.gov/geo/&lt;/a&gt;
Create User ID and password. my username is &lt;code&gt;research_guru&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;I used my google account.&lt;/p&gt;

&lt;h3 id=&#34;2-fill-in-the-xls-sheet&#34;&gt;2. fill in the xls sheet&lt;/h3&gt;

&lt;p&gt;Downloaded the meata xls sheet from &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/geo/info/seq.html&#34; target=&#34;_blank&#34;&gt;https://www.ncbi.nlm.nih.gov/geo/info/seq.html&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;## bgzip the fastqs

cd 01seq
find *fastq | parallel bgzip
md5sum *fastq.gz &amp;gt; fastq_md5.txt 
# copy to excle
cat fastq_md5.txt | awk &#39;{print $2}&#39;

#copy to excle
cat fastq_md5.txt | awk &#39;{print $1}&#39;


cd ../07bigwig
#get the md5sum

md5sum *bw &amp;gt; bigwig_md5.txt

# sample name, copy to excel
cat bigwig_md5.txt | awk &#39;{print $2}&#39;

# md5, copy to excel
cat bigwig_md5.txt | awk &#39;{print $1}&#39;

cd ../08peak_macs1

md5sum *macs1_peaks.bed &amp;gt; peaks_md5.txt
# copy to excel
cat peaks_md5.txt | awk &#39;{print $2}&#39;

cd ..
mkdir research_guru_KMT2D_ChIPseq

cd research_guru_KMT2D_ChIPseq

## fill in the xls sheet and save in this folder
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is the most time-consuming/tedious step.&lt;/p&gt;

&lt;h3 id=&#34;3-hard-link-peak-and-bigwig-files-to-the-folder&#34;&gt;3. hard link peak and bigwig files to the folder&lt;/h3&gt;

&lt;p&gt;soft link does not work for me&amp;hellip;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ln  /rsrch2/genomic_med/krai/hunain_histone_reseq/snakemake_ChIPseq_pipeline_downsample/07bigwig/*bw .


ln /rsrch2/genomic_med/krai/hunain_histone_reseq/snakemake_ChIPseq_pipeline_downsample/08peak_macs1/*macs1_peaks.bed .
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;4-upload-to-geo&#34;&gt;4. upload to GEO&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;
# inside the folder: research_guru_KMT2D_ChIPseq
ftp ftp-private.ncbi.nlm.nih.gov

## type in the user name and the password
## this is not your GEO account user name.
## everyone uses the same `geo` and the same password below.

# https://www.ncbi.nlm.nih.gov/geo/info/submissionftp.html

#name: geo
#password: 33%9uyj_fCh?M16H

ftp&amp;gt; prompt n
Interactive mode off.

ftp&amp;gt; cd fasp

# make a folder in the ftp site
ftp&amp;gt; mkdir research_guru_ChIPseq

ftp&amp;gt; cd research_guru_ChIPseq

#upload all the files
ftp&amp;gt; mput *
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;5-telling-ncbi-you-uploaded-stuff&#34;&gt;5. telling NCBI you uploaded stuff&lt;/h3&gt;

&lt;p&gt;After your transfer is complete, you need to tell the NCBI.&lt;/p&gt;

&lt;p&gt;After file transfer is complete, please e-mail GEO with the following information: - GEO account username (tangming2005@gmail.com); - Names of the directory and files deposited; - Public release date (required - up to 3 years from now - see FAQ).&lt;/p&gt;

&lt;h3 id=&#34;side-notes&#34;&gt;Side notes&lt;/h3&gt;

&lt;p&gt;for paired-end sequencing data. the xls sheet requries you to fill in the average insert size and the std.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;picard CollectInsertSizeMetrics&lt;/code&gt; can do this job.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;time java -jar /scratch/genomic_med/apps/picard/picard-tools-2.13.2/picard.jar CollectInsertSizeMetrics I=4-Mll4-RasG12D-1646-2-cd45_S40_L006.sorted.bam  H=4-Mll4-RasG12D-1646-2-cd45_S40_L006_insert.pdf  O=4-Mll4-RasG12D-1646-2-cd45_S40_L006_insert.txt

# finish in ~5mins
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;read &lt;a href=&#34;http://thegenomefactory.blogspot.com/2013/08/paired-end-read-confusion-library.html&#34; target=&#34;_blank&#34;&gt;http://thegenomefactory.blogspot.com/2013/08/paired-end-read-confusion-library.html&lt;/a&gt; for insert size definition.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Integrative Analysis Identifies Four Molecular and Clinical Subsets in Uveal Melanoma</title>
      <link>/publication/2017-08-14-uveal-melanoma/</link>
      <pubDate>Mon, 14 Aug 2017 00:00:00 -0500</pubDate>
      
      <guid>/publication/2017-08-14-uveal-melanoma/</guid>
      <description>&lt;p&gt;More detail can easily be written here using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Systematic analysis of telomere length and somatic alterations in 31 cancer types</title>
      <link>/publication/2012-03-01-ctcf-angiogenesis/</link>
      <pubDate>Wed, 01 Mar 2017 00:00:00 -0600</pubDate>
      
      <guid>/publication/2012-03-01-ctcf-angiogenesis/</guid>
      <description>&lt;p&gt;More detail can easily be written here using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Systematic analysis of telomere length and somatic alterations in 31 cancer types</title>
      <link>/publication/telomere-pan-cancer/</link>
      <pubDate>Wed, 01 Mar 2017 00:00:00 -0600</pubDate>
      
      <guid>/publication/telomere-pan-cancer/</guid>
      <description>&lt;p&gt;More detail can easily be written here using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Talk</title>
      <link>/talk/example-talk/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 -0600</pubDate>
      
      <guid>/talk/example-talk/</guid>
      <description>&lt;p&gt;Embed your slides or video here using &lt;a href=&#34;https://sourcethemes.com/academic/post/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;shortcodes&lt;/a&gt;. Further details can easily be added using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Snakemake Pipelines</title>
      <link>/project/snakemake-pipelines/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 -0500</pubDate>
      
      <guid>/project/snakemake-pipelines/</guid>
      <description>&lt;p&gt;Snakemake is a python extension for writing workflows. Genomics data processing usually requires bundling many different tools to reach a stage that is ready for downstream analysis.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The malignant brain tumor (MBT) domain protein SFMBT1 is an integral histone reader subunit of the LSD1 demethylase complex for chromatin association and epithelial-to-mesenchymal transition</title>
      <link>/publication/sfmbt-snail-emt-cancer/</link>
      <pubDate>Fri, 20 Sep 2013 00:00:00 -0500</pubDate>
      
      <guid>/publication/sfmbt-snail-emt-cancer/</guid>
      <description>&lt;p&gt;More detail can easily be written here using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Restraint of angiogenesis by zinc finger transcription factor CTCF-dependent chromatin insulation</title>
      <link>/publication/ctcf-vegf-enhancer-blocking/</link>
      <pubDate>Tue, 13 Sep 2011 00:00:00 -0500</pubDate>
      
      <guid>/publication/ctcf-vegf-enhancer-blocking/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
